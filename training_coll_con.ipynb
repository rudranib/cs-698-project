{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from movienet import MovieNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from autoencoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'tfidf_matrix.pkl', 'rb') as fh:\n",
    "    tfidf = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratings=pd.read_csv('ratings1.csv')\n",
    "ratings=pd.read_csv('ratings1.dat', sep='::', header=None, engine='python', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.columns=['userId','movieId', 'rating', 'timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838985046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>292</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1      122     5.0  838985046\n",
       "1       1      185     5.0  838983525\n",
       "2       1      231     5.0  838983392\n",
       "3       1      292     5.0  838983421\n",
       "4       1      316     5.0  838983392"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000054, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full dataset:\n",
      "number users 69878, number movies 10677\n"
     ]
    }
   ],
   "source": [
    "print(f\"full dataset:\\nnumber users {int(ratings.userId.nunique())}, number movies {int(ratings.movieId.nunique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_uniq = ratings.userId.unique()\n",
    "user2idx = {o:i for i,o in enumerate(u_uniq)}\n",
    "ratings.userId = ratings.userId.apply(lambda x: user2idx[x])\n",
    "\n",
    "m_uniq = ratings.movieId.unique()\n",
    "movie2idx = {o:i for i,o in enumerate(m_uniq)}\n",
    "ratings.movieId = ratings.movieId.apply(lambda x: movie2idx[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number users: 69878, number movies 10677\n"
     ]
    }
   ],
   "source": [
    "n_users=int(ratings.userId.nunique())\n",
    "n_movies=int(ratings.movieId.nunique())\n",
    "n_factors = 100\n",
    "print(f\"number users: {n_users}, number movies {n_movies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_rating,max_rating = ratings.rating.min(),ratings.rating.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = ratings.drop(['rating', 'timestamp'],axis=1)\n",
    "# y = ratings['rating'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId         int64\n",
       "movieId        int64\n",
       "rating       float64\n",
       "timestamp      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       0        0     5.0\n",
       "1       0        1     5.0\n",
       "2       0        2     5.0\n",
       "3       0        3     5.0\n",
       "4       0        4     5.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_final=ratings.drop(['timestamp'],axis=1)\n",
    "ratings_final=ratings_final.astype({\"rating\": np.float32})\n",
    "ratings_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPreprocessor(rating_df, num_users, num_items, init_value=0, average=False):\n",
    "    \"\"\"\n",
    "        INPUT: \n",
    "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating' ...]\n",
    "            num_row: int. number of users\n",
    "            num_col: int. number of items\n",
    "            \n",
    "        OUTPUT:\n",
    "            matrix: 2D numpy array. \n",
    "    \"\"\"\n",
    "    matrix = np.zeros((num_users, num_items),dtype='float32')\n",
    "    for (_, userID, itemID, rating) in rating_df.itertuples():\n",
    "        matrix[userID, itemID] = rating\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=dataPreprocessor(ratings_final, n_users,n_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_final=ratings_final.astype({\"rating\": np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 5., 5., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 3., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=pd.DataFrame(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>10667</th>\n",
       "      <th>10668</th>\n",
       "      <th>10669</th>\n",
       "      <th>10670</th>\n",
       "      <th>10671</th>\n",
       "      <th>10672</th>\n",
       "      <th>10673</th>\n",
       "      <th>10674</th>\n",
       "      <th>10675</th>\n",
       "      <th>10676</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10677 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0    5.0    5.0    5.0    5.0    5.0    5.0    5.0    5.0    5.0    5.0  ...   \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "3    0.0    0.0    1.0    3.0    5.0    5.0    0.0    0.0    0.0    5.0  ...   \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "\n",
       "   10667  10668  10669  10670  10671  10672  10673  10674  10675  10676  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 10677 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=new_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>69868</th>\n",
       "      <th>69869</th>\n",
       "      <th>69870</th>\n",
       "      <th>69871</th>\n",
       "      <th>69872</th>\n",
       "      <th>69873</th>\n",
       "      <th>69874</th>\n",
       "      <th>69875</th>\n",
       "      <th>69876</th>\n",
       "      <th>69877</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69878 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "1    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "2    5.0    0.0    0.0    1.0    0.0    0.0    0.0    3.0    0.0    0.0  ...   \n",
       "3    5.0    0.0    0.0    3.0    0.0    0.0    0.0    3.5    0.0    0.0  ...   \n",
       "4    5.0    0.0    0.0    5.0    0.0    0.0    0.0    4.5    0.0    0.0  ...   \n",
       "\n",
       "   69868  69869  69870  69871  69872  69873  69874  69875  69876  69877  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0    3.0    0.0  \n",
       "2    0.0    0.0    1.0    0.0    2.0    0.0    3.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    3.0    0.0    0.0    0.0    0.0    0.0    3.0    4.0  \n",
       "\n",
       "[5 rows x 69878 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_pickle('new_df_matrix.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'new_df_matrix.pkl', 'rb') as fh:\n",
    "    new_df = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datal= <torch.utils.data.dataloader.DataLoader object at 0x7f65582f4d90>\n"
     ]
    }
   ],
   "source": [
    "ae = AutoEncoder(new_df, validation_perc=0.1, lr=1e-3, intermediate_size=2000, encoded_size=100)\n",
    "#ae = AutoEncoder(tfidf, validation_perc=0.05, lr=1e-3, intermediate_size=5000, encoded_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "i= 50\n",
      "train loss: 0.31533483 | validation loss: 0.32790279\n",
      "i= 100\n",
      "train loss: 0.29060414 | validation loss: 0.31675267\n",
      "i= 150\n",
      "train loss: 0.34711674 | validation loss: 0.30342406\n",
      "Epoch 2/5\n",
      "i= 50\n",
      "train loss: 0.28460607 | validation loss: 0.29833099\n",
      "i= 100\n",
      "train loss: 0.27354485 | validation loss: 0.28637746\n",
      "i= 150\n",
      "train loss: 0.25272042 | validation loss: 0.27871877\n",
      "Epoch 3/5\n",
      "i= 50\n",
      "train loss: 0.3080444 | validation loss: 0.26546082\n",
      "i= 100\n",
      "train loss: 0.252058 | validation loss: 0.25940496\n",
      "i= 150\n",
      "train loss: 0.36840412 | validation loss: 0.25429341\n",
      "Epoch 4/5\n",
      "i= 50\n",
      "train loss: 0.21030338 | validation loss: 0.25191289\n",
      "i= 100\n",
      "train loss: 0.29700267 | validation loss: 0.23341557\n",
      "i= 150\n",
      "train loss: 0.27211711 | validation loss: 0.23083213\n",
      "Epoch 5/5\n",
      "i= 50\n",
      "train loss: 0.23966418 | validation loss: 0.23005028\n",
      "i= 100\n",
      "train loss: 0.19644442 | validation loss: 0.22073255\n",
      "i= 150\n",
      "train loss: 0.20634866 | validation loss: 0.21819027\n"
     ]
    }
   ],
   "source": [
    "ae.train_loop(epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/145\n",
      "i= 50\n",
      "train loss: 0.21082558 | validation loss: 0.21595867\n",
      "i= 100\n",
      "train loss: 0.17547941 | validation loss: 0.20887233\n",
      "i= 150\n",
      "train loss: 0.23984087 | validation loss: 0.20642887\n",
      "Epoch 2/145\n",
      "i= 50\n",
      "train loss: 0.19158444 | validation loss: 0.20432445\n",
      "i= 100\n",
      "train loss: 0.19663207 | validation loss: 0.19870204\n",
      "i= 150\n",
      "train loss: 0.18451618 | validation loss: 0.19773258\n",
      "Epoch 3/145\n",
      "i= 50\n",
      "train loss: 0.20915669 | validation loss: 0.19586404\n",
      "i= 100\n",
      "train loss: 0.25280908 | validation loss: 0.19592924\n",
      "i= 150\n",
      "train loss: 0.42553648 | validation loss: 0.1879916\n",
      "Epoch 4/145\n",
      "i= 50\n",
      "train loss: 0.1269905 | validation loss: 0.18401623\n",
      "i= 100\n",
      "train loss: 0.23024251 | validation loss: 0.18432909\n",
      "i= 150\n",
      "train loss: 0.29638201 | validation loss: 0.18092115\n",
      "Epoch 5/145\n",
      "i= 50\n",
      "train loss: 0.20750853 | validation loss: 0.17980367\n",
      "i= 100\n",
      "train loss: 0.23356582 | validation loss: 0.17861532\n",
      "i= 150\n",
      "train loss: 0.24769107 | validation loss: 0.17450313\n",
      "Epoch 6/145\n",
      "i= 50\n",
      "train loss: 0.16133972 | validation loss: 0.17600569\n",
      "i= 100\n",
      "train loss: 0.16370359 | validation loss: 0.17441386\n",
      "i= 150\n",
      "train loss: 0.22518487 | validation loss: 0.17262322\n",
      "Epoch 7/145\n",
      "i= 50\n",
      "train loss: 0.2539528 | validation loss: 0.17026918\n",
      "i= 100\n",
      "train loss: 0.12780707 | validation loss: 0.17114002\n",
      "i= 150\n",
      "train loss: 0.35420662 | validation loss: 0.16859844\n",
      "Epoch 8/145\n",
      "i= 50\n",
      "train loss: 0.11985437 | validation loss: 0.16681354\n",
      "i= 100\n",
      "train loss: 0.22660856 | validation loss: 0.16390151\n",
      "i= 150\n",
      "train loss: 0.26996166 | validation loss: 0.16563059\n",
      "Epoch 9/145\n",
      "i= 50\n",
      "train loss: 0.23100218 | validation loss: 0.16634485\n",
      "i= 100\n",
      "train loss: 0.13424803 | validation loss: 0.1665469\n",
      "i= 150\n",
      "train loss: 0.18671338 | validation loss: 0.16484243\n",
      "Epoch 10/145\n",
      "i= 50\n",
      "train loss: 0.12341484 | validation loss: 0.16447233\n",
      "i= 100\n",
      "train loss: 0.18838619 | validation loss: 0.16331814\n",
      "i= 150\n",
      "train loss: 0.22240445 | validation loss: 0.16538344\n",
      "Epoch 11/145\n",
      "i= 50\n",
      "train loss: 0.14285354 | validation loss: 0.16269618\n",
      "i= 100\n",
      "train loss: 0.25758699 | validation loss: 0.15816917\n",
      "i= 150\n",
      "train loss: 0.18273191 | validation loss: 0.16039003\n",
      "Epoch 12/145\n",
      "i= 50\n",
      "train loss: 0.20257446 | validation loss: 0.15745783\n",
      "i= 100\n",
      "train loss: 0.12187646 | validation loss: 0.15643069\n",
      "i= 150\n",
      "train loss: 0.30575988 | validation loss: 0.1545026\n",
      "Epoch 13/145\n",
      "i= 50\n",
      "train loss: 0.09415868 | validation loss: 0.15729266\n",
      "i= 100\n",
      "train loss: 0.26522869 | validation loss: 0.15688758\n",
      "i= 150\n",
      "train loss: 0.21447948 | validation loss: 0.15254106\n",
      "Epoch 14/145\n",
      "i= 50\n",
      "train loss: 0.2190316 | validation loss: 0.15463832\n",
      "i= 100\n",
      "train loss: 0.11854535 | validation loss: 0.1553362\n",
      "i= 150\n",
      "train loss: 0.19729212 | validation loss: 0.15454674\n",
      "Epoch 15/145\n",
      "i= 50\n",
      "train loss: 0.09952671 | validation loss: 0.15382916\n",
      "i= 100\n",
      "train loss: 0.15148284 | validation loss: 0.15309499\n",
      "i= 150\n",
      "train loss: 0.30328175 | validation loss: 0.15420727\n",
      "Epoch 16/145\n",
      "i= 50\n",
      "train loss: 0.10253542 | validation loss: 0.15284754\n",
      "i= 100\n",
      "train loss: 0.09371845 | validation loss: 0.15381368\n",
      "i= 150\n",
      "train loss: 0.16115156 | validation loss: 0.14937216\n",
      "Epoch 17/145\n",
      "i= 50\n",
      "train loss: 0.16101384 | validation loss: 0.15093604\n",
      "i= 100\n",
      "train loss: 0.18334767 | validation loss: 0.14999805\n",
      "i= 150\n",
      "train loss: 0.36287183 | validation loss: 0.15009998\n",
      "Epoch 18/145\n",
      "i= 50\n",
      "train loss: 0.12202271 | validation loss: 0.1504356\n",
      "i= 100\n",
      "train loss: 0.13879785 | validation loss: 0.14875606\n",
      "i= 150\n",
      "train loss: 0.20921743 | validation loss: 0.15004072\n",
      "Epoch 19/145\n",
      "i= 50\n",
      "train loss: 0.14040947 | validation loss: 0.1494455\n",
      "i= 100\n",
      "train loss: 0.12885815 | validation loss: 0.15009266\n",
      "i= 150\n",
      "train loss: 0.20585972 | validation loss: 0.14933385\n",
      "Epoch 20/145\n",
      "i= 50\n",
      "train loss: 0.10488924 | validation loss: 0.1489228\n",
      "i= 100\n",
      "train loss: 0.16803086 | validation loss: 0.14547172\n",
      "i= 150\n",
      "train loss: 0.16426069 | validation loss: 0.14853239\n",
      "Epoch 21/145\n",
      "i= 50\n",
      "train loss: 0.12801531 | validation loss: 0.14788522\n",
      "i= 100\n",
      "train loss: 0.10567656 | validation loss: 0.14698949\n",
      "i= 150\n",
      "train loss: 0.75008738 | validation loss: 0.14582764\n",
      "Epoch 22/145\n",
      "i= 50\n",
      "train loss: 0.16713074 | validation loss: 0.1473238\n",
      "i= 100\n",
      "train loss: 0.16092062 | validation loss: 0.14678882\n",
      "i= 150\n",
      "train loss: 0.14632489 | validation loss: 0.14539173\n",
      "Epoch 23/145\n",
      "i= 50\n",
      "train loss: 0.16181807 | validation loss: 0.14523748\n",
      "i= 100\n",
      "train loss: 0.13823229 | validation loss: 0.14561795\n",
      "i= 150\n",
      "train loss: 0.53307056 | validation loss: 0.1448905\n",
      "Epoch 24/145\n",
      "i= 50\n",
      "train loss: 0.1396085 | validation loss: 0.14648843\n",
      "i= 100\n",
      "train loss: 0.17914963 | validation loss: 0.1450927\n",
      "i= 150\n",
      "train loss: 0.14905901 | validation loss: 0.14632466\n",
      "Epoch 25/145\n",
      "i= 50\n",
      "train loss: 0.12416097 | validation loss: 0.14570734\n",
      "i= 100\n",
      "train loss: 0.22034532 | validation loss: 0.14431717\n",
      "i= 150\n",
      "train loss: 0.12754424 | validation loss: 0.14432524\n",
      "Epoch 26/145\n",
      "i= 50\n",
      "train loss: 0.13441746 | validation loss: 0.14399628\n",
      "i= 100\n",
      "train loss: 0.09863453 | validation loss: 0.14412728\n",
      "i= 150\n",
      "train loss: 0.38163075 | validation loss: 0.14561915\n",
      "Epoch 27/145\n",
      "i= 50\n",
      "train loss: 0.15098879 | validation loss: 0.14351493\n",
      "i= 100\n",
      "train loss: 0.13913076 | validation loss: 0.14392164\n",
      "i= 150\n",
      "train loss: 0.13920979 | validation loss: 0.14456114\n",
      "Epoch 28/145\n",
      "i= 50\n",
      "train loss: 0.11093884 | validation loss: 0.14386116\n",
      "i= 100\n",
      "train loss: 0.14368248 | validation loss: 0.143316\n",
      "i= 150\n",
      "train loss: 0.10663706 | validation loss: 0.14386174\n",
      "Epoch 29/145\n",
      "i= 50\n",
      "train loss: 0.09658621 | validation loss: 0.14621204\n",
      "i= 100\n",
      "train loss: 0.12542064 | validation loss: 0.14480589\n",
      "i= 150\n",
      "train loss: 0.20770968 | validation loss: 0.14452435\n",
      "Epoch 30/145\n",
      "i= 50\n",
      "train loss: 0.0968722 | validation loss: 0.14339745\n",
      "i= 100\n",
      "train loss: 0.1471848 | validation loss: 0.14620869\n",
      "i= 150\n",
      "train loss: 0.27093557 | validation loss: 0.14403079\n",
      "Epoch 31/145\n",
      "i= 50\n",
      "train loss: 0.1602927 | validation loss: 0.14435478\n",
      "i= 100\n",
      "train loss: 0.07352735 | validation loss: 0.14394026\n",
      "i= 150\n",
      "train loss: 0.10207538 | validation loss: 0.14285915\n",
      "Epoch 32/145\n",
      "i= 50\n",
      "train loss: 0.15045586 | validation loss: 0.14289887\n",
      "i= 100\n",
      "train loss: 0.12178882 | validation loss: 0.14274651\n",
      "i= 150\n",
      "train loss: 0.08917268 | validation loss: 0.14193891\n",
      "Epoch 33/145\n",
      "i= 50\n",
      "train loss: 0.21777116 | validation loss: 0.14176106\n",
      "i= 100\n",
      "train loss: 0.11174455 | validation loss: 0.14151965\n",
      "i= 150\n",
      "train loss: 0.05910134 | validation loss: 0.14223422\n",
      "Epoch 34/145\n",
      "i= 50\n",
      "train loss: 0.11091071 | validation loss: 0.1418322\n",
      "i= 100\n",
      "train loss: 0.08506698 | validation loss: 0.14088835\n",
      "i= 150\n",
      "train loss: 0.09673496 | validation loss: 0.14103161\n",
      "Epoch 35/145\n",
      "i= 50\n",
      "train loss: 0.21884839 | validation loss: 0.14076157\n",
      "i= 100\n",
      "train loss: 0.14872189 | validation loss: 0.14139357\n",
      "i= 150\n",
      "train loss: 0.15864314 | validation loss: 0.14070001\n",
      "Epoch 36/145\n",
      "i= 50\n",
      "train loss: 0.1475092 | validation loss: 0.14126582\n",
      "i= 100\n",
      "train loss: 0.14314334 | validation loss: 0.14047396\n",
      "i= 150\n",
      "train loss: 0.22221059 | validation loss: 0.14090951\n",
      "Epoch 37/145\n",
      "i= 50\n",
      "train loss: 0.15554139 | validation loss: 0.14043732\n",
      "i= 100\n",
      "train loss: 0.13868392 | validation loss: 0.14009283\n",
      "i= 150\n",
      "train loss: 0.2137389 | validation loss: 0.14045957\n",
      "Epoch 38/145\n",
      "i= 50\n",
      "train loss: 0.08593649 | validation loss: 0.14009844\n",
      "i= 100\n",
      "train loss: 0.19728838 | validation loss: 0.14036886\n",
      "i= 150\n",
      "train loss: 0.20163517 | validation loss: 0.13975751\n",
      "Epoch 39/145\n",
      "i= 50\n",
      "train loss: 0.1103579 | validation loss: 0.13945986\n",
      "i= 100\n",
      "train loss: 0.1260432 | validation loss: 0.13972691\n",
      "i= 150\n",
      "train loss: 0.10676863 | validation loss: 0.13965304\n",
      "Epoch 40/145\n",
      "i= 50\n",
      "train loss: 0.09064093 | validation loss: 0.13989873\n",
      "i= 100\n",
      "train loss: 0.12914297 | validation loss: 0.13952069\n",
      "i= 150\n",
      "train loss: 0.19494964 | validation loss: 0.13931805\n",
      "Epoch 41/145\n",
      "i= 50\n",
      "train loss: 0.08319317 | validation loss: 0.13983773\n",
      "i= 100\n",
      "train loss: 0.16494711 | validation loss: 0.13940643\n",
      "i= 150\n",
      "train loss: 0.08929486 | validation loss: 0.13968305\n",
      "Epoch 42/145\n",
      "i= 50\n",
      "train loss: 0.0774591 | validation loss: 0.13976842\n",
      "i= 100\n",
      "train loss: 0.09027069 | validation loss: 0.13931951\n",
      "i= 150\n",
      "train loss: 0.2461042 | validation loss: 0.13987653\n",
      "Epoch 43/145\n",
      "i= 50\n",
      "train loss: 0.17299691 | validation loss: 0.13932216\n",
      "i= 100\n",
      "train loss: 0.16833602 | validation loss: 0.13929243\n",
      "i= 150\n",
      "train loss: 0.11055803 | validation loss: 0.139888\n",
      "Epoch 44/145\n",
      "i= 50\n",
      "train loss: 0.20505702 | validation loss: 0.13912433\n",
      "i= 100\n",
      "train loss: 0.06620282 | validation loss: 0.13919431\n",
      "i= 150\n",
      "train loss: 0.08203675 | validation loss: 0.13933286\n",
      "Epoch 45/145\n",
      "i= 50\n",
      "train loss: 0.07540031 | validation loss: 0.13957003\n",
      "i= 100\n",
      "train loss: 0.14390412 | validation loss: 0.13894424\n",
      "i= 150\n",
      "train loss: 0.05115221 | validation loss: 0.13897188\n",
      "Epoch 46/145\n",
      "i= 50\n",
      "train loss: 0.15883197 | validation loss: 0.13938753\n",
      "i= 100\n",
      "train loss: 0.10785248 | validation loss: 0.13871028\n",
      "i= 150\n",
      "train loss: 0.08729888 | validation loss: 0.13925344\n",
      "Epoch 47/145\n",
      "i= 50\n",
      "train loss: 0.08443943 | validation loss: 0.13890769\n",
      "i= 100\n",
      "train loss: 0.09012675 | validation loss: 0.13998258\n",
      "i= 150\n",
      "train loss: 0.15389718 | validation loss: 0.13889897\n",
      "Epoch 48/145\n",
      "i= 50\n",
      "train loss: 0.16526295 | validation loss: 0.13939193\n",
      "i= 100\n",
      "train loss: 0.23223118 | validation loss: 0.13958056\n",
      "i= 150\n",
      "train loss: 0.21465854 | validation loss: 0.13899156\n",
      "Epoch 49/145\n",
      "i= 50\n",
      "train loss: 0.14775397 | validation loss: 0.13925895\n",
      "i= 100\n",
      "train loss: 0.14384148 | validation loss: 0.13979079\n",
      "i= 150\n",
      "train loss: 0.06313612 | validation loss: 0.13838679\n",
      "Epoch 50/145\n",
      "i= 50\n",
      "train loss: 0.08684495 | validation loss: 0.14019687\n",
      "i= 100\n",
      "train loss: 0.092083 | validation loss: 0.13894974\n",
      "i= 150\n",
      "train loss: 0.04702415 | validation loss: 0.13896029\n",
      "Epoch 51/145\n",
      "i= 50\n",
      "train loss: 0.07407254 | validation loss: 0.13930152\n",
      "i= 100\n",
      "train loss: 0.21200761 | validation loss: 0.13937104\n",
      "i= 150\n",
      "train loss: 0.07538017 | validation loss: 0.13949771\n",
      "Epoch 52/145\n",
      "i= 50\n",
      "train loss: 0.10042283 | validation loss: 0.13884227\n",
      "i= 100\n",
      "train loss: 0.1521074 | validation loss: 0.13966048\n",
      "i= 150\n",
      "train loss: 0.11365537 | validation loss: 0.13924712\n",
      "Epoch 53/145\n",
      "i= 50\n",
      "train loss: 0.1155599 | validation loss: 0.13923454\n",
      "i= 100\n",
      "train loss: 0.17839949 | validation loss: 0.13896738\n",
      "i= 150\n",
      "train loss: 0.20852271 | validation loss: 0.13923851\n",
      "Epoch 54/145\n",
      "i= 50\n",
      "train loss: 0.11014643 | validation loss: 0.13902971\n",
      "i= 100\n",
      "train loss: 0.18627219 | validation loss: 0.13923103\n",
      "i= 150\n",
      "train loss: 0.31871867 | validation loss: 0.14090607\n",
      "Epoch 55/145\n",
      "i= 50\n",
      "train loss: 0.16594963 | validation loss: 0.13954586\n",
      "i= 100\n",
      "train loss: 0.10864372 | validation loss: 0.13968194\n",
      "i= 150\n",
      "train loss: 0.33052891 | validation loss: 0.13953999\n",
      "Epoch 56/145\n",
      "i= 50\n",
      "train loss: 0.08721653 | validation loss: 0.13917062\n",
      "i= 100\n",
      "train loss: 0.09991993 | validation loss: 0.13902351\n",
      "i= 150\n",
      "train loss: 0.1043522 | validation loss: 0.13900784\n",
      "Epoch 57/145\n",
      "i= 50\n",
      "train loss: 0.11394053 | validation loss: 0.1393659\n",
      "i= 100\n",
      "train loss: 0.08197039 | validation loss: 0.13949229\n",
      "i= 150\n",
      "train loss: 0.030007 | validation loss: 0.13945951\n",
      "Epoch 58/145\n",
      "i= 50\n",
      "train loss: 0.1322618 | validation loss: 0.1395544\n",
      "i= 100\n",
      "train loss: 0.17016719 | validation loss: 0.13939141\n",
      "i= 150\n",
      "train loss: 0.05572441 | validation loss: 0.1390432\n",
      "Epoch 59/145\n",
      "i= 50\n",
      "train loss: 0.10002293 | validation loss: 0.13949305\n",
      "i= 100\n",
      "train loss: 0.16600497 | validation loss: 0.13972957\n",
      "i= 150\n",
      "train loss: 0.04003294 | validation loss: 0.13901635\n",
      "Epoch 60/145\n",
      "i= 50\n",
      "train loss: 0.09320731 | validation loss: 0.13966066\n",
      "i= 100\n",
      "train loss: 0.16440336 | validation loss: 0.13970467\n",
      "i= 150\n",
      "train loss: 0.71143299 | validation loss: 0.14343289\n",
      "Epoch 61/145\n",
      "i= 50\n",
      "train loss: 0.16273454 | validation loss: 0.13919272\n",
      "i= 100\n",
      "train loss: 0.24798276 | validation loss: 0.140571\n",
      "i= 150\n",
      "train loss: 0.04748518 | validation loss: 0.13942528\n",
      "Epoch 62/145\n",
      "i= 50\n",
      "train loss: 0.15132403 | validation loss: 0.1401176\n",
      "i= 100\n",
      "train loss: 0.20682192 | validation loss: 0.13962375\n",
      "i= 150\n",
      "train loss: 0.15412633 | validation loss: 0.1401445\n",
      "Epoch 63/145\n",
      "i= 50\n",
      "train loss: 0.09852996 | validation loss: 0.13985218\n",
      "i= 100\n",
      "train loss: 0.08176097 | validation loss: 0.1393737\n",
      "i= 150\n",
      "train loss: 0.05435719 | validation loss: 0.13907538\n",
      "Epoch 64/145\n",
      "i= 50\n",
      "train loss: 0.11035062 | validation loss: 0.13959411\n",
      "i= 100\n",
      "train loss: 0.06580283 | validation loss: 0.14039266\n",
      "i= 150\n",
      "train loss: 0.10918897 | validation loss: 0.1396444\n",
      "Epoch 65/145\n",
      "i= 50\n",
      "train loss: 0.1228203 | validation loss: 0.14010938\n",
      "i= 100\n",
      "train loss: 0.10560821 | validation loss: 0.13891007\n",
      "i= 150\n",
      "train loss: 0.05764038 | validation loss: 0.14004605\n",
      "Epoch 66/145\n",
      "i= 50\n",
      "train loss: 0.15292224 | validation loss: 0.14050965\n",
      "i= 100\n",
      "train loss: 0.18761067 | validation loss: 0.1400066\n",
      "i= 150\n",
      "train loss: 0.44698974 | validation loss: 0.14187789\n",
      "Epoch 67/145\n",
      "i= 50\n",
      "train loss: 0.17206769 | validation loss: 0.14012235\n",
      "i= 100\n",
      "train loss: 0.08326899 | validation loss: 0.13993013\n",
      "i= 150\n",
      "train loss: 0.07068572 | validation loss: 0.13925342\n",
      "Epoch 68/145\n",
      "i= 50\n",
      "train loss: 0.09109477 | validation loss: 0.14034326\n",
      "i= 100\n",
      "train loss: 0.20431678 | validation loss: 0.13971807\n",
      "i= 150\n",
      "train loss: 0.05886525 | validation loss: 0.14073098\n",
      "Epoch 69/145\n",
      "i= 50\n",
      "train loss: 0.11219155 | validation loss: 0.14028959\n",
      "i= 100\n",
      "train loss: 0.18063244 | validation loss: 0.14054191\n",
      "i= 150\n",
      "train loss: 0.04844262 | validation loss: 0.13958853\n",
      "Epoch 70/145\n",
      "i= 50\n",
      "train loss: 0.09964342 | validation loss: 0.13994773\n",
      "i= 100\n",
      "train loss: 0.16334945 | validation loss: 0.14057899\n",
      "i= 150\n",
      "train loss: 0.03992156 | validation loss: 0.13974352\n",
      "Epoch 71/145\n",
      "i= 50\n",
      "train loss: 0.14129752 | validation loss: 0.14018978\n",
      "i= 100\n",
      "train loss: 0.06860169 | validation loss: 0.13999116\n",
      "i= 150\n",
      "train loss: 0.11381922 | validation loss: 0.13979702\n",
      "Epoch 72/145\n",
      "i= 50\n",
      "train loss: 0.09027742 | validation loss: 0.13981554\n",
      "i= 100\n",
      "train loss: 0.10095 | validation loss: 0.14027381\n",
      "i= 150\n",
      "train loss: 0.06393626 | validation loss: 0.14106536\n",
      "Epoch 73/145\n",
      "i= 50\n",
      "train loss: 0.15337108 | validation loss: 0.14058764\n",
      "i= 100\n",
      "train loss: 0.13162301 | validation loss: 0.13963473\n",
      "i= 150\n",
      "train loss: 0.17564444 | validation loss: 0.14018875\n",
      "Epoch 74/145\n",
      "i= 50\n",
      "train loss: 0.06806888 | validation loss: 0.14136711\n",
      "i= 100\n",
      "train loss: 0.14619081 | validation loss: 0.14147694\n",
      "i= 150\n",
      "train loss: 0.17464963 | validation loss: 0.14072533\n",
      "Epoch 75/145\n",
      "i= 50\n",
      "train loss: 0.10571495 | validation loss: 0.14052716\n",
      "i= 100\n",
      "train loss: 0.11816568 | validation loss: 0.14004292\n",
      "i= 150\n",
      "train loss: 0.26014897 | validation loss: 0.14136015\n",
      "Epoch 76/145\n",
      "i= 50\n",
      "train loss: 0.09834716 | validation loss: 0.14068855\n",
      "i= 100\n",
      "train loss: 0.23893727 | validation loss: 0.14084381\n",
      "i= 150\n",
      "train loss: 0.08601388 | validation loss: 0.14113928\n",
      "Epoch 77/145\n",
      "i= 50\n",
      "train loss: 0.11686325 | validation loss: 0.14080614\n",
      "i= 100\n",
      "train loss: 0.07913358 | validation loss: 0.14011838\n",
      "i= 150\n",
      "train loss: 0.12115104 | validation loss: 0.14094584\n",
      "Epoch 78/145\n",
      "i= 50\n",
      "train loss: 0.12410786 | validation loss: 0.1404389\n",
      "i= 100\n",
      "train loss: 0.13819347 | validation loss: 0.1395438\n",
      "i= 150\n",
      "train loss: 0.04471595 | validation loss: 0.14095601\n",
      "Epoch 79/145\n",
      "i= 50\n",
      "train loss: 0.10739075 | validation loss: 0.14126201\n",
      "i= 100\n",
      "train loss: 0.06428892 | validation loss: 0.14093073\n",
      "i= 150\n",
      "train loss: 0.04650059 | validation loss: 0.14081037\n",
      "Epoch 80/145\n",
      "i= 50\n",
      "train loss: 0.08380294 | validation loss: 0.14039159\n",
      "i= 100\n",
      "train loss: 0.129338 | validation loss: 0.14039485\n",
      "i= 150\n",
      "train loss: 0.30438006 | validation loss: 0.14047046\n",
      "Epoch 81/145\n",
      "i= 50\n",
      "train loss: 0.08264735 | validation loss: 0.14131264\n",
      "i= 100\n",
      "train loss: 0.14746991 | validation loss: 0.14036651\n",
      "i= 150\n",
      "train loss: 0.0580608 | validation loss: 0.14152481\n",
      "Epoch 82/145\n",
      "i= 50\n",
      "train loss: 0.10520755 | validation loss: 0.14128421\n",
      "i= 100\n",
      "train loss: 0.09735871 | validation loss: 0.14062724\n",
      "i= 150\n",
      "train loss: 0.03580872 | validation loss: 0.14237379\n",
      "Epoch 83/145\n",
      "i= 50\n",
      "train loss: 0.06407362 | validation loss: 0.14033543\n",
      "i= 100\n",
      "train loss: 0.15020514 | validation loss: 0.14170229\n",
      "i= 150\n",
      "train loss: 0.0848899 | validation loss: 0.14017488\n",
      "Epoch 84/145\n",
      "i= 50\n",
      "train loss: 0.10398033 | validation loss: 0.14063893\n",
      "i= 100\n",
      "train loss: 0.08954355 | validation loss: 0.1413386\n",
      "i= 150\n",
      "train loss: 0.06030927 | validation loss: 0.14154194\n",
      "Epoch 85/145\n",
      "i= 50\n",
      "train loss: 0.13188751 | validation loss: 0.1404863\n",
      "i= 100\n",
      "train loss: 0.1342259 | validation loss: 0.14180684\n",
      "i= 150\n",
      "train loss: 0.10991589 | validation loss: 0.14131148\n",
      "Epoch 86/145\n",
      "i= 50\n",
      "train loss: 0.32947376 | validation loss: 0.14186904\n",
      "i= 100\n",
      "train loss: 0.07590821 | validation loss: 0.14031021\n",
      "i= 150\n",
      "train loss: 0.16182876 | validation loss: 0.14178249\n",
      "Epoch 87/145\n",
      "i= 50\n",
      "train loss: 0.22309278 | validation loss: 0.14155425\n",
      "i= 100\n",
      "train loss: 0.11347932 | validation loss: 0.14173296\n",
      "i= 150\n",
      "train loss: 0.24939327 | validation loss: 0.14135769\n",
      "Epoch 88/145\n",
      "i= 50\n",
      "train loss: 0.13647212 | validation loss: 0.14088267\n",
      "i= 100\n",
      "train loss: 0.15845729 | validation loss: 0.14043888\n",
      "i= 150\n",
      "train loss: 0.05247885 | validation loss: 0.14153273\n",
      "Epoch 89/145\n",
      "i= 50\n",
      "train loss: 0.15113468 | validation loss: 0.14199933\n",
      "i= 100\n",
      "train loss: 0.06353438 | validation loss: 0.14120607\n",
      "i= 150\n",
      "train loss: 0.20933251 | validation loss: 0.14156008\n",
      "Epoch 90/145\n",
      "i= 50\n",
      "train loss: 0.15521659 | validation loss: 0.14193042\n",
      "i= 100\n",
      "train loss: 0.13263911 | validation loss: 0.1412928\n",
      "i= 150\n",
      "train loss: 0.24899498 | validation loss: 0.14417109\n",
      "Epoch 91/145\n",
      "i= 50\n",
      "train loss: 0.12376453 | validation loss: 0.14099368\n",
      "i= 100\n",
      "train loss: 0.08343667 | validation loss: 0.14037061\n",
      "i= 150\n",
      "train loss: 0.0896176 | validation loss: 0.14197792\n",
      "Epoch 92/145\n",
      "i= 50\n",
      "train loss: 0.18788473 | validation loss: 0.14139315\n",
      "i= 100\n",
      "train loss: 0.10611811 | validation loss: 0.14090721\n",
      "i= 150\n",
      "train loss: 0.03714171 | validation loss: 0.14099725\n",
      "Epoch 93/145\n",
      "i= 50\n",
      "train loss: 0.08918442 | validation loss: 0.14059786\n",
      "i= 100\n",
      "train loss: 0.07686011 | validation loss: 0.1420878\n",
      "i= 150\n",
      "train loss: 0.06551311 | validation loss: 0.14239025\n",
      "Epoch 94/145\n",
      "i= 50\n",
      "train loss: 0.17894559 | validation loss: 0.14170383\n",
      "i= 100\n",
      "train loss: 0.10740542 | validation loss: 0.14254031\n",
      "i= 150\n",
      "train loss: 0.18383604 | validation loss: 0.14125404\n",
      "Epoch 95/145\n",
      "i= 50\n",
      "train loss: 0.10439206 | validation loss: 0.14154658\n",
      "i= 100\n",
      "train loss: 0.06972628 | validation loss: 0.14133556\n",
      "i= 150\n",
      "train loss: 0.24393874 | validation loss: 0.14336848\n",
      "Epoch 96/145\n",
      "i= 50\n",
      "train loss: 0.10121097 | validation loss: 0.1413707\n",
      "i= 100\n",
      "train loss: 0.07003938 | validation loss: 0.14163582\n",
      "i= 150\n",
      "train loss: 0.0440169 | validation loss: 0.14140597\n",
      "Epoch 97/145\n",
      "i= 50\n",
      "train loss: 0.060126 | validation loss: 0.14147812\n",
      "i= 100\n",
      "train loss: 0.07985435 | validation loss: 0.14131235\n",
      "i= 150\n",
      "train loss: 0.50949538 | validation loss: 0.14445613\n",
      "Epoch 98/145\n",
      "i= 50\n",
      "train loss: 0.11474989 | validation loss: 0.1409492\n",
      "i= 100\n",
      "train loss: 0.14923273 | validation loss: 0.14194088\n",
      "i= 150\n",
      "train loss: 0.03652956 | validation loss: 0.14267719\n",
      "Epoch 99/145\n",
      "i= 50\n",
      "train loss: 0.08089593 | validation loss: 0.14107716\n",
      "i= 100\n",
      "train loss: 0.08050581 | validation loss: 0.1421129\n",
      "i= 150\n",
      "train loss: 0.75830781 | validation loss: 0.14653109\n",
      "Epoch 100/145\n",
      "i= 50\n",
      "train loss: 0.05271792 | validation loss: 0.14271215\n",
      "i= 100\n",
      "train loss: 0.10464314 | validation loss: 0.14100602\n",
      "i= 150\n",
      "train loss: 0.20228602 | validation loss: 0.14233601\n",
      "Epoch 101/145\n",
      "i= 50\n",
      "train loss: 0.16620663 | validation loss: 0.14212085\n",
      "i= 100\n",
      "train loss: 0.06891138 | validation loss: 0.14081673\n",
      "i= 150\n",
      "train loss: 0.05145359 | validation loss: 0.14225116\n",
      "Epoch 102/145\n",
      "i= 50\n",
      "train loss: 0.10704815 | validation loss: 0.14195862\n",
      "i= 100\n",
      "train loss: 0.10073089 | validation loss: 0.14218843\n",
      "i= 150\n",
      "train loss: 0.06495495 | validation loss: 0.14141795\n",
      "Epoch 103/145\n",
      "i= 50\n",
      "train loss: 0.08111689 | validation loss: 0.14167228\n",
      "i= 100\n",
      "train loss: 0.1503188 | validation loss: 0.14219105\n",
      "i= 150\n",
      "train loss: 0.19796154 | validation loss: 0.1413493\n",
      "Epoch 104/145\n",
      "i= 50\n",
      "train loss: 0.17614409 | validation loss: 0.14217265\n",
      "i= 100\n",
      "train loss: 0.19307528 | validation loss: 0.14237735\n",
      "i= 150\n",
      "train loss: 0.19597562 | validation loss: 0.142215\n",
      "Epoch 105/145\n",
      "i= 50\n",
      "train loss: 0.16765469 | validation loss: 0.1416893\n",
      "i= 100\n",
      "train loss: 0.11756353 | validation loss: 0.14119849\n",
      "i= 150\n",
      "train loss: 0.07476624 | validation loss: 0.14141004\n",
      "Epoch 106/145\n",
      "i= 50\n",
      "train loss: 0.08946688 | validation loss: 0.1417876\n",
      "i= 100\n",
      "train loss: 0.11213929 | validation loss: 0.14079736\n",
      "i= 150\n",
      "train loss: 0.06111036 | validation loss: 0.14349303\n",
      "Epoch 107/145\n",
      "i= 50\n",
      "train loss: 0.17303553 | validation loss: 0.14130302\n",
      "i= 100\n",
      "train loss: 0.09893867 | validation loss: 0.14165354\n",
      "i= 150\n",
      "train loss: 0.17230134 | validation loss: 0.14186658\n",
      "Epoch 108/145\n",
      "i= 50\n",
      "train loss: 0.10884354 | validation loss: 0.14195576\n",
      "i= 100\n",
      "train loss: 0.08800888 | validation loss: 0.14182352\n",
      "i= 150\n",
      "train loss: 0.37252778 | validation loss: 0.14609356\n",
      "Epoch 109/145\n",
      "i= 50\n",
      "train loss: 0.19250722 | validation loss: 0.14379047\n",
      "i= 100\n",
      "train loss: 0.08143084 | validation loss: 0.14177555\n",
      "i= 150\n",
      "train loss: 0.35207683 | validation loss: 0.14689104\n",
      "Epoch 110/145\n",
      "i= 50\n",
      "train loss: 0.134911 | validation loss: 0.141688\n",
      "i= 100\n",
      "train loss: 0.08362912 | validation loss: 0.14138757\n",
      "i= 150\n",
      "train loss: 0.18338665 | validation loss: 0.14360461\n",
      "Epoch 111/145\n",
      "i= 50\n",
      "train loss: 0.11707669 | validation loss: 0.14157431\n",
      "i= 100\n",
      "train loss: 0.1033383 | validation loss: 0.14245088\n",
      "i= 150\n",
      "train loss: 0.07835609 | validation loss: 0.14214653\n",
      "Epoch 112/145\n",
      "i= 50\n",
      "train loss: 0.06114116 | validation loss: 0.14291212\n",
      "i= 100\n",
      "train loss: 0.08849724 | validation loss: 0.14183241\n",
      "i= 150\n",
      "train loss: 0.03843215 | validation loss: 0.14413889\n",
      "Epoch 113/145\n",
      "i= 50\n",
      "train loss: 0.12863943 | validation loss: 0.14192383\n",
      "i= 100\n",
      "train loss: 0.09579539 | validation loss: 0.14204496\n",
      "i= 150\n",
      "train loss: 0.09742419 | validation loss: 0.14213429\n",
      "Epoch 114/145\n",
      "i= 50\n",
      "train loss: 0.12295789 | validation loss: 0.14197989\n",
      "i= 100\n",
      "train loss: 0.06441381 | validation loss: 0.14255248\n",
      "i= 150\n",
      "train loss: 0.08169944 | validation loss: 0.14289311\n",
      "Epoch 115/145\n",
      "i= 50\n",
      "train loss: 0.06419551 | validation loss: 0.14173368\n",
      "i= 100\n",
      "train loss: 0.08292275 | validation loss: 0.14163159\n",
      "i= 150\n",
      "train loss: 0.21970761 | validation loss: 0.1433046\n",
      "Epoch 116/145\n",
      "i= 50\n",
      "train loss: 0.13456327 | validation loss: 0.14285184\n",
      "i= 100\n",
      "train loss: 0.12401102 | validation loss: 0.14278971\n",
      "i= 150\n",
      "train loss: 0.04694095 | validation loss: 0.14403318\n",
      "Epoch 117/145\n",
      "i= 50\n",
      "train loss: 0.13989688 | validation loss: 0.14245155\n",
      "i= 100\n",
      "train loss: 0.12381624 | validation loss: 0.14215219\n",
      "i= 150\n",
      "train loss: 0.13419349 | validation loss: 0.14189023\n",
      "Epoch 118/145\n",
      "i= 50\n",
      "train loss: 0.13983218 | validation loss: 0.14244321\n",
      "i= 100\n",
      "train loss: 0.08726667 | validation loss: 0.14144431\n",
      "i= 150\n",
      "train loss: 0.16995396 | validation loss: 0.14258429\n",
      "Epoch 119/145\n",
      "i= 50\n",
      "train loss: 0.1616368 | validation loss: 0.1423557\n",
      "i= 100\n",
      "train loss: 0.1324548 | validation loss: 0.14241496\n",
      "i= 150\n",
      "train loss: 0.04606331 | validation loss: 0.14379466\n",
      "Epoch 120/145\n",
      "i= 50\n",
      "train loss: 0.13124244 | validation loss: 0.14184347\n",
      "i= 100\n",
      "train loss: 0.15939792 | validation loss: 0.14282429\n",
      "i= 150\n",
      "train loss: 0.21756546 | validation loss: 0.1431518\n",
      "Epoch 121/145\n",
      "i= 50\n",
      "train loss: 0.14460793 | validation loss: 0.14256221\n",
      "i= 100\n",
      "train loss: 0.06649653 | validation loss: 0.14274554\n",
      "i= 150\n",
      "train loss: 0.03476783 | validation loss: 0.14653331\n",
      "Epoch 122/145\n",
      "i= 50\n",
      "train loss: 0.1053546 | validation loss: 0.14292511\n",
      "i= 100\n",
      "train loss: 0.10333445 | validation loss: 0.14226116\n",
      "i= 150\n",
      "train loss: 0.35788971 | validation loss: 0.14522025\n",
      "Epoch 123/145\n",
      "i= 50\n",
      "train loss: 0.12347817 | validation loss: 0.14335164\n",
      "i= 100\n",
      "train loss: 0.09428673 | validation loss: 0.14228565\n",
      "i= 150\n",
      "train loss: 0.05207154 | validation loss: 0.14492573\n",
      "Epoch 124/145\n",
      "i= 50\n",
      "train loss: 0.22910146 | validation loss: 0.14295536\n",
      "i= 100\n",
      "train loss: 0.10132524 | validation loss: 0.1428958\n",
      "i= 150\n",
      "train loss: 0.217832 | validation loss: 0.14407001\n",
      "Epoch 125/145\n",
      "i= 50\n",
      "train loss: 0.23035774 | validation loss: 0.14243847\n",
      "i= 100\n",
      "train loss: 0.06990361 | validation loss: 0.14189559\n",
      "i= 150\n",
      "train loss: 0.03127472 | validation loss: 0.14226238\n",
      "Epoch 126/145\n",
      "i= 50\n",
      "train loss: 0.16523512 | validation loss: 0.14295933\n",
      "i= 100\n",
      "train loss: 0.05627523 | validation loss: 0.14237198\n",
      "i= 150\n",
      "train loss: 0.04944682 | validation loss: 0.14425896\n",
      "Epoch 127/145\n",
      "i= 50\n",
      "train loss: 0.15165243 | validation loss: 0.14278847\n",
      "i= 100\n",
      "train loss: 0.13119291 | validation loss: 0.14251983\n",
      "i= 150\n",
      "train loss: 0.06993335 | validation loss: 0.14275526\n",
      "Epoch 128/145\n",
      "i= 50\n",
      "train loss: 0.10061773 | validation loss: 0.14434101\n",
      "i= 100\n",
      "train loss: 0.13943788 | validation loss: 0.14199424\n",
      "i= 150\n",
      "train loss: 0.03571618 | validation loss: 0.14619863\n",
      "Epoch 129/145\n",
      "i= 50\n",
      "train loss: 0.07842995 | validation loss: 0.14250295\n",
      "i= 100\n",
      "train loss: 0.12378896 | validation loss: 0.14255704\n",
      "i= 150\n",
      "train loss: 0.61406469 | validation loss: 0.14977115\n",
      "Epoch 130/145\n",
      "i= 50\n",
      "train loss: 0.11496948 | validation loss: 0.14232409\n",
      "i= 100\n",
      "train loss: 0.1290711 | validation loss: 0.14290002\n",
      "i= 150\n",
      "train loss: 0.15575136 | validation loss: 0.14446558\n",
      "Epoch 131/145\n",
      "i= 50\n",
      "train loss: 0.13904715 | validation loss: 0.14183855\n",
      "i= 100\n",
      "train loss: 0.20275921 | validation loss: 0.14333153\n",
      "i= 150\n",
      "train loss: 0.14748196 | validation loss: 0.14299677\n",
      "Epoch 132/145\n",
      "i= 50\n",
      "train loss: 0.15059562 | validation loss: 0.14202006\n",
      "i= 100\n",
      "train loss: 0.1335308 | validation loss: 0.1423036\n",
      "i= 150\n",
      "train loss: 0.12184564 | validation loss: 0.143507\n",
      "Epoch 133/145\n",
      "i= 50\n",
      "train loss: 0.10417336 | validation loss: 0.14307375\n",
      "i= 100\n",
      "train loss: 0.16468801 | validation loss: 0.14453799\n",
      "i= 150\n",
      "train loss: 0.17584157 | validation loss: 0.14343752\n",
      "Epoch 134/145\n",
      "i= 50\n",
      "train loss: 0.13166539 | validation loss: 0.14194557\n",
      "i= 100\n",
      "train loss: 0.10307246 | validation loss: 0.14349106\n",
      "i= 150\n",
      "train loss: 0.07680885 | validation loss: 0.14135294\n",
      "Epoch 135/145\n",
      "i= 50\n",
      "train loss: 0.18779249 | validation loss: 0.14374723\n",
      "i= 100\n",
      "train loss: 0.1076143 | validation loss: 0.14365892\n",
      "i= 150\n",
      "train loss: 0.26423651 | validation loss: 0.14306386\n",
      "Epoch 136/145\n",
      "i= 50\n",
      "train loss: 0.1063659 | validation loss: 0.14280555\n",
      "i= 100\n",
      "train loss: 0.06916696 | validation loss: 0.14323424\n",
      "i= 150\n",
      "train loss: 0.06885133 | validation loss: 0.14400254\n",
      "Epoch 137/145\n",
      "i= 50\n",
      "train loss: 0.10712656 | validation loss: 0.14217603\n",
      "i= 100\n",
      "train loss: 0.07772824 | validation loss: 0.14255616\n",
      "i= 150\n",
      "train loss: 0.14748903 | validation loss: 0.14473449\n",
      "Epoch 138/145\n",
      "i= 50\n",
      "train loss: 0.10969724 | validation loss: 0.14277998\n",
      "i= 100\n",
      "train loss: 0.07785194 | validation loss: 0.14237572\n",
      "i= 150\n",
      "train loss: 0.06641004 | validation loss: 0.14459591\n",
      "Epoch 139/145\n",
      "i= 50\n",
      "train loss: 0.18309203 | validation loss: 0.14261684\n",
      "i= 100\n",
      "train loss: 0.17656364 | validation loss: 0.14225341\n",
      "i= 150\n",
      "train loss: 0.16044387 | validation loss: 0.14378628\n",
      "Epoch 140/145\n",
      "i= 50\n",
      "train loss: 0.10738454 | validation loss: 0.14328447\n",
      "i= 100\n",
      "train loss: 0.09920794 | validation loss: 0.14349096\n",
      "i= 150\n",
      "train loss: 0.09893334 | validation loss: 0.14330976\n",
      "Epoch 141/145\n",
      "i= 50\n",
      "train loss: 0.12854135 | validation loss: 0.14258932\n",
      "i= 100\n",
      "train loss: 0.09151123 | validation loss: 0.14290439\n",
      "i= 150\n",
      "train loss: 0.10035889 | validation loss: 0.14640947\n",
      "Epoch 142/145\n",
      "i= 50\n",
      "train loss: 0.12162983 | validation loss: 0.1433589\n",
      "i= 100\n",
      "train loss: 0.0816654 | validation loss: 0.14329743\n",
      "i= 150\n",
      "train loss: 0.24816549 | validation loss: 0.1453522\n",
      "Epoch 143/145\n",
      "i= 50\n",
      "train loss: 0.1698336 | validation loss: 0.14248385\n",
      "i= 100\n",
      "train loss: 0.10085943 | validation loss: 0.14340848\n",
      "i= 150\n",
      "train loss: 0.1321907 | validation loss: 0.14384021\n",
      "Epoch 144/145\n",
      "i= 50\n",
      "train loss: 0.28044873 | validation loss: 0.14559984\n",
      "i= 100\n",
      "train loss: 0.0630496 | validation loss: 0.14276262\n",
      "i= 150\n",
      "train loss: 0.12537943 | validation loss: 0.14523578\n",
      "Epoch 145/145\n",
      "i= 50\n",
      "train loss: 0.12000867 | validation loss: 0.14277959\n",
      "i= 100\n",
      "train loss: 0.14465901 | validation loss: 0.14340402\n",
      "i= 150\n",
      "train loss: 0.64855027 | validation loss: 0.1466331\n"
     ]
    }
   ],
   "source": [
    "ae.train_loop(epochs=145)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae.train_loop(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae.train_loop(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae1 = AutoEncoder(new_df, validation_perc=0.1, lr=1e-3, intermediate_size=1000, encoded_size=100)\n",
    "#ae1.train_loop(epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('autoencodercoll_embeddings.pkl', 'wb') as fh:\n",
    "    pickle.dump(encoded, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>4973</td>\n",
       "      <td>excellent!</td>\n",
       "      <td>1215184630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>1747</td>\n",
       "      <td>politics</td>\n",
       "      <td>1188263867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>1747</td>\n",
       "      <td>satire</td>\n",
       "      <td>1188263867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>2424</td>\n",
       "      <td>chick flick 212</td>\n",
       "      <td>1188263835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>2424</td>\n",
       "      <td>hanks</td>\n",
       "      <td>1188263835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId              tag   timestamp\n",
       "0      15     4973       excellent!  1215184630\n",
       "1      20     1747         politics  1188263867\n",
       "2      20     1747           satire  1188263867\n",
       "3      20     2424  chick flick 212  1188263835\n",
       "4      20     2424            hanks  1188263835"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = pd.read_csv('tags.dat',sep='::', header=None, engine='python', encoding='latin-1')\n",
    "tags.columns=['userId','movieId','tag','timestamp']\n",
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>4973</td>\n",
       "      <td>excellent!</td>\n",
       "      <td>1215184630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>1747</td>\n",
       "      <td>politics</td>\n",
       "      <td>1188263867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>1747</td>\n",
       "      <td>satire</td>\n",
       "      <td>1188263867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>2424</td>\n",
       "      <td>chick flick 212</td>\n",
       "      <td>1188263835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>2424</td>\n",
       "      <td>hanks</td>\n",
       "      <td>1188263835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId              tag   timestamp\n",
       "0      15     4973       excellent!  1215184630\n",
       "1      20     1747         politics  1188263867\n",
       "2      20     1747           satire  1188263867\n",
       "3      20     2424  chick flick 212  1188263835\n",
       "4      20     2424            hanks  1188263835"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = pd.read_csv('tags.dat',sep='::', header=None, engine='python', encoding='latin-1')\n",
    "tags.columns=['userId','movieId','tag','timestamp']\n",
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7601 unique movies in tags.csv\n",
      "the tags data has (95580, 4) shape\n",
      "10677 unique movies in ratings.csv\n"
     ]
    }
   ],
   "source": [
    "#tags = pd.read_csv('tags.dat',sep='::', header=None, engine='python', encoding='latin-1')\n",
    "#tags.columns=['userId_x','movieId','tag','timestamp_x','userId_y','rating','timestamp_y']\n",
    "print(\"{} unique movies in tags.csv\".format(len(tags.movieId.unique())))\n",
    "print(\"the tags data has {} shape\".format(tags.shape))\n",
    "ratings = pd.read_csv(\"ratings1.dat\", sep='::', header=None, engine='python', encoding='latin-1')\n",
    "ratings.columns=['userId','movieId', 'rating', 'timestamp']\n",
    "ratings = ratings.drop_duplicates('movieId')\n",
    "print(\"{} unique movies in ratings.csv\".format(len(ratings.movieId.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_uniq = ratings.movieId.unique()\n",
    "movie2idx = {o:i for i,o in enumerate(m_uniq)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10677 unique movies in tags.csv\n",
      "(98630, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId_x</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp_x</th>\n",
       "      <th>userId_y</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1926</td>\n",
       "      <td>excellent!</td>\n",
       "      <td>1.215185e+09</td>\n",
       "      <td>38</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1162149051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146.0</td>\n",
       "      <td>1926</td>\n",
       "      <td>surreal</td>\n",
       "      <td>1.193705e+09</td>\n",
       "      <td>38</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1162149051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1751.0</td>\n",
       "      <td>1926</td>\n",
       "      <td>Jeunet</td>\n",
       "      <td>1.137525e+09</td>\n",
       "      <td>38</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1162149051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2456.0</td>\n",
       "      <td>1926</td>\n",
       "      <td>Paris</td>\n",
       "      <td>1.163102e+09</td>\n",
       "      <td>38</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1162149051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2456.0</td>\n",
       "      <td>1926</td>\n",
       "      <td>romance</td>\n",
       "      <td>1.163102e+09</td>\n",
       "      <td>38</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1162149051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId_x  movieId         tag   timestamp_x  userId_y  rating  timestamp_y\n",
       "0      15.0     1926  excellent!  1.215185e+09        38     5.0   1162149051\n",
       "1     146.0     1926     surreal  1.193705e+09        38     5.0   1162149051\n",
       "2    1751.0     1926      Jeunet  1.137525e+09        38     5.0   1162149051\n",
       "3    2456.0     1926       Paris  1.163102e+09        38     5.0   1162149051\n",
       "4    2456.0     1926     romance  1.163102e+09        38     5.0   1162149051"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map movie index for tags data\n",
    "tags = pd.merge(tags, ratings, on=\"movieId\", how=\"right\")\n",
    "tags.movieId = tags.movieId.apply(lambda x: movie2idx[x])\n",
    "print(\"{} unique movies in tags.csv\".format(len(tags.movieId.unique())))\n",
    "print(tags.shape)\n",
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10681 unique movies in movies.csv\n",
      "10677 unique movies in ratings.csv\n",
      "10677 unique movies in movies.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>Primer (2004)</td>\n",
       "      <td>Drama Mystery SciFi Thriller</td>\n",
       "      <td>92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1162165737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 title                        genres  userId  rating  \\\n",
       "movieId                                                                \n",
       "2976     Primer (2004)  Drama Mystery SciFi Thriller      92     5.0   \n",
       "\n",
       "          timestamp  \n",
       "movieId              \n",
       "2976     1162165737  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map movie index for movie data\n",
    "movies = pd.read_csv(\"movies1.dat\", sep='::', header=None, engine='python', encoding='latin-1')\n",
    "movies.columns=['movieId','title','genres']\n",
    "#movies.head()\n",
    "print(\"{} unique movies in movies.csv\".format(len(movies.movieId.unique())))\n",
    "print(\"{} unique movies in ratings.csv\".format(len(ratings.movieId.unique())))\n",
    "\n",
    "movies = pd.merge(movies, ratings, on=\"movieId\", how=\"inner\")\n",
    "movies.movieId = movies.movieId.apply(lambda x: movie2idx[x])\n",
    "print(\"{} unique movies in movies.csv\".format(len(movies.movieId.unique())))\n",
    "\n",
    "movies.set_index('movieId', inplace=True)\n",
    "movies['genres'] = movies['genres'].str.replace(pat=\"|\", repl=\" \")\n",
    "movies['genres'] = movies['genres'].str.replace(pat=\"-\", repl=\"\")\n",
    "movies.query('title == \"Primer (2004)\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10677 unique movies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6863</th>\n",
       "      <td>6863</td>\n",
       "      <td>{Richard Attenborough Candice Bergen Richard A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>2397</td>\n",
       "      <td>{fishing}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>755</td>\n",
       "      <td>{John Landis Africa immigrants Arsenio Hall Ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>9982</td>\n",
       "      <td>{fake documental}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>3750</td>\n",
       "      <td>{Subgenre: Heroic Bloodshed gun fu explosions}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10482</th>\n",
       "      <td>10482</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8586</th>\n",
       "      <td>8586</td>\n",
       "      <td>{70mm}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6703</th>\n",
       "      <td>6703</td>\n",
       "      <td>{Henry Fonda Lucille Ball}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>5904</td>\n",
       "      <td>{musical american revolution congress politica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10518</th>\n",
       "      <td>10518</td>\n",
       "      <td>{Musical}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                                                tag\n",
       "6863      6863  {Richard Attenborough Candice Bergen Richard A...\n",
       "2397      2397                                          {fishing}\n",
       "755        755  {John Landis Africa immigrants Arsenio Hall Ed...\n",
       "9982      9982                                  {fake documental}\n",
       "3750      3750     {Subgenre: Heroic Bloodshed gun fu explosions}\n",
       "10482    10482                                                 {}\n",
       "8586      8586                                             {70mm}\n",
       "6703      6703                         {Henry Fonda Lucille Ball}\n",
       "5904      5904  {musical american revolution congress politica...\n",
       "10518    10518                                          {Musical}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create documents from tags\n",
    "tags.fillna(\"\", inplace=True)\n",
    "tags = pd.DataFrame(tags.groupby('movieId')['tag'].apply(lambda x: \"{%s}\" % ' '.join(x)))\n",
    "tags.reset_index(inplace=True)\n",
    "movie_id = tags.movieId\n",
    "print(\"There are {} unique movies\".format(len(movie_id)))\n",
    "tags.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boomerang (1992)</td>\n",
       "      <td>Comedy Romance</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838985046</td>\n",
       "      <td>0</td>\n",
       "      <td>{dating Nudity (Topless - Brief) Can't remember}</td>\n",
       "      <td>{dating Nudity (Topless - Brief) Can't remembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Net, The (1995)</td>\n",
       "      <td>Action Crime Thriller</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983525</td>\n",
       "      <td>1</td>\n",
       "      <td>{computers computers internet Irwin Winkler Sa...</td>\n",
       "      <td>{computers computers internet Irwin Winkler Sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dumb &amp; Dumber (1994)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "      <td>2</td>\n",
       "      <td>{Jeff Daniels Jim Carrey stupid Jim Carrey Shi...</td>\n",
       "      <td>{Jeff Daniels Jim Carrey stupid Jim Carrey Shi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                 genres  userId  rating  timestamp  \\\n",
       "0      Boomerang (1992)         Comedy Romance       1     5.0  838985046   \n",
       "1       Net, The (1995)  Action Crime Thriller       1     5.0  838983525   \n",
       "2  Dumb & Dumber (1994)                 Comedy       1     5.0  838983392   \n",
       "\n",
       "   movieId                                                tag  \\\n",
       "0        0   {dating Nudity (Topless - Brief) Can't remember}   \n",
       "1        1  {computers computers internet Irwin Winkler Sa...   \n",
       "2        2  {Jeff Daniels Jim Carrey stupid Jim Carrey Shi...   \n",
       "\n",
       "                                            document  \n",
       "0  {dating Nudity (Topless - Brief) Can't remembe...  \n",
       "1  {computers computers internet Irwin Winkler Sa...  \n",
       "2  {Jeff Daniels Jim Carrey stupid Jim Carrey Shi...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add genres to document\n",
    "tags = pd.merge(movies, tags, left_index=True, right_on='movieId', how='right')\n",
    "tags['document'] = tags[['tag', 'genres']].apply(lambda x: ' '.join(x), axis=1)\n",
    "tags.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>userId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>Ever After: A Cinderella Story (1998)</td>\n",
       "      <td>Comedy Drama Fantasy Romance</td>\n",
       "      <td>14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1133576251</td>\n",
       "      <td>1193</td>\n",
       "      <td>{definitely for girls lovely xvgb funny chick ...</td>\n",
       "      <td>{definitely for girls lovely xvgb funny chick ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>Cinderella (1950)</td>\n",
       "      <td>Animation Children Fantasy Musical Romance</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>877086235</td>\n",
       "      <td>1450</td>\n",
       "      <td>{Disney Disney library vhs fairy tale Disney f...</td>\n",
       "      <td>{Disney Disney library vhs fairy tale Disney f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>Cinderella Man (2005)</td>\n",
       "      <td>Drama Romance</td>\n",
       "      <td>92</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1162165478</td>\n",
       "      <td>2979</td>\n",
       "      <td>{crowe did it again boxing Nice drama not as g...</td>\n",
       "      <td>{crowe did it again boxing Nice drama not as g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6589</th>\n",
       "      <td>Cinderella Story, A (2004)</td>\n",
       "      <td>Comedy Romance</td>\n",
       "      <td>874</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1162530606</td>\n",
       "      <td>6589</td>\n",
       "      <td>{Bibliothek based on a book Drama Hilary Duff ...</td>\n",
       "      <td>{Bibliothek based on a book Drama Hilary Duff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9272</th>\n",
       "      <td>Cinderella (1997)</td>\n",
       "      <td>Children Fantasy Musical Romance</td>\n",
       "      <td>5405</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1227152784</td>\n",
       "      <td>9272</td>\n",
       "      <td>{}</td>\n",
       "      <td>{} Children Fantasy Musical Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title  \\\n",
       "1193  Ever After: A Cinderella Story (1998)   \n",
       "1450                      Cinderella (1950)   \n",
       "2979                  Cinderella Man (2005)   \n",
       "6589             Cinderella Story, A (2004)   \n",
       "9272                      Cinderella (1997)   \n",
       "\n",
       "                                          genres  userId  rating   timestamp  \\\n",
       "1193                Comedy Drama Fantasy Romance      14     4.0  1133576251   \n",
       "1450  Animation Children Fantasy Musical Romance      19     5.0   877086235   \n",
       "2979                               Drama Romance      92     3.0  1162165478   \n",
       "6589                              Comedy Romance     874     3.5  1162530606   \n",
       "9272            Children Fantasy Musical Romance    5405     4.0  1227152784   \n",
       "\n",
       "      movieId                                                tag  \\\n",
       "1193     1193  {definitely for girls lovely xvgb funny chick ...   \n",
       "1450     1450  {Disney Disney library vhs fairy tale Disney f...   \n",
       "2979     2979  {crowe did it again boxing Nice drama not as g...   \n",
       "6589     6589  {Bibliothek based on a book Drama Hilary Duff ...   \n",
       "9272     9272                                                 {}   \n",
       "\n",
       "                                               document  \n",
       "1193  {definitely for girls lovely xvgb funny chick ...  \n",
       "1450  {Disney Disney library vhs fairy tale Disney f...  \n",
       "2979  {crowe did it again boxing Nice drama not as g...  \n",
       "6589  {Bibliothek based on a book Drama Hilary Duff ...  \n",
       "9272                {} Children Fantasy Musical Romance  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags[tags['title'].str.contains(\"Cinderella\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10677, 6250)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6240</th>\n",
       "      <th>6241</th>\n",
       "      <th>6242</th>\n",
       "      <th>6243</th>\n",
       "      <th>6244</th>\n",
       "      <th>6245</th>\n",
       "      <th>6246</th>\n",
       "      <th>6247</th>\n",
       "      <th>6248</th>\n",
       "      <th>6249</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 6250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  6240  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "   6241  6242  6243  6244  6245  6246  6247  6248  6249  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[3 rows x 6250 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(0, 1),\n",
    "    min_df=0.0001,\n",
    "    stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(tags['document'])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=tags.index.tolist())\n",
    "print(tfidf_df.shape)\n",
    "tfidf_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.to_pickle('tfidf_matrix.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datal= <torch.utils.data.dataloader.DataLoader object at 0x7f79f2c7be10>\n"
     ]
    }
   ],
   "source": [
    "ae1 = AutoEncoder(tfidf_df, validation_perc=0.1, lr=1e-3, intermediate_size=900, encoded_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "train loss: 0.2391832 | validation loss: 0.18588601)\n",
      "train loss: 0.22586899 | validation loss: 0.18180402)\n",
      "train loss: 0.21859425 | validation loss: 0.18887985)\n",
      "train loss: 0.2167014 | validation loss: 0.20691377)\n",
      "train loss: 0.21543203 | validation loss: 0.21924669)\n",
      "train loss: 0.20605822 | validation loss: 0.2139274)\n",
      "train loss: 0.20228587 | validation loss: 0.19938968)\n",
      "Epoch 2/30\n",
      "train loss: 0.19994999 | validation loss: 0.20324397)\n",
      "train loss: 0.19207145 | validation loss: 0.20144577)\n",
      "train loss: 0.18522128 | validation loss: 0.18006602)\n",
      "train loss: 0.18550417 | validation loss: 0.17494939)\n",
      "train loss: 0.17681316 | validation loss: 0.16451074)\n",
      "train loss: 0.17498109 | validation loss: 0.16536534)\n",
      "train loss: 0.17420757 | validation loss: 0.16593096)\n",
      "Epoch 3/30\n",
      "train loss: 0.17121659 | validation loss: 0.15960816)\n",
      "train loss: 0.17385641 | validation loss: 0.15422997)\n",
      "train loss: 0.15987308 | validation loss: 0.14988491)\n",
      "train loss: 0.15478493 | validation loss: 0.1464826)\n",
      "train loss: 0.17007175 | validation loss: 0.14600012)\n",
      "train loss: 0.15020446 | validation loss: 0.14454916)\n",
      "train loss: 0.15131181 | validation loss: 0.141964)\n",
      "Epoch 4/30\n",
      "train loss: 0.14359079 | validation loss: 0.1444931)\n",
      "train loss: 0.14137134 | validation loss: 0.13177337)\n",
      "train loss: 0.13363425 | validation loss: 0.13668777)\n",
      "train loss: 0.1298966 | validation loss: 0.13353428)\n",
      "train loss: 0.12732401 | validation loss: 0.12851761)\n",
      "train loss: 0.12947808 | validation loss: 0.12874779)\n",
      "train loss: 0.12489139 | validation loss: 0.12423386)\n",
      "Epoch 5/30\n",
      "train loss: 0.12422248 | validation loss: 0.12250306)\n",
      "train loss: 0.12754735 | validation loss: 0.11556079)\n",
      "train loss: 0.11479267 | validation loss: 0.11741568)\n",
      "train loss: 0.11284307 | validation loss: 0.11130076)\n",
      "train loss: 0.12162476 | validation loss: 0.1075889)\n",
      "train loss: 0.11136992 | validation loss: 0.10625774)\n",
      "train loss: 0.11059923 | validation loss: 0.10189541)\n",
      "Epoch 6/30\n",
      "train loss: 0.10708214 | validation loss: 0.11018835)\n",
      "train loss: 0.14219151 | validation loss: 0.10631693)\n",
      "train loss: 0.09809305 | validation loss: 0.10279258)\n",
      "train loss: 0.09615444 | validation loss: 0.10335612)\n",
      "train loss: 0.11564629 | validation loss: 0.09716593)\n",
      "train loss: 0.09826139 | validation loss: 0.09288508)\n",
      "train loss: 0.09825332 | validation loss: 0.09025317)\n",
      "Epoch 7/30\n",
      "train loss: 0.0887129 | validation loss: 0.092075)\n",
      "train loss: 0.10139936 | validation loss: 0.08612411)\n",
      "train loss: 0.10140853 | validation loss: 0.09048276)\n",
      "train loss: 0.09002972 | validation loss: 0.08219443)\n",
      "train loss: 0.08425892 | validation loss: 0.08662032)\n",
      "train loss: 0.08083004 | validation loss: 0.08817137)\n",
      "train loss: 0.10355555 | validation loss: 0.07573227)\n",
      "Epoch 8/30\n",
      "train loss: 0.08388833 | validation loss: 0.08679511)\n",
      "train loss: 0.08530565 | validation loss: 0.07783943)\n",
      "train loss: 0.08375178 | validation loss: 0.06915847)\n",
      "train loss: 0.08223725 | validation loss: 0.07190779)\n",
      "train loss: 0.08113098 | validation loss: 0.07193944)\n",
      "train loss: 0.12656145 | validation loss: 0.07160451)\n",
      "train loss: 0.07047857 | validation loss: 0.08178227)\n",
      "Epoch 9/30\n",
      "train loss: 0.07676348 | validation loss: 0.07454994)\n",
      "train loss: 0.08668605 | validation loss: 0.07906286)\n",
      "train loss: 0.08492798 | validation loss: 0.07624546)\n",
      "train loss: 0.07436135 | validation loss: 0.06954146)\n",
      "train loss: 0.06541533 | validation loss: 0.06565591)\n",
      "train loss: 0.07197929 | validation loss: 0.0630746)\n",
      "train loss: 0.0803471 | validation loss: 0.05819532)\n",
      "Epoch 10/30\n",
      "train loss: 0.06137273 | validation loss: 0.06972913)\n",
      "train loss: 0.06076931 | validation loss: 0.06441478)\n",
      "train loss: 0.06812326 | validation loss: 0.05758213)\n",
      "train loss: 0.0589812 | validation loss: 0.060489)\n",
      "train loss: 0.06731874 | validation loss: 0.06320477)\n",
      "train loss: 0.06675365 | validation loss: 0.0578794)\n",
      "train loss: 0.06540725 | validation loss: 0.06191818)\n",
      "Epoch 11/30\n",
      "train loss: 0.06288873 | validation loss: 0.0589406)\n",
      "train loss: 0.06393457 | validation loss: 0.05284768)\n",
      "train loss: 0.05659065 | validation loss: 0.05670235)\n",
      "train loss: 0.05325793 | validation loss: 0.05502412)\n",
      "train loss: 0.07142248 | validation loss: 0.0558791)\n",
      "train loss: 0.05255708 | validation loss: 0.05511971)\n",
      "train loss: 0.06705314 | validation loss: 0.04991069)\n",
      "Epoch 12/30\n",
      "train loss: 0.0570892 | validation loss: 0.06084504)\n",
      "train loss: 0.05972144 | validation loss: 0.05586292)\n",
      "train loss: 0.06908607 | validation loss: 0.05516191)\n",
      "train loss: 0.05882936 | validation loss: 0.04306223)\n",
      "train loss: 0.05769663 | validation loss: 0.04711236)\n",
      "train loss: 0.04708564 | validation loss: 0.05429522)\n",
      "train loss: 0.05248378 | validation loss: 0.04934722)\n",
      "Epoch 13/30\n",
      "train loss: 0.0689747 | validation loss: 0.05209582)\n",
      "train loss: 0.05174698 | validation loss: 0.05097265)\n",
      "train loss: 0.06026069 | validation loss: 0.05327006)\n",
      "train loss: 0.04435708 | validation loss: 0.05498877)\n",
      "train loss: 0.05655183 | validation loss: 0.05290817)\n",
      "train loss: 0.04335398 | validation loss: 0.04587852)\n",
      "train loss: 0.05357214 | validation loss: 0.04447933)\n",
      "Epoch 14/30\n",
      "train loss: 0.05309263 | validation loss: 0.04862875)\n",
      "train loss: 0.04181427 | validation loss: 0.04749256)\n",
      "train loss: 0.05199542 | validation loss: 0.04431458)\n",
      "train loss: 0.04266329 | validation loss: 0.04735594)\n",
      "train loss: 0.11760215 | validation loss: 0.04678054)\n",
      "train loss: 0.04025334 | validation loss: 0.04086135)\n",
      "train loss: 0.05226882 | validation loss: 0.04711441)\n",
      "Epoch 15/30\n",
      "train loss: 0.05213314 | validation loss: 0.04548264)\n",
      "train loss: 0.05133987 | validation loss: 0.03853651)\n",
      "train loss: 0.05255152 | validation loss: 0.03788802)\n",
      "train loss: 0.04131848 | validation loss: 0.05060061)\n",
      "train loss: 0.04960648 | validation loss: 0.04081677)\n",
      "train loss: 0.07685792 | validation loss: 0.03742861)\n",
      "train loss: 0.06435291 | validation loss: 0.03295613)\n",
      "Epoch 16/30\n",
      "train loss: 0.03708649 | validation loss: 0.04103006)\n",
      "train loss: 0.0482163 | validation loss: 0.03966178)\n",
      "train loss: 0.04806826 | validation loss: 0.04505588)\n",
      "train loss: 0.04739404 | validation loss: 0.0440417)\n",
      "train loss: 0.03563526 | validation loss: 0.03982217)\n",
      "train loss: 0.05626911 | validation loss: 0.03506133)\n",
      "train loss: 0.05220548 | validation loss: 0.03902585)\n",
      "Epoch 17/30\n",
      "train loss: 0.03484661 | validation loss: 0.04277764)\n",
      "train loss: 0.03421187 | validation loss: 0.04814685)\n",
      "train loss: 0.04570474 | validation loss: 0.04071767)\n",
      "train loss: 0.04586015 | validation loss: 0.04491488)\n",
      "train loss: 0.06066338 | validation loss: 0.02810434)\n",
      "train loss: 0.03649631 | validation loss: 0.03032635)\n",
      "train loss: 0.04786151 | validation loss: 0.03642749)\n",
      "Epoch 18/30\n",
      "train loss: 0.0470113 | validation loss: 0.0347063)\n",
      "train loss: 0.05148299 | validation loss: 0.02636223)\n",
      "train loss: 0.03238969 | validation loss: 0.03103016)\n",
      "train loss: 0.04144647 | validation loss: 0.03502697)\n",
      "train loss: 0.03167234 | validation loss: 0.03632003)\n",
      "train loss: 0.04595014 | validation loss: 0.03252919)\n",
      "train loss: 0.03066993 | validation loss: 0.03426357)\n",
      "Epoch 19/30\n",
      "train loss: 0.04402783 | validation loss: 0.03738497)\n",
      "train loss: 0.03070969 | validation loss: 0.03352593)\n",
      "train loss: 0.03053693 | validation loss: 0.0312475)\n",
      "train loss: 0.03045947 | validation loss: 0.03180709)\n",
      "train loss: 0.03056676 | validation loss: 0.02011764)\n",
      "train loss: 0.04417238 | validation loss: 0.02766459)\n",
      "train loss: 0.04417447 | validation loss: 0.03283099)\n",
      "Epoch 20/30\n",
      "train loss: 0.04305694 | validation loss: 0.03561297)\n",
      "train loss: 0.04143495 | validation loss: 0.03016219)\n",
      "train loss: 0.04139732 | validation loss: 0.03015354)\n",
      "train loss: 0.02825432 | validation loss: 0.03239579)\n",
      "train loss: 0.04256012 | validation loss: 0.02999738)\n",
      "train loss: 0.03754022 | validation loss: 0.02393417)\n",
      "train loss: 0.0331753 | validation loss: 0.03352513)\n",
      "Epoch 21/30\n",
      "train loss: 0.04345446 | validation loss: 0.0238392)\n",
      "train loss: 0.0406773 | validation loss: 0.0220855)\n",
      "train loss: 0.02815795 | validation loss: 0.02558916)\n",
      "train loss: 0.04027363 | validation loss: 0.02753902)\n",
      "train loss: 0.02702799 | validation loss: 0.02166812)\n",
      "train loss: 0.02842209 | validation loss: 0.02549518)\n",
      "train loss: 0.03662276 | validation loss: 0.02693925)\n",
      "Epoch 22/30\n",
      "train loss: 0.02685445 | validation loss: 0.02641958)\n",
      "train loss: 0.04037035 | validation loss: 0.02873168)\n",
      "train loss: 0.05121549 | validation loss: 0.02462169)\n",
      "train loss: 0.02689451 | validation loss: 0.02555881)\n",
      "train loss: 0.03960789 | validation loss: 0.02689156)\n",
      "train loss: 0.02664881 | validation loss: 0.0284069)\n",
      "train loss: 0.02531305 | validation loss: 0.02886469)\n",
      "Epoch 23/30\n",
      "train loss: 0.02504378 | validation loss: 0.02879882)\n",
      "train loss: 0.02491205 | validation loss: 0.02512522)\n",
      "train loss: 0.02593 | validation loss: 0.02830539)\n",
      "train loss: 0.04303465 | validation loss: 0.02597841)\n",
      "train loss: 0.02478563 | validation loss: 0.02170844)\n",
      "train loss: 0.03686758 | validation loss: 0.02540139)\n",
      "train loss: 0.03782412 | validation loss: 0.02066342)\n",
      "Epoch 24/30\n",
      "train loss: 0.02879829 | validation loss: 0.01586047)\n",
      "train loss: 0.03406226 | validation loss: 0.02005679)\n",
      "train loss: 0.02818062 | validation loss: 0.02284655)\n",
      "train loss: 0.02191204 | validation loss: 0.02365298)\n",
      "train loss: 0.0223143 | validation loss: 0.02443828)\n",
      "train loss: 0.02691212 | validation loss: 0.02461082)\n",
      "train loss: 0.02424115 | validation loss: 0.02419448)\n",
      "Epoch 25/30\n",
      "train loss: 0.0229042 | validation loss: 0.02215984)\n",
      "train loss: 0.0192576 | validation loss: 0.02153828)\n",
      "train loss: 0.02017346 | validation loss: 0.01988518)\n",
      "train loss: 0.02729205 | validation loss: 0.02029858)\n",
      "train loss: 0.01982114 | validation loss: 0.01921552)\n",
      "train loss: 0.02076561 | validation loss: 0.01897453)\n",
      "train loss: 0.02147285 | validation loss: 0.01800524)\n",
      "Epoch 26/30\n",
      "train loss: 0.02006687 | validation loss: 0.01704778)\n",
      "train loss: 0.01738023 | validation loss: 0.01623059)\n",
      "train loss: 0.01690334 | validation loss: 0.01544881)\n",
      "train loss: 0.01412972 | validation loss: 0.01495053)\n",
      "train loss: 0.0145731 | validation loss: 0.01485828)\n",
      "train loss: 0.01506022 | validation loss: 0.01438341)\n",
      "train loss: 0.01642395 | validation loss: 0.01534188)\n",
      "Epoch 27/30\n",
      "train loss: 0.01509404 | validation loss: 0.01511182)\n",
      "train loss: 0.01510139 | validation loss: 0.01360532)\n",
      "train loss: 0.01269259 | validation loss: 0.01368692)\n",
      "train loss: 0.013839 | validation loss: 0.01291758)\n",
      "train loss: 0.01459172 | validation loss: 0.01237805)\n",
      "train loss: 0.01134691 | validation loss: 0.01265503)\n",
      "train loss: 0.01564586 | validation loss: 0.01299368)\n",
      "Epoch 28/30\n",
      "train loss: 0.01401076 | validation loss: 0.01167219)\n",
      "train loss: 0.01200133 | validation loss: 0.01147076)\n",
      "train loss: 0.01263858 | validation loss: 0.01227645)\n",
      "train loss: 0.0133115 | validation loss: 0.01130635)\n",
      "train loss: 0.01085217 | validation loss: 0.01090066)\n",
      "train loss: 0.01337452 | validation loss: 0.01049954)\n",
      "train loss: 0.01050251 | validation loss: 0.01096458)\n",
      "Epoch 29/30\n",
      "train loss: 0.02013764 | validation loss: 0.01102661)\n",
      "train loss: 0.00905366 | validation loss: 0.01022818)\n",
      "train loss: 0.00975452 | validation loss: 0.00945112)\n",
      "train loss: 0.00871879 | validation loss: 0.00913174)\n",
      "train loss: 0.00968185 | validation loss: 0.00920665)\n",
      "train loss: 0.00857631 | validation loss: 0.00928999)\n",
      "train loss: 0.00846799 | validation loss: 0.00917037)\n",
      "Epoch 30/30\n",
      "train loss: 0.01020783 | validation loss: 0.00867256)\n",
      "train loss: 0.00793314 | validation loss: 0.00888107)\n",
      "train loss: 0.00877126 | validation loss: 0.00891055)\n",
      "train loss: 0.00854789 | validation loss: 0.00893555)\n",
      "train loss: 0.00737156 | validation loss: 0.00801013)\n",
      "train loss: 0.00724492 | validation loss: 0.0081628)\n",
      "train loss: 0.00706516 | validation loss: 0.007825)\n"
     ]
    }
   ],
   "source": [
    "ae1.train_loop(epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae1.train_loop(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae1.train_loop(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae1.train_loop(epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses1 = pd.DataFrame(data=list(zip(ae1.train_losses, ae1.val_losses)), columns=['train_loss', 'validation_loss'])\n",
    "losses1['epoch'] = (losses1.index + 1) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'autoencoder loss over time')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 392.14375 277.314375\" width=\"392.14375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 277.314375 \n",
       "L 392.14375 277.314375 \n",
       "L 392.14375 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 384.94375 239.758125 \n",
       "L 384.94375 22.318125 \n",
       "L 50.14375 22.318125 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"m81b468af0c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"63.905646\" xlink:href=\"#m81b468af0c\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(60.724396 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"107.594207\" xlink:href=\"#m81b468af0c\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 10 -->\n",
       "      <defs>\n",
       "       <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(101.231707 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"151.282767\" xlink:href=\"#m81b468af0c\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 20 -->\n",
       "      <defs>\n",
       "       <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(144.920267 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"194.971327\" xlink:href=\"#m81b468af0c\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 30 -->\n",
       "      <defs>\n",
       "       <path d=\"M 40.578125 39.3125 \n",
       "Q 47.65625 37.796875 51.625 33 \n",
       "Q 55.609375 28.21875 55.609375 21.1875 \n",
       "Q 55.609375 10.40625 48.1875 4.484375 \n",
       "Q 40.765625 -1.421875 27.09375 -1.421875 \n",
       "Q 22.515625 -1.421875 17.65625 -0.515625 \n",
       "Q 12.796875 0.390625 7.625 2.203125 \n",
       "L 7.625 11.71875 \n",
       "Q 11.71875 9.328125 16.59375 8.109375 \n",
       "Q 21.484375 6.890625 26.8125 6.890625 \n",
       "Q 36.078125 6.890625 40.9375 10.546875 \n",
       "Q 45.796875 14.203125 45.796875 21.1875 \n",
       "Q 45.796875 27.640625 41.28125 31.265625 \n",
       "Q 36.765625 34.90625 28.71875 34.90625 \n",
       "L 20.21875 34.90625 \n",
       "L 20.21875 43.015625 \n",
       "L 29.109375 43.015625 \n",
       "Q 36.375 43.015625 40.234375 45.921875 \n",
       "Q 44.09375 48.828125 44.09375 54.296875 \n",
       "Q 44.09375 59.90625 40.109375 62.90625 \n",
       "Q 36.140625 65.921875 28.71875 65.921875 \n",
       "Q 24.65625 65.921875 20.015625 65.03125 \n",
       "Q 15.375 64.15625 9.8125 62.3125 \n",
       "L 9.8125 71.09375 \n",
       "Q 15.4375 72.65625 20.34375 73.4375 \n",
       "Q 25.25 74.21875 29.59375 74.21875 \n",
       "Q 40.828125 74.21875 47.359375 69.109375 \n",
       "Q 53.90625 64.015625 53.90625 55.328125 \n",
       "Q 53.90625 49.265625 50.4375 45.09375 \n",
       "Q 46.96875 40.921875 40.578125 39.3125 \n",
       "z\n",
       "\" id=\"DejaVuSans-51\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(188.608827 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-51\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"238.659887\" xlink:href=\"#m81b468af0c\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 40 -->\n",
       "      <defs>\n",
       "       <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(232.297387 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"282.348448\" xlink:href=\"#m81b468af0c\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 50 -->\n",
       "      <defs>\n",
       "       <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(275.985948 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"326.037008\" xlink:href=\"#m81b468af0c\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 60 -->\n",
       "      <defs>\n",
       "       <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(319.674508 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"369.725568\" xlink:href=\"#m81b468af0c\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 70 -->\n",
       "      <defs>\n",
       "       <path d=\"M 8.203125 72.90625 \n",
       "L 55.078125 72.90625 \n",
       "L 55.078125 68.703125 \n",
       "L 28.609375 0 \n",
       "L 18.3125 0 \n",
       "L 43.21875 64.59375 \n",
       "L 8.203125 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-55\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(363.363068 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-55\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_9\">\n",
       "     <!-- epoch -->\n",
       "     <defs>\n",
       "      <path d=\"M 56.203125 29.59375 \n",
       "L 56.203125 25.203125 \n",
       "L 14.890625 25.203125 \n",
       "Q 15.484375 15.921875 20.484375 11.0625 \n",
       "Q 25.484375 6.203125 34.421875 6.203125 \n",
       "Q 39.59375 6.203125 44.453125 7.46875 \n",
       "Q 49.3125 8.734375 54.109375 11.28125 \n",
       "L 54.109375 2.78125 \n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \n",
       "Q 5.515625 13.8125 5.515625 26.8125 \n",
       "Q 5.515625 40.234375 12.765625 48.109375 \n",
       "Q 20.015625 56 32.328125 56 \n",
       "Q 43.359375 56 49.78125 48.890625 \n",
       "Q 56.203125 41.796875 56.203125 29.59375 \n",
       "z\n",
       "M 47.21875 32.234375 \n",
       "Q 47.125 39.59375 43.09375 43.984375 \n",
       "Q 39.0625 48.390625 32.421875 48.390625 \n",
       "Q 24.90625 48.390625 20.390625 44.140625 \n",
       "Q 15.875 39.890625 15.1875 32.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-101\"/>\n",
       "      <path d=\"M 18.109375 8.203125 \n",
       "L 18.109375 -20.796875 \n",
       "L 9.078125 -20.796875 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.390625 \n",
       "Q 20.953125 51.265625 25.265625 53.625 \n",
       "Q 29.59375 56 35.59375 56 \n",
       "Q 45.5625 56 51.78125 48.09375 \n",
       "Q 58.015625 40.1875 58.015625 27.296875 \n",
       "Q 58.015625 14.40625 51.78125 6.484375 \n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \n",
       "Q 20.953125 3.328125 18.109375 8.203125 \n",
       "z\n",
       "M 48.6875 27.296875 \n",
       "Q 48.6875 37.203125 44.609375 42.84375 \n",
       "Q 40.53125 48.484375 33.40625 48.484375 \n",
       "Q 26.265625 48.484375 22.1875 42.84375 \n",
       "Q 18.109375 37.203125 18.109375 27.296875 \n",
       "Q 18.109375 17.390625 22.1875 11.75 \n",
       "Q 26.265625 6.109375 33.40625 6.109375 \n",
       "Q 40.53125 6.109375 44.609375 11.75 \n",
       "Q 48.6875 17.390625 48.6875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-112\"/>\n",
       "      <path d=\"M 30.609375 48.390625 \n",
       "Q 23.390625 48.390625 19.1875 42.75 \n",
       "Q 14.984375 37.109375 14.984375 27.296875 \n",
       "Q 14.984375 17.484375 19.15625 11.84375 \n",
       "Q 23.34375 6.203125 30.609375 6.203125 \n",
       "Q 37.796875 6.203125 41.984375 11.859375 \n",
       "Q 46.1875 17.53125 46.1875 27.296875 \n",
       "Q 46.1875 37.015625 41.984375 42.703125 \n",
       "Q 37.796875 48.390625 30.609375 48.390625 \n",
       "z\n",
       "M 30.609375 56 \n",
       "Q 42.328125 56 49.015625 48.375 \n",
       "Q 55.71875 40.765625 55.71875 27.296875 \n",
       "Q 55.71875 13.875 49.015625 6.21875 \n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \n",
       "Q 5.515625 13.875 5.515625 27.296875 \n",
       "Q 5.515625 40.765625 12.171875 48.375 \n",
       "Q 18.84375 56 30.609375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-111\"/>\n",
       "      <path d=\"M 48.78125 52.59375 \n",
       "L 48.78125 44.1875 \n",
       "Q 44.96875 46.296875 41.140625 47.34375 \n",
       "Q 37.3125 48.390625 33.40625 48.390625 \n",
       "Q 24.65625 48.390625 19.8125 42.84375 \n",
       "Q 14.984375 37.3125 14.984375 27.296875 \n",
       "Q 14.984375 17.28125 19.8125 11.734375 \n",
       "Q 24.65625 6.203125 33.40625 6.203125 \n",
       "Q 37.3125 6.203125 41.140625 7.25 \n",
       "Q 44.96875 8.296875 48.78125 10.40625 \n",
       "L 48.78125 2.09375 \n",
       "Q 45.015625 0.34375 40.984375 -0.53125 \n",
       "Q 36.96875 -1.421875 32.421875 -1.421875 \n",
       "Q 20.0625 -1.421875 12.78125 6.34375 \n",
       "Q 5.515625 14.109375 5.515625 27.296875 \n",
       "Q 5.515625 40.671875 12.859375 48.328125 \n",
       "Q 20.21875 56 33.015625 56 \n",
       "Q 37.15625 56 41.109375 55.140625 \n",
       "Q 45.0625 54.296875 48.78125 52.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-99\"/>\n",
       "      <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 75.984375 \n",
       "L 18.109375 75.984375 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-104\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(202.315625 268.034687)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"md5197bb9fc\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#md5197bb9fc\" y=\"235.89121\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.00 -->\n",
       "      <defs>\n",
       "       <path d=\"M 10.6875 12.40625 \n",
       "L 21 12.40625 \n",
       "L 21 0 \n",
       "L 10.6875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-46\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(20.878125 239.690429)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#md5197bb9fc\" y=\"193.310994\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.05 -->\n",
       "      <g transform=\"translate(20.878125 197.110213)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#md5197bb9fc\" y=\"150.730778\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.10 -->\n",
       "      <g transform=\"translate(20.878125 154.529997)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#md5197bb9fc\" y=\"108.150562\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.15 -->\n",
       "      <g transform=\"translate(20.878125 111.949781)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#md5197bb9fc\" y=\"65.570346\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 0.20 -->\n",
       "      <g transform=\"translate(20.878125 69.369565)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#md5197bb9fc\" y=\"22.99013\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 0.25 -->\n",
       "      <g transform=\"translate(20.878125 26.789349)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- MSE loss -->\n",
       "     <defs>\n",
       "      <path d=\"M 9.8125 72.90625 \n",
       "L 24.515625 72.90625 \n",
       "L 43.109375 23.296875 \n",
       "L 61.8125 72.90625 \n",
       "L 76.515625 72.90625 \n",
       "L 76.515625 0 \n",
       "L 66.890625 0 \n",
       "L 66.890625 64.015625 \n",
       "L 48.09375 14.015625 \n",
       "L 38.1875 14.015625 \n",
       "L 19.390625 64.015625 \n",
       "L 19.390625 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-77\"/>\n",
       "      <path d=\"M 53.515625 70.515625 \n",
       "L 53.515625 60.890625 \n",
       "Q 47.90625 63.578125 42.921875 64.890625 \n",
       "Q 37.9375 66.21875 33.296875 66.21875 \n",
       "Q 25.25 66.21875 20.875 63.09375 \n",
       "Q 16.5 59.96875 16.5 54.203125 \n",
       "Q 16.5 49.359375 19.40625 46.890625 \n",
       "Q 22.3125 44.4375 30.421875 42.921875 \n",
       "L 36.375 41.703125 \n",
       "Q 47.40625 39.59375 52.65625 34.296875 \n",
       "Q 57.90625 29 57.90625 20.125 \n",
       "Q 57.90625 9.515625 50.796875 4.046875 \n",
       "Q 43.703125 -1.421875 29.984375 -1.421875 \n",
       "Q 24.8125 -1.421875 18.96875 -0.25 \n",
       "Q 13.140625 0.921875 6.890625 3.21875 \n",
       "L 6.890625 13.375 \n",
       "Q 12.890625 10.015625 18.65625 8.296875 \n",
       "Q 24.421875 6.59375 29.984375 6.59375 \n",
       "Q 38.421875 6.59375 43.015625 9.90625 \n",
       "Q 47.609375 13.234375 47.609375 19.390625 \n",
       "Q 47.609375 24.75 44.3125 27.78125 \n",
       "Q 41.015625 30.8125 33.5 32.328125 \n",
       "L 27.484375 33.5 \n",
       "Q 16.453125 35.6875 11.515625 40.375 \n",
       "Q 6.59375 45.0625 6.59375 53.421875 \n",
       "Q 6.59375 63.09375 13.40625 68.65625 \n",
       "Q 20.21875 74.21875 32.171875 74.21875 \n",
       "Q 37.3125 74.21875 42.625 73.28125 \n",
       "Q 47.953125 72.359375 53.515625 70.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-83\"/>\n",
       "      <path d=\"M 9.8125 72.90625 \n",
       "L 55.90625 72.90625 \n",
       "L 55.90625 64.59375 \n",
       "L 19.671875 64.59375 \n",
       "L 19.671875 43.015625 \n",
       "L 54.390625 43.015625 \n",
       "L 54.390625 34.71875 \n",
       "L 19.671875 34.71875 \n",
       "L 19.671875 8.296875 \n",
       "L 56.78125 8.296875 \n",
       "L 56.78125 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-69\"/>\n",
       "      <path id=\"DejaVuSans-32\"/>\n",
       "      <path d=\"M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-108\"/>\n",
       "      <path d=\"M 44.28125 53.078125 \n",
       "L 44.28125 44.578125 \n",
       "Q 40.484375 46.53125 36.375 47.5 \n",
       "Q 32.28125 48.484375 27.875 48.484375 \n",
       "Q 21.1875 48.484375 17.84375 46.4375 \n",
       "Q 14.5 44.390625 14.5 40.28125 \n",
       "Q 14.5 37.15625 16.890625 35.375 \n",
       "Q 19.28125 33.59375 26.515625 31.984375 \n",
       "L 29.59375 31.296875 \n",
       "Q 39.15625 29.25 43.1875 25.515625 \n",
       "Q 47.21875 21.78125 47.21875 15.09375 \n",
       "Q 47.21875 7.46875 41.1875 3.015625 \n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \n",
       "Q 10.6875 0.296875 5.421875 2 \n",
       "L 5.421875 11.28125 \n",
       "Q 10.40625 8.6875 15.234375 7.390625 \n",
       "Q 20.0625 6.109375 24.8125 6.109375 \n",
       "Q 31.15625 6.109375 34.5625 8.28125 \n",
       "Q 37.984375 10.453125 37.984375 14.40625 \n",
       "Q 37.984375 18.0625 35.515625 20.015625 \n",
       "Q 33.0625 21.96875 24.703125 23.78125 \n",
       "L 21.578125 24.515625 \n",
       "Q 13.234375 26.265625 9.515625 29.90625 \n",
       "Q 5.8125 33.546875 5.8125 39.890625 \n",
       "Q 5.8125 47.609375 11.28125 51.796875 \n",
       "Q 16.75 56 26.8125 56 \n",
       "Q 31.78125 56 36.171875 55.265625 \n",
       "Q 40.578125 54.546875 44.28125 53.078125 \n",
       "z\n",
       "\" id=\"DejaVuSans-115\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(14.798438 152.932656)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-77\"/>\n",
       "      <use x=\"86.279297\" xlink:href=\"#DejaVuSans-83\"/>\n",
       "      <use x=\"149.755859\" xlink:href=\"#DejaVuSans-69\"/>\n",
       "      <use x=\"212.939453\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"244.726562\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "      <use x=\"272.509766\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"333.691406\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"385.791016\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path clip-path=\"url(#p2deb31fa71)\" d=\"M 65.361932 32.201761 \n",
       "L 66.818217 43.540206 \n",
       "L 68.274503 49.7354 \n",
       "L 69.730788 51.347359 \n",
       "L 71.187073 52.42836 \n",
       "L 72.643359 60.41114 \n",
       "L 74.099644 63.623688 \n",
       "L 75.555929 65.612931 \n",
       "L 77.012215 72.322331 \n",
       "L 78.4685 78.155964 \n",
       "L 79.924785 77.915059 \n",
       "L 81.381071 85.316363 \n",
       "L 82.837356 86.87656 \n",
       "L 84.293641 87.535292 \n",
       "L 85.749927 90.08242 \n",
       "L 87.206212 87.834342 \n",
       "L 88.662497 99.742602 \n",
       "L 90.118783 104.075693 \n",
       "L 91.575068 91.057372 \n",
       "L 93.031353 107.976439 \n",
       "L 94.487639 107.033415 \n",
       "L 95.943924 113.60867 \n",
       "L 97.400209 115.498767 \n",
       "L 98.856495 122.087702 \n",
       "L 100.31278 125.270708 \n",
       "L 101.769065 127.461529 \n",
       "L 103.225351 125.627116 \n",
       "L 104.681636 129.533167 \n",
       "L 106.137921 130.10281 \n",
       "L 107.594207 127.271333 \n",
       "L 109.050492 138.133272 \n",
       "L 110.506777 139.793567 \n",
       "L 111.963063 132.315039 \n",
       "L 113.419348 141.048103 \n",
       "L 114.875633 141.70443 \n",
       "L 116.331919 144.699594 \n",
       "L 117.788204 114.800302 \n",
       "L 119.244489 152.354747 \n",
       "L 120.700775 154.00567 \n",
       "L 122.15706 137.406332 \n",
       "L 123.613345 152.211389 \n",
       "L 125.069631 152.218254 \n",
       "L 126.525916 160.342921 \n",
       "L 127.982202 149.539075 \n",
       "L 129.438487 149.531265 \n",
       "L 130.894772 159.221515 \n",
       "L 132.351058 164.135949 \n",
       "L 133.807343 167.056001 \n",
       "L 135.263628 147.70286 \n",
       "L 136.719914 164.451546 \n",
       "L 138.176199 163.244547 \n",
       "L 141.08877 165.857612 \n",
       "L 142.545055 166.799716 \n",
       "L 144.00134 128.110934 \n",
       "L 145.457626 175.871359 \n",
       "L 146.913911 170.519098 \n",
       "L 148.370196 162.068993 \n",
       "L 149.826482 163.566172 \n",
       "L 151.282767 172.56476 \n",
       "L 152.739052 180.183232 \n",
       "L 154.195338 174.593334 \n",
       "L 155.651623 167.467274 \n",
       "L 157.107908 183.625931 \n",
       "L 158.564194 184.139805 \n",
       "L 160.020479 177.877149 \n",
       "L 161.476764 185.66257 \n",
       "L 162.93305 178.562283 \n",
       "L 164.389335 179.043515 \n",
       "L 165.84562 180.19011 \n",
       "L 167.301906 182.334899 \n",
       "L 168.758191 181.444252 \n",
       "L 170.214476 187.698365 \n",
       "L 171.670762 190.536523 \n",
       "L 173.127047 175.067518 \n",
       "L 174.583332 191.133376 \n",
       "L 176.039618 178.788467 \n",
       "L 177.495903 187.273799 \n",
       "L 178.952188 185.032171 \n",
       "L 180.408474 177.05721 \n",
       "L 181.864759 185.79187 \n",
       "L 183.321044 186.756508 \n",
       "L 184.77733 195.792873 \n",
       "L 186.233615 191.195795 \n",
       "L 187.689901 177.152055 \n",
       "L 189.146186 191.823259 \n",
       "L 190.602471 184.572946 \n",
       "L 192.058757 198.116526 \n",
       "L 193.515042 187.731432 \n",
       "L 194.971327 198.970775 \n",
       "L 196.427613 190.268944 \n",
       "L 197.883898 190.677298 \n",
       "L 199.340183 200.281996 \n",
       "L 200.796469 191.611687 \n",
       "L 202.252754 199.558964 \n",
       "L 203.709039 135.740714 \n",
       "L 205.165325 201.611294 \n",
       "L 206.62161 191.378859 \n",
       "L 208.077895 191.494401 \n",
       "L 209.534181 192.169956 \n",
       "L 210.990466 191.138106 \n",
       "L 212.446751 200.704211 \n",
       "L 213.903037 193.646115 \n",
       "L 215.359322 170.43867 \n",
       "L 216.815607 181.087996 \n",
       "L 218.271893 204.308198 \n",
       "L 219.728178 194.830002 \n",
       "L 221.184463 194.956073 \n",
       "L 222.640749 195.53024 \n",
       "L 224.097034 205.544067 \n",
       "L 225.553319 187.972194 \n",
       "L 227.009605 191.432801 \n",
       "L 228.46589 206.215686 \n",
       "L 229.922175 206.756234 \n",
       "L 231.378461 196.968852 \n",
       "L 232.834746 196.836512 \n",
       "L 234.291031 184.230011 \n",
       "L 235.747317 204.810797 \n",
       "L 237.203602 195.132139 \n",
       "L 238.659887 195.856183 \n",
       "L 240.116173 192.048076 \n",
       "L 241.572458 208.308014 \n",
       "L 243.028743 200.595218 \n",
       "L 244.485029 208.918909 \n",
       "L 245.941314 196.759875 \n",
       "L 247.397599 209.772569 \n",
       "L 248.853885 198.396919 \n",
       "L 250.31017 209.738705 \n",
       "L 253.222741 209.951793 \n",
       "L 254.679026 209.860424 \n",
       "L 256.135312 198.273821 \n",
       "L 257.591597 198.272041 \n",
       "L 259.047882 199.223732 \n",
       "L 260.504168 200.605027 \n",
       "L 261.960453 200.637072 \n",
       "L 263.416738 211.829705 \n",
       "L 264.873024 199.646829 \n",
       "L 266.329309 203.9218 \n",
       "L 267.785594 207.638984 \n",
       "L 269.24188 198.885204 \n",
       "L 270.698165 201.250248 \n",
       "L 272.15445 211.911776 \n",
       "L 273.610736 201.594017 \n",
       "L 275.067021 212.874055 \n",
       "L 276.523306 211.686838 \n",
       "L 277.979592 204.703111 \n",
       "L 279.435877 213.021845 \n",
       "L 280.892162 201.511647 \n",
       "L 282.348448 192.275879 \n",
       "L 283.804733 212.987731 \n",
       "L 285.261018 202.160957 \n",
       "L 286.717304 213.19697 \n",
       "L 288.173589 214.334505 \n",
       "L 289.629874 214.563821 \n",
       "L 291.08616 214.676001 \n",
       "L 292.542445 213.809107 \n",
       "L 293.99873 199.242719 \n",
       "L 295.455016 214.783657 \n",
       "L 296.911301 204.494622 \n",
       "L 298.367586 203.680026 \n",
       "L 299.823872 211.366466 \n",
       "L 301.280157 206.883647 \n",
       "L 304.192728 217.230825 \n",
       "L 305.649013 216.888252 \n",
       "L 307.105298 212.972733 \n",
       "L 308.561584 215.247341 \n",
       "L 310.017869 216.385891 \n",
       "L 311.474155 219.491359 \n",
       "L 312.93044 218.711406 \n",
       "L 314.386725 212.649179 \n",
       "L 315.843011 219.011446 \n",
       "L 317.299296 218.207127 \n",
       "L 318.755581 217.604838 \n",
       "L 320.211867 218.80218 \n",
       "L 321.668152 221.09013 \n",
       "L 323.124437 221.496257 \n",
       "L 324.580723 223.858278 \n",
       "L 327.493293 223.065858 \n",
       "L 328.949579 221.9045 \n",
       "L 330.405864 223.037062 \n",
       "L 331.862149 223.030801 \n",
       "L 333.318435 225.08215 \n",
       "L 334.77472 224.105859 \n",
       "L 336.231005 223.464838 \n",
       "L 337.687291 226.228132 \n",
       "L 339.143576 222.567132 \n",
       "L 340.599861 223.95959 \n",
       "L 342.056147 225.670823 \n",
       "L 344.968717 224.555078 \n",
       "L 346.425003 226.649451 \n",
       "L 347.881288 224.501415 \n",
       "L 349.337573 226.947226 \n",
       "L 350.793859 218.741908 \n",
       "L 352.250144 228.181072 \n",
       "L 353.706429 227.584221 \n",
       "L 355.162715 228.466251 \n",
       "L 356.619 227.646105 \n",
       "L 358.075285 228.587584 \n",
       "L 359.531571 228.679835 \n",
       "L 360.987856 227.198177 \n",
       "L 362.444141 229.135313 \n",
       "L 363.900427 228.421564 \n",
       "L 365.356712 228.611791 \n",
       "L 366.812997 229.613561 \n",
       "L 369.725568 229.874489 \n",
       "L 369.725568 229.874489 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path clip-path=\"url(#p2deb31fa71)\" d=\"M 65.361932 77.58988 \n",
       "L 66.818217 81.066124 \n",
       "L 68.274503 75.040316 \n",
       "L 69.730788 59.68255 \n",
       "L 71.187073 49.179785 \n",
       "L 72.643359 53.709709 \n",
       "L 74.099644 66.090096 \n",
       "L 75.555929 62.807766 \n",
       "L 77.012215 64.339119 \n",
       "L 78.4685 82.54621 \n",
       "L 79.924785 86.903551 \n",
       "L 81.381071 95.793152 \n",
       "L 82.837356 95.065373 \n",
       "L 84.293641 94.583691 \n",
       "L 85.749927 99.968215 \n",
       "L 87.206212 104.548302 \n",
       "L 88.662497 108.248574 \n",
       "L 90.118783 111.145994 \n",
       "L 91.575068 111.55688 \n",
       "L 93.031353 112.79252 \n",
       "L 94.487639 114.994051 \n",
       "L 95.943924 112.840259 \n",
       "L 97.400209 123.672441 \n",
       "L 98.856495 119.487314 \n",
       "L 100.31278 122.172838 \n",
       "L 101.769065 126.445056 \n",
       "L 103.225351 126.249035 \n",
       "L 104.681636 130.093121 \n",
       "L 106.137921 131.567077 \n",
       "L 107.594207 137.47914 \n",
       "L 109.050492 135.899509 \n",
       "L 110.506777 141.107003 \n",
       "L 111.963063 144.268036 \n",
       "L 113.419348 145.401663 \n",
       "L 114.875633 149.116641 \n",
       "L 116.331919 142.054335 \n",
       "L 117.788204 145.351252 \n",
       "L 119.244489 148.352608 \n",
       "L 120.700775 147.872696 \n",
       "L 122.15706 153.14428 \n",
       "L 123.613345 156.789877 \n",
       "L 125.069631 159.031217 \n",
       "L 126.525916 157.479744 \n",
       "L 127.982202 162.547542 \n",
       "L 129.438487 158.835704 \n",
       "L 130.894772 165.894076 \n",
       "L 132.351058 162.124975 \n",
       "L 133.807343 160.80409 \n",
       "L 135.263628 171.397283 \n",
       "L 136.719914 161.976116 \n",
       "L 139.632484 176.995557 \n",
       "L 141.08877 174.654227 \n",
       "L 142.545055 174.627274 \n",
       "L 144.00134 174.912504 \n",
       "L 145.457626 166.245072 \n",
       "L 146.913911 172.404163 \n",
       "L 148.370196 168.560934 \n",
       "L 149.826482 170.960243 \n",
       "L 151.282767 176.669401 \n",
       "L 152.739052 179.978354 \n",
       "L 154.195338 182.176605 \n",
       "L 155.651623 186.331822 \n",
       "L 157.107908 176.509578 \n",
       "L 158.564194 181.035308 \n",
       "L 160.020479 186.854024 \n",
       "L 162.93305 182.065759 \n",
       "L 164.389335 186.600867 \n",
       "L 165.84562 183.16142 \n",
       "L 167.301906 185.697137 \n",
       "L 168.758191 190.885901 \n",
       "L 170.214476 187.603248 \n",
       "L 171.670762 189.032428 \n",
       "L 173.127047 188.304323 \n",
       "L 174.583332 188.951029 \n",
       "L 176.039618 193.387054 \n",
       "L 177.495903 184.075312 \n",
       "L 178.952188 188.318108 \n",
       "L 180.408474 188.915088 \n",
       "L 181.864759 199.21923 \n",
       "L 183.321044 195.770117 \n",
       "L 184.77733 189.653164 \n",
       "L 186.233615 193.866903 \n",
       "L 187.689901 191.526186 \n",
       "L 189.146186 192.482683 \n",
       "L 190.602471 190.526193 \n",
       "L 192.058757 189.062538 \n",
       "L 193.515042 190.834386 \n",
       "L 194.971327 196.820863 \n",
       "L 196.427613 198.012425 \n",
       "L 197.883898 194.478756 \n",
       "L 199.340183 195.446344 \n",
       "L 200.796469 198.152721 \n",
       "L 202.252754 195.562685 \n",
       "L 203.709039 196.052699 \n",
       "L 205.165325 201.093512 \n",
       "L 206.62161 195.768372 \n",
       "L 208.077895 197.157995 \n",
       "L 209.534181 203.073351 \n",
       "L 210.990466 203.625609 \n",
       "L 212.446751 192.799508 \n",
       "L 213.903037 201.131473 \n",
       "L 215.359322 204.016841 \n",
       "L 216.815607 207.82563 \n",
       "L 218.271893 200.94983 \n",
       "L 219.728178 202.115067 \n",
       "L 221.184463 197.52143 \n",
       "L 222.640749 198.385105 \n",
       "L 224.097034 201.978479 \n",
       "L 225.553319 206.032831 \n",
       "L 228.46589 199.461585 \n",
       "L 229.922175 194.889144 \n",
       "L 231.378461 201.215868 \n",
       "L 232.834746 197.641505 \n",
       "L 234.291031 211.957436 \n",
       "L 235.747317 210.065157 \n",
       "L 237.203602 204.869399 \n",
       "L 238.659887 206.335177 \n",
       "L 240.116173 213.441024 \n",
       "L 241.572458 209.465792 \n",
       "L 243.028743 206.062093 \n",
       "L 244.485029 204.960918 \n",
       "L 245.941314 208.189211 \n",
       "L 247.397599 206.712209 \n",
       "L 248.853885 204.054007 \n",
       "L 250.31017 207.340384 \n",
       "L 251.766456 209.280707 \n",
       "L 253.222741 208.804151 \n",
       "L 254.679026 218.758942 \n",
       "L 256.135312 212.331922 \n",
       "L 257.591597 207.932194 \n",
       "L 259.047882 205.563051 \n",
       "L 260.504168 210.204957 \n",
       "L 261.960453 210.212329 \n",
       "L 263.416738 208.302818 \n",
       "L 264.873024 210.34531 \n",
       "L 266.329309 215.508772 \n",
       "L 267.785594 207.341063 \n",
       "L 269.24188 215.589648 \n",
       "L 270.698165 217.083106 \n",
       "L 272.15445 214.099371 \n",
       "L 273.610736 212.438858 \n",
       "L 275.067021 217.438548 \n",
       "L 276.523306 214.179407 \n",
       "L 277.979592 212.949628 \n",
       "L 279.435877 213.392183 \n",
       "L 280.892162 211.423189 \n",
       "L 282.348448 214.923276 \n",
       "L 283.804733 214.125218 \n",
       "L 285.261018 212.990239 \n",
       "L 286.717304 211.699774 \n",
       "L 288.173589 211.309915 \n",
       "L 289.629874 211.366012 \n",
       "L 291.08616 214.494464 \n",
       "L 292.542445 211.786219 \n",
       "L 293.99873 213.76788 \n",
       "L 295.455016 217.404209 \n",
       "L 296.911301 214.259279 \n",
       "L 299.823872 222.384366 \n",
       "L 301.280157 218.810765 \n",
       "L 302.736442 216.434993 \n",
       "L 305.649013 215.079465 \n",
       "L 307.105298 214.932526 \n",
       "L 308.561584 215.287083 \n",
       "L 310.017869 217.019794 \n",
       "L 311.474155 217.549118 \n",
       "L 312.93044 218.956906 \n",
       "L 314.386725 218.604851 \n",
       "L 315.843011 219.527193 \n",
       "L 317.299296 219.732419 \n",
       "L 320.211867 221.373246 \n",
       "L 323.124437 222.734937 \n",
       "L 324.580723 223.159271 \n",
       "L 326.037008 223.237837 \n",
       "L 327.493293 223.642233 \n",
       "L 328.949579 222.825995 \n",
       "L 330.405864 223.021917 \n",
       "L 331.862149 224.304863 \n",
       "L 333.318435 224.235371 \n",
       "L 334.77472 224.890543 \n",
       "L 336.231005 225.350009 \n",
       "L 339.143576 224.825733 \n",
       "L 340.599861 225.951124 \n",
       "L 342.056147 226.122664 \n",
       "L 343.512432 225.436529 \n",
       "L 344.968717 226.262676 \n",
       "L 347.881288 226.949759 \n",
       "L 349.337573 226.55373 \n",
       "L 350.793859 226.500904 \n",
       "L 353.706429 227.842596 \n",
       "L 355.162715 228.114585 \n",
       "L 358.075285 227.979815 \n",
       "L 359.531571 228.081686 \n",
       "L 360.987856 228.50562 \n",
       "L 362.444141 228.328053 \n",
       "L 365.356712 228.281659 \n",
       "L 366.812997 229.069748 \n",
       "L 368.269283 228.939731 \n",
       "L 369.725568 229.227406 \n",
       "L 369.725568 229.227406 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 50.14375 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 384.94375 239.758125 \n",
       "L 384.94375 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 384.94375 239.758125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 50.14375 22.318125 \n",
       "L 384.94375 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_17\">\n",
       "    <!-- autoencoder loss over time -->\n",
       "    <defs>\n",
       "     <path d=\"M 34.28125 27.484375 \n",
       "Q 23.390625 27.484375 19.1875 25 \n",
       "Q 14.984375 22.515625 14.984375 16.5 \n",
       "Q 14.984375 11.71875 18.140625 8.90625 \n",
       "Q 21.296875 6.109375 26.703125 6.109375 \n",
       "Q 34.1875 6.109375 38.703125 11.40625 \n",
       "Q 43.21875 16.703125 43.21875 25.484375 \n",
       "L 43.21875 27.484375 \n",
       "z\n",
       "M 52.203125 31.203125 \n",
       "L 52.203125 0 \n",
       "L 43.21875 0 \n",
       "L 43.21875 8.296875 \n",
       "Q 40.140625 3.328125 35.546875 0.953125 \n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \n",
       "Q 6 8.015625 6 15.921875 \n",
       "Q 6 25.140625 12.171875 29.828125 \n",
       "Q 18.359375 34.515625 30.609375 34.515625 \n",
       "L 43.21875 34.515625 \n",
       "L 43.21875 35.40625 \n",
       "Q 43.21875 41.609375 39.140625 45 \n",
       "Q 35.0625 48.390625 27.6875 48.390625 \n",
       "Q 23 48.390625 18.546875 47.265625 \n",
       "Q 14.109375 46.140625 10.015625 43.890625 \n",
       "L 10.015625 52.203125 \n",
       "Q 14.9375 54.109375 19.578125 55.046875 \n",
       "Q 24.21875 56 28.609375 56 \n",
       "Q 40.484375 56 46.34375 49.84375 \n",
       "Q 52.203125 43.703125 52.203125 31.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-97\"/>\n",
       "     <path d=\"M 8.5 21.578125 \n",
       "L 8.5 54.6875 \n",
       "L 17.484375 54.6875 \n",
       "L 17.484375 21.921875 \n",
       "Q 17.484375 14.15625 20.5 10.265625 \n",
       "Q 23.53125 6.390625 29.59375 6.390625 \n",
       "Q 36.859375 6.390625 41.078125 11.03125 \n",
       "Q 45.3125 15.671875 45.3125 23.6875 \n",
       "L 45.3125 54.6875 \n",
       "L 54.296875 54.6875 \n",
       "L 54.296875 0 \n",
       "L 45.3125 0 \n",
       "L 45.3125 8.40625 \n",
       "Q 42.046875 3.421875 37.71875 1 \n",
       "Q 33.40625 -1.421875 27.6875 -1.421875 \n",
       "Q 18.265625 -1.421875 13.375 4.4375 \n",
       "Q 8.5 10.296875 8.5 21.578125 \n",
       "z\n",
       "M 31.109375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-117\"/>\n",
       "     <path d=\"M 18.3125 70.21875 \n",
       "L 18.3125 54.6875 \n",
       "L 36.8125 54.6875 \n",
       "L 36.8125 47.703125 \n",
       "L 18.3125 47.703125 \n",
       "L 18.3125 18.015625 \n",
       "Q 18.3125 11.328125 20.140625 9.421875 \n",
       "Q 21.96875 7.515625 27.59375 7.515625 \n",
       "L 36.8125 7.515625 \n",
       "L 36.8125 0 \n",
       "L 27.59375 0 \n",
       "Q 17.1875 0 13.234375 3.875 \n",
       "Q 9.28125 7.765625 9.28125 18.015625 \n",
       "L 9.28125 47.703125 \n",
       "L 2.6875 47.703125 \n",
       "L 2.6875 54.6875 \n",
       "L 9.28125 54.6875 \n",
       "L 9.28125 70.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-116\"/>\n",
       "     <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-110\"/>\n",
       "     <path d=\"M 45.40625 46.390625 \n",
       "L 45.40625 75.984375 \n",
       "L 54.390625 75.984375 \n",
       "L 54.390625 0 \n",
       "L 45.40625 0 \n",
       "L 45.40625 8.203125 \n",
       "Q 42.578125 3.328125 38.25 0.953125 \n",
       "Q 33.9375 -1.421875 27.875 -1.421875 \n",
       "Q 17.96875 -1.421875 11.734375 6.484375 \n",
       "Q 5.515625 14.40625 5.515625 27.296875 \n",
       "Q 5.515625 40.1875 11.734375 48.09375 \n",
       "Q 17.96875 56 27.875 56 \n",
       "Q 33.9375 56 38.25 53.625 \n",
       "Q 42.578125 51.265625 45.40625 46.390625 \n",
       "z\n",
       "M 14.796875 27.296875 \n",
       "Q 14.796875 17.390625 18.875 11.75 \n",
       "Q 22.953125 6.109375 30.078125 6.109375 \n",
       "Q 37.203125 6.109375 41.296875 11.75 \n",
       "Q 45.40625 17.390625 45.40625 27.296875 \n",
       "Q 45.40625 37.203125 41.296875 42.84375 \n",
       "Q 37.203125 48.484375 30.078125 48.484375 \n",
       "Q 22.953125 48.484375 18.875 42.84375 \n",
       "Q 14.796875 37.203125 14.796875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-100\"/>\n",
       "     <path d=\"M 41.109375 46.296875 \n",
       "Q 39.59375 47.171875 37.8125 47.578125 \n",
       "Q 36.03125 48 33.890625 48 \n",
       "Q 26.265625 48 22.1875 43.046875 \n",
       "Q 18.109375 38.09375 18.109375 28.8125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 20.953125 51.171875 25.484375 53.578125 \n",
       "Q 30.03125 56 36.53125 56 \n",
       "Q 37.453125 56 38.578125 55.875 \n",
       "Q 39.703125 55.765625 41.0625 55.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-114\"/>\n",
       "     <path d=\"M 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 8.796875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "L 35.6875 0 \n",
       "L 23.484375 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-118\"/>\n",
       "     <path d=\"M 9.421875 54.6875 \n",
       "L 18.40625 54.6875 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 64.59375 \n",
       "L 9.421875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-105\"/>\n",
       "     <path d=\"M 52 44.1875 \n",
       "Q 55.375 50.25 60.0625 53.125 \n",
       "Q 64.75 56 71.09375 56 \n",
       "Q 79.640625 56 84.28125 50.015625 \n",
       "Q 88.921875 44.046875 88.921875 33.015625 \n",
       "L 88.921875 0 \n",
       "L 79.890625 0 \n",
       "L 79.890625 32.71875 \n",
       "Q 79.890625 40.578125 77.09375 44.375 \n",
       "Q 74.3125 48.1875 68.609375 48.1875 \n",
       "Q 61.625 48.1875 57.5625 43.546875 \n",
       "Q 53.515625 38.921875 53.515625 30.90625 \n",
       "L 53.515625 0 \n",
       "L 44.484375 0 \n",
       "L 44.484375 32.71875 \n",
       "Q 44.484375 40.625 41.703125 44.40625 \n",
       "Q 38.921875 48.1875 33.109375 48.1875 \n",
       "Q 26.21875 48.1875 22.15625 43.53125 \n",
       "Q 18.109375 38.875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.1875 51.21875 25.484375 53.609375 \n",
       "Q 29.78125 56 35.6875 56 \n",
       "Q 41.65625 56 45.828125 52.96875 \n",
       "Q 50 49.953125 52 44.1875 \n",
       "z\n",
       "\" id=\"DejaVuSans-109\"/>\n",
       "    </defs>\n",
       "    <g transform=\"translate(135.3625 16.318125)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-97\"/>\n",
       "     <use x=\"61.279297\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "     <use x=\"124.658203\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "     <use x=\"163.867188\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"225.048828\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"286.572266\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "     <use x=\"349.951172\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "     <use x=\"404.931641\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"466.113281\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "     <use x=\"529.589844\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"591.113281\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "     <use x=\"632.226562\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"664.013672\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "     <use x=\"691.796875\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"752.978516\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "     <use x=\"805.078125\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "     <use x=\"857.177734\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"888.964844\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"950.146484\" xlink:href=\"#DejaVuSans-118\"/>\n",
       "     <use x=\"1009.326172\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"1070.849609\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "     <use x=\"1111.962891\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"1143.75\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "     <use x=\"1182.958984\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "     <use x=\"1210.742188\" xlink:href=\"#DejaVuSans-109\"/>\n",
       "     <use x=\"1308.154297\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p2deb31fa71\">\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"50.14375\" y=\"22.318125\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(losses1['epoch'], losses1['train_loss'])\n",
    "ax.plot(losses1['epoch'], losses1['validation_loss'])\n",
    "ax.set_ylabel('MSE loss')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_title('autoencoder loss over time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded1 = ae1.get_encoded_representations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('autoencodercon_embeddings.pkl', 'wb') as fh:\n",
    "    pickle.dump(encoded1, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'tfidf_matrix.pkl', 'rb') as fh:\n",
    "    tfidf_df1 = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae2 = AutoEncoder(new_df1, validation_perc=0.1, lr=1e-3, intermediate_size=3000, encoded_size=100)\n",
    "ae2 = AutoEncoder(tfidf_df1, validation_perc=0.1, lr=1e-3, intermediate_size=900, encoded_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "i= 20\n",
      "train loss: 0.23530476 | validation loss: 0.18365635\n",
      "i= 40\n",
      "train loss: 0.22357292 | validation loss: 0.19156446\n",
      "i= 60\n",
      "train loss: 0.22732845 | validation loss: 0.19618365\n",
      "i= 80\n",
      "train loss: 0.21548831 | validation loss: 0.20167594\n",
      "i= 100\n",
      "train loss: 0.21266311 | validation loss: 0.21435273\n",
      "i= 120\n",
      "train loss: 0.20898134 | validation loss: 0.20511483\n",
      "i= 140\n",
      "train loss: 0.2040506 | validation loss: 0.20580655\n",
      "Epoch 2/30\n",
      "i= 20\n",
      "train loss: 0.20361391 | validation loss: 0.19221185\n",
      "i= 40\n",
      "train loss: 0.19174379 | validation loss: 0.19801868\n",
      "i= 60\n",
      "train loss: 0.18998598 | validation loss: 0.18013354\n",
      "i= 80\n",
      "train loss: 0.19024231 | validation loss: 0.17321955\n",
      "i= 100\n",
      "train loss: 0.18127784 | validation loss: 0.1703154\n",
      "i= 120\n",
      "train loss: 0.17620385 | validation loss: 0.17059261\n",
      "i= 140\n",
      "train loss: 0.16991983 | validation loss: 0.17320888\n",
      "Epoch 3/30\n",
      "i= 20\n",
      "train loss: 0.17265868 | validation loss: 0.15576218\n",
      "i= 40\n",
      "train loss: 0.16534144 | validation loss: 0.15535089\n",
      "i= 60\n",
      "train loss: 0.17951332 | validation loss: 0.15295382\n",
      "i= 80\n",
      "train loss: 0.15291764 | validation loss: 0.14932308\n",
      "i= 100\n",
      "train loss: 0.15718099 | validation loss: 0.1549854\n",
      "i= 120\n",
      "train loss: 0.14808629 | validation loss: 0.13991246\n",
      "i= 140\n",
      "train loss: 0.14463593 | validation loss: 0.14249673\n",
      "Epoch 4/30\n",
      "i= 20\n",
      "train loss: 0.14626591 | validation loss: 0.13388181\n",
      "i= 40\n",
      "train loss: 0.14117284 | validation loss: 0.1278979\n",
      "i= 60\n",
      "train loss: 0.14361492 | validation loss: 0.13526832\n",
      "i= 80\n",
      "train loss: 0.13899812 | validation loss: 0.12574412\n",
      "i= 100\n",
      "train loss: 0.13436951 | validation loss: 0.12574197\n",
      "i= 120\n",
      "train loss: 0.12948118 | validation loss: 0.11831342\n",
      "i= 140\n",
      "train loss: 0.12748867 | validation loss: 0.11756403\n",
      "Epoch 5/30\n",
      "i= 20\n",
      "train loss: 0.12914659 | validation loss: 0.11116733\n",
      "i= 40\n",
      "train loss: 0.12202034 | validation loss: 0.11753136\n",
      "i= 60\n",
      "train loss: 0.13594826 | validation loss: 0.10568228\n",
      "i= 80\n",
      "train loss: 0.11283909 | validation loss: 0.11470176\n",
      "i= 100\n",
      "train loss: 0.11788195 | validation loss: 0.10755084\n",
      "i= 120\n",
      "train loss: 0.11084398 | validation loss: 0.10308205\n",
      "i= 140\n",
      "train loss: 0.11896316 | validation loss: 0.10297068\n",
      "Epoch 6/30\n",
      "i= 20\n",
      "train loss: 0.10952062 | validation loss: 0.09520605\n",
      "i= 40\n",
      "train loss: 0.11444058 | validation loss: 0.09667324\n",
      "i= 60\n",
      "train loss: 0.1049283 | validation loss: 0.10228463\n",
      "i= 80\n",
      "train loss: 0.10134018 | validation loss: 0.09473376\n",
      "i= 100\n",
      "train loss: 0.10898032 | validation loss: 0.0952788\n",
      "i= 120\n",
      "train loss: 0.09484854 | validation loss: 0.09324907\n",
      "i= 140\n",
      "train loss: 0.09685306 | validation loss: 0.08769712\n",
      "Epoch 7/30\n",
      "i= 20\n",
      "train loss: 0.09542667 | validation loss: 0.08945453\n",
      "i= 40\n",
      "train loss: 0.08660918 | validation loss: 0.09057941\n",
      "i= 60\n",
      "train loss: 0.08644132 | validation loss: 0.07185823\n",
      "i= 80\n",
      "train loss: 0.0979586 | validation loss: 0.08463403\n",
      "i= 100\n",
      "train loss: 0.09182357 | validation loss: 0.08422542\n",
      "i= 120\n",
      "train loss: 0.08076667 | validation loss: 0.07992589\n",
      "i= 140\n",
      "train loss: 0.08625407 | validation loss: 0.063983\n",
      "Epoch 8/30\n",
      "i= 20\n",
      "train loss: 0.08378197 | validation loss: 0.07541882\n",
      "i= 40\n",
      "train loss: 0.08300015 | validation loss: 0.07525108\n",
      "i= 60\n",
      "train loss: 0.08167957 | validation loss: 0.07389975\n",
      "i= 80\n",
      "train loss: 0.07353187 | validation loss: 0.07130577\n",
      "i= 100\n",
      "train loss: 0.07251542 | validation loss: 0.07053277\n",
      "i= 120\n",
      "train loss: 0.07119852 | validation loss: 0.07125675\n",
      "i= 140\n",
      "train loss: 0.07075696 | validation loss: 0.0730454\n",
      "Epoch 9/30\n",
      "i= 20\n",
      "train loss: 0.08011461 | validation loss: 0.06784166\n",
      "i= 40\n",
      "train loss: 0.07582614 | validation loss: 0.07084225\n",
      "i= 60\n",
      "train loss: 0.07492144 | validation loss: 0.06626924\n",
      "i= 80\n",
      "train loss: 0.06603949 | validation loss: 0.06057146\n",
      "i= 100\n",
      "train loss: 0.07420916 | validation loss: 0.06230174\n",
      "i= 120\n",
      "train loss: 0.06320687 | validation loss: 0.06216326\n",
      "i= 140\n",
      "train loss: 0.07111188 | validation loss: 0.06214586\n",
      "Epoch 10/30\n",
      "i= 20\n",
      "train loss: 0.07187628 | validation loss: 0.06249427\n",
      "i= 40\n",
      "train loss: 0.06024843 | validation loss: 0.06363601\n",
      "i= 60\n",
      "train loss: 0.0682098 | validation loss: 0.05677301\n",
      "i= 80\n",
      "train loss: 0.06771661 | validation loss: 0.05543276\n",
      "i= 100\n",
      "train loss: 0.06774087 | validation loss: 0.04993134\n",
      "i= 120\n",
      "train loss: 0.06765638 | validation loss: 0.0563375\n",
      "i= 140\n",
      "train loss: 0.09404762 | validation loss: 0.05172408\n",
      "Epoch 11/30\n",
      "i= 20\n",
      "train loss: 0.06368006 | validation loss: 0.05360141\n",
      "i= 40\n",
      "train loss: 0.06838719 | validation loss: 0.05602364\n",
      "i= 60\n",
      "train loss: 0.06925341 | validation loss: 0.04984425\n",
      "i= 80\n",
      "train loss: 0.06193637 | validation loss: 0.04602223\n",
      "i= 100\n",
      "train loss: 0.05204164 | validation loss: 0.05065059\n",
      "i= 120\n",
      "train loss: 0.06102741 | validation loss: 0.04831352\n",
      "i= 140\n",
      "train loss: 0.0536704 | validation loss: 0.04097921\n",
      "Epoch 12/30\n",
      "i= 20\n",
      "train loss: 0.06269561 | validation loss: 0.04360813\n",
      "i= 40\n",
      "train loss: 0.05982195 | validation loss: 0.0425592\n",
      "i= 60\n",
      "train loss: 0.05332039 | validation loss: 0.03952998\n",
      "i= 80\n",
      "train loss: 0.06119099 | validation loss: 0.04523645\n",
      "i= 100\n",
      "train loss: 0.05777949 | validation loss: 0.04627054\n",
      "i= 120\n",
      "train loss: 0.07137539 | validation loss: 0.03817412\n",
      "i= 140\n",
      "train loss: 0.04778054 | validation loss: 0.04214405\n",
      "Epoch 13/30\n",
      "i= 20\n",
      "train loss: 0.0584269 | validation loss: 0.04098186\n",
      "i= 40\n",
      "train loss: 0.04482082 | validation loss: 0.0383706\n",
      "i= 60\n",
      "train loss: 0.04458958 | validation loss: 0.0351669\n",
      "i= 80\n",
      "train loss: 0.0437767 | validation loss: 0.04157354\n",
      "i= 100\n",
      "train loss: 0.0433347 | validation loss: 0.04075324\n",
      "i= 120\n",
      "train loss: 0.04282246 | validation loss: 0.03995426\n",
      "i= 140\n",
      "train loss: 0.06154273 | validation loss: 0.04208741\n",
      "Epoch 14/30\n",
      "i= 20\n",
      "train loss: 0.05462409 | validation loss: 0.03429924\n",
      "i= 40\n",
      "train loss: 0.04117428 | validation loss: 0.03895343\n",
      "i= 60\n",
      "train loss: 0.04093044 | validation loss: 0.04155585\n",
      "i= 80\n",
      "train loss: 0.05143395 | validation loss: 0.03895171\n",
      "i= 100\n",
      "train loss: 0.03991668 | validation loss: 0.0389512\n",
      "i= 120\n",
      "train loss: 0.04461922 | validation loss: 0.03715242\n",
      "i= 140\n",
      "train loss: 0.03981341 | validation loss: 0.04083684\n",
      "Epoch 15/30\n",
      "i= 20\n",
      "train loss: 0.05189347 | validation loss: 0.04094293\n",
      "i= 40\n",
      "train loss: 0.03884741 | validation loss: 0.03920605\n",
      "i= 60\n",
      "train loss: 0.03898388 | validation loss: 0.02741336\n",
      "i= 80\n",
      "train loss: 0.05089994 | validation loss: 0.0312016\n",
      "i= 100\n",
      "train loss: 0.03717823 | validation loss: 0.03450439\n",
      "i= 120\n",
      "train loss: 0.04895264 | validation loss: 0.0310146\n",
      "i= 140\n",
      "train loss: 0.03737779 | validation loss: 0.02769677\n",
      "Epoch 16/30\n",
      "i= 20\n",
      "train loss: 0.03591501 | validation loss: 0.02861123\n",
      "i= 40\n",
      "train loss: 0.03555446 | validation loss: 0.03137777\n",
      "i= 60\n",
      "train loss: 0.0351974 | validation loss: 0.03223465\n",
      "i= 80\n",
      "train loss: 0.0469745 | validation loss: 0.03135785\n",
      "i= 100\n",
      "train loss: 0.05204542 | validation loss: 0.03437843\n",
      "i= 120\n",
      "train loss: 0.03424992 | validation loss: 0.03232937\n",
      "i= 140\n",
      "train loss: 0.03393484 | validation loss: 0.02836427\n",
      "Epoch 17/30\n",
      "i= 20\n",
      "train loss: 0.0335455 | validation loss: 0.02510571\n",
      "i= 40\n",
      "train loss: 0.04035994 | validation loss: 0.02477229\n",
      "i= 60\n",
      "train loss: 0.03369592 | validation loss: 0.02482977\n",
      "i= 80\n",
      "train loss: 0.03292447 | validation loss: 0.02467346\n",
      "i= 100\n",
      "train loss: 0.04475824 | validation loss: 0.02642013\n",
      "i= 120\n",
      "train loss: 0.04355693 | validation loss: 0.02566692\n",
      "i= 140\n",
      "train loss: 0.03188359 | validation loss: 0.031962\n",
      "Epoch 18/30\n",
      "i= 20\n",
      "train loss: 0.05555933 | validation loss: 0.02818813\n",
      "i= 40\n",
      "train loss: 0.03166757 | validation loss: 0.02998292\n",
      "i= 60\n",
      "train loss: 0.03697183 | validation loss: 0.02324459\n",
      "i= 80\n",
      "train loss: 0.03077623 | validation loss: 0.02668251\n",
      "i= 100\n",
      "train loss: 0.05480861 | validation loss: 0.0243529\n",
      "i= 120\n",
      "train loss: 0.0353299 | validation loss: 0.02359787\n",
      "i= 140\n",
      "train loss: 0.03019222 | validation loss: 0.0196636\n",
      "Epoch 19/30\n",
      "i= 20\n",
      "train loss: 0.03307957 | validation loss: 0.01997368\n",
      "i= 40\n",
      "train loss: 0.03001371 | validation loss: 0.01948057\n",
      "i= 60\n",
      "train loss: 0.02938469 | validation loss: 0.02172676\n",
      "i= 80\n",
      "train loss: 0.02911683 | validation loss: 0.02235327\n",
      "i= 100\n",
      "train loss: 0.02889087 | validation loss: 0.02245276\n",
      "i= 120\n",
      "train loss: 0.02957084 | validation loss: 0.02206983\n",
      "i= 140\n",
      "train loss: 0.03409155 | validation loss: 0.02394293\n",
      "Epoch 20/30\n",
      "i= 20\n",
      "train loss: 0.02902977 | validation loss: 0.0215119\n",
      "i= 40\n",
      "train loss: 0.04090313 | validation loss: 0.02097243\n",
      "i= 60\n",
      "train loss: 0.03309214 | validation loss: 0.01838075\n",
      "i= 80\n",
      "train loss: 0.02900941 | validation loss: 0.02186026\n",
      "i= 100\n",
      "train loss: 0.02833068 | validation loss: 0.02531722\n",
      "i= 120\n",
      "train loss: 0.02726591 | validation loss: 0.02170375\n",
      "i= 140\n",
      "train loss: 0.02720912 | validation loss: 0.02540787\n",
      "Epoch 21/30\n",
      "i= 20\n",
      "train loss: 0.02721683 | validation loss: 0.01943824\n",
      "i= 40\n",
      "train loss: 0.03979088 | validation loss: 0.02055992\n",
      "i= 60\n",
      "train loss: 0.0282128 | validation loss: 0.01929708\n",
      "i= 80\n",
      "train loss: 0.02983258 | validation loss: 0.01789249\n",
      "i= 100\n",
      "train loss: 0.0405463 | validation loss: 0.01779748\n",
      "i= 120\n",
      "train loss: 0.04064567 | validation loss: 0.02247795\n",
      "i= 140\n",
      "train loss: 0.02691813 | validation loss: 0.0173493\n",
      "Epoch 22/30\n",
      "i= 20\n",
      "train loss: 0.02714196 | validation loss: 0.02067208\n",
      "i= 40\n",
      "train loss: 0.02612319 | validation loss: 0.01771432\n",
      "i= 60\n",
      "train loss: 0.03731658 | validation loss: 0.01922722\n",
      "i= 80\n",
      "train loss: 0.02537596 | validation loss: 0.01689561\n",
      "i= 100\n",
      "train loss: 0.02547136 | validation loss: 0.0196669\n",
      "i= 120\n",
      "train loss: 0.03162799 | validation loss: 0.02004642\n",
      "i= 140\n",
      "train loss: 0.02460844 | validation loss: 0.01671248\n",
      "Epoch 23/30\n",
      "i= 20\n",
      "train loss: 0.02703699 | validation loss: 0.01592054\n",
      "i= 40\n",
      "train loss: 0.03079156 | validation loss: 0.02161217\n",
      "i= 60\n",
      "train loss: 0.02536624 | validation loss: 0.01893865\n",
      "i= 80\n",
      "train loss: 0.02506746 | validation loss: 0.01853459\n",
      "i= 100\n",
      "train loss: 0.02485021 | validation loss: 0.0196289\n",
      "i= 120\n",
      "train loss: 0.0331845 | validation loss: 0.0199659\n",
      "i= 140\n",
      "train loss: 0.02499285 | validation loss: 0.0172451\n",
      "Epoch 24/30\n",
      "i= 20\n",
      "train loss: 0.02945014 | validation loss: 0.01763049\n",
      "i= 40\n",
      "train loss: 0.02477788 | validation loss: 0.01694822\n",
      "i= 60\n",
      "train loss: 0.03078888 | validation loss: 0.01512902\n",
      "i= 80\n",
      "train loss: 0.02307881 | validation loss: 0.01459112\n",
      "i= 100\n",
      "train loss: 0.02205977 | validation loss: 0.01751239\n",
      "i= 120\n",
      "train loss: 0.02221937 | validation loss: 0.01767096\n",
      "i= 140\n",
      "train loss: 0.02172894 | validation loss: 0.01692131\n",
      "Epoch 25/30\n",
      "i= 20\n",
      "train loss: 0.02132913 | validation loss: 0.01627743\n",
      "i= 40\n",
      "train loss: 0.0233853 | validation loss: 0.0181488\n",
      "i= 60\n",
      "train loss: 0.02132543 | validation loss: 0.01552245\n",
      "i= 80\n",
      "train loss: 0.02240325 | validation loss: 0.01666527\n",
      "i= 100\n",
      "train loss: 0.02213675 | validation loss: 0.02041414\n",
      "i= 120\n",
      "train loss: 0.0252949 | validation loss: 0.01820075\n",
      "i= 140\n",
      "train loss: 0.02564166 | validation loss: 0.01523235\n",
      "Epoch 26/30\n",
      "i= 20\n",
      "train loss: 0.02132939 | validation loss: 0.01736972\n",
      "i= 40\n",
      "train loss: 0.02011708 | validation loss: 0.01423959\n",
      "i= 60\n",
      "train loss: 0.01955726 | validation loss: 0.01383971\n",
      "i= 80\n",
      "train loss: 0.01982037 | validation loss: 0.0128564\n",
      "i= 100\n",
      "train loss: 0.02069251 | validation loss: 0.0152434\n",
      "i= 120\n",
      "train loss: 0.02006784 | validation loss: 0.01485829\n",
      "i= 140\n",
      "train loss: 0.02053092 | validation loss: 0.01679988\n",
      "Epoch 27/30\n",
      "i= 20\n",
      "train loss: 0.01637368 | validation loss: 0.01586702\n",
      "i= 40\n",
      "train loss: 0.01652594 | validation loss: 0.01576637\n",
      "i= 60\n",
      "train loss: 0.01757814 | validation loss: 0.01692859\n",
      "i= 80\n",
      "train loss: 0.01497411 | validation loss: 0.01445812\n",
      "i= 100\n",
      "train loss: 0.0178333 | validation loss: 0.0146671\n",
      "i= 120\n",
      "train loss: 0.01737181 | validation loss: 0.01454328\n",
      "i= 140\n",
      "train loss: 0.01922274 | validation loss: 0.01415844\n",
      "Epoch 28/30\n",
      "i= 20\n",
      "train loss: 0.01575886 | validation loss: 0.01315195\n",
      "i= 40\n",
      "train loss: 0.01506357 | validation loss: 0.01279358\n",
      "i= 60\n",
      "train loss: 0.01506509 | validation loss: 0.01206321\n",
      "i= 80\n",
      "train loss: 0.01465083 | validation loss: 0.01221517\n",
      "i= 100\n",
      "train loss: 0.0134171 | validation loss: 0.01224901\n",
      "i= 120\n",
      "train loss: 0.01163683 | validation loss: 0.01136001\n",
      "i= 140\n",
      "train loss: 0.01182284 | validation loss: 0.01160253\n",
      "Epoch 29/30\n",
      "i= 20\n",
      "train loss: 0.0120768 | validation loss: 0.01081002\n",
      "i= 40\n",
      "train loss: 0.01086374 | validation loss: 0.010857\n",
      "i= 60\n",
      "train loss: 0.01223662 | validation loss: 0.01095569\n",
      "i= 80\n",
      "train loss: 0.01042369 | validation loss: 0.01029699\n",
      "i= 100\n",
      "train loss: 0.01335667 | validation loss: 0.01025271\n",
      "i= 120\n",
      "train loss: 0.01008699 | validation loss: 0.00979764\n",
      "i= 140\n",
      "train loss: 0.00988713 | validation loss: 0.00980841\n",
      "Epoch 30/30\n",
      "i= 20\n",
      "train loss: 0.00998305 | validation loss: 0.00954483\n",
      "i= 40\n",
      "train loss: 0.01096215 | validation loss: 0.00960738\n",
      "i= 60\n",
      "train loss: 0.00914423 | validation loss: 0.0089531\n",
      "i= 80\n",
      "train loss: 0.0095521 | validation loss: 0.00915777\n",
      "i= 100\n",
      "train loss: 0.00884884 | validation loss: 0.00895681\n",
      "i= 120\n",
      "train loss: 0.00860752 | validation loss: 0.00840072\n",
      "i= 140\n",
      "train loss: 0.00894465 | validation loss: 0.00852053\n"
     ]
    }
   ],
   "source": [
    "ae2.train_loop(epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded2 = ae2.get_encoded_representations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10677, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('autoencodercon2_embeddings.pkl', 'wb') as fh:\n",
    "    pickle.dump(encoded2, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses2 = pd.DataFrame(data=list(zip(ae2.train_losses, ae2.val_losses)), columns=['train_loss', 'validation_loss'])\n",
    "losses2['epoch'] = (losses2.index + 1) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'new_df_matrix.pkl', 'rb') as fh:\n",
    "    new_df1 = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "def get_cv_idxs(n, cv_idx=0, val_pct=0.2, seed=42):\n",
    "    \"\"\" Get a list of index values for Validation set from a dataset\n",
    "\n",
    "    Arguments:\n",
    "        n : int, Total number of elements in the data set.\n",
    "        cv_idx : int, starting index [idx_start = cv_idx*int(val_pct*n)]\n",
    "        val_pct : (int, float), validation set percentage\n",
    "        seed : seed value for RandomState\n",
    "\n",
    "    Returns:\n",
    "        list of indexes\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    n_val = int(val_pct * n)\n",
    "    idx_start = cv_idx * n_val\n",
    "    idxs = np.random.permutation(n)\n",
    "    return idxs[idx_start:idx_start + n_val]\n",
    "\n",
    "\n",
    "def split_by_idx(idxs, *a):\n",
    "    \"\"\"\n",
    "    Split each array passed as *a, to a pair of arrays like this (elements selected by idxs,  the remaining elements)\n",
    "    This can be used to split multiple arrays containing training data to validation and training set.\n",
    "\n",
    "    :param idxs [int]: list of indexes selected\n",
    "    :param a list: list of np.array, each array should have same amount of elements in the first dimension\n",
    "    :return: list of tuples, each containing a split of corresponding array from *a.\n",
    "            First element of each tuple is an array composed from elements selected by idxs,\n",
    "            second element is an array of remaining elements.\n",
    "    \"\"\"\n",
    "    mask = np.zeros(len(a[0]), dtype=bool)\n",
    "    mask[np.array(idxs)] = True\n",
    "    return [(o[mask], o[~mask]) for o in a]\n",
    "\n",
    "\n",
    "class AutoEncoder(object):\n",
    "\n",
    "    def __init__(self, data, validation_perc=0.2, lr=0.001,\n",
    "                 intermediate_size=1000, encoded_size=100):\n",
    "\n",
    "        # create training dataloader and validation tensor\n",
    "        self.data = data\n",
    "        self.val_idxs = get_cv_idxs(n=data.shape[0], val_pct=validation_perc)\n",
    "        [(self.val, self.train)] = split_by_idx(self.val_idxs, data)\n",
    "        self.dataset = AETrainingData(self.train)\n",
    "        self.dataloader = DataLoader(self.dataset, batch_size=64, shuffle=True,\n",
    "                                     num_workers=multiprocessing.cpu_count())\n",
    "        #print('datal=',self.dataloader)\n",
    "        self.val = torch.from_numpy(self.val.values).\\\n",
    "            type(torch.FloatTensor).cuda()\n",
    "\n",
    "        # instantiate the encoder and decoder nets\n",
    "        size = data.shape[1]\n",
    "        self.encoder = Encoder(size, intermediate_size, encoded_size).cuda()\n",
    "        self.decoder = Decoder(size, intermediate_size, encoded_size).cuda()\n",
    "\n",
    "        # instantiate the optimizers\n",
    "        self.encoder_optimizer = optim.Adam(\n",
    "            self.encoder.parameters(), lr=lr, weight_decay=1e-8)\n",
    "        self.decoder_optimizer = optim.Adam(\n",
    "            self.decoder.parameters(), lr=lr, weight_decay=1e-8)\n",
    "\n",
    "        # instantiate the loss criterion\n",
    "        self.criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def train_step(self, input_tensor, target_tensor):\n",
    "        # clear the gradients in the optimizers\n",
    "        self.encoder_optimizer.zero_grad()\n",
    "        self.decoder_optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through\n",
    "        encoded_representation = self.encoder(input_tensor)\n",
    "        reconstruction = self.decoder(encoded_representation)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = self.criterion(reconstruction, target_tensor)\n",
    "\n",
    "        # Compute the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Step the optimizers to update the model weights\n",
    "        self.encoder_optimizer.step()\n",
    "        self.decoder_optimizer.step()\n",
    "\n",
    "        # Return the loss value to track training progress\n",
    "        return loss.item()\n",
    "    \n",
    "    def reset(self, train=True):\n",
    "        # due to dropout the network behaves differently in training and\n",
    "        # evaluation modes\n",
    "        if train: self.encoder.train(); self.decoder.train()\n",
    "        else: self.encoder.eval(); self.decoder.eval()\n",
    "\n",
    "    def get_val_loss(self, input_tensor, target_tensor):\n",
    "        self.reset(train=False)\n",
    "        encoded = self.encoder(input_tensor)\n",
    "        decoded = self.decoder(encoded)\n",
    "        loss = self.criterion(decoded, target_tensor)\n",
    "        return loss.item()\n",
    "\n",
    "    def train_loop(self, epochs, print_every_n_batches=20):\n",
    "\n",
    "        # Cycle through epochs\n",
    "        for epoch in range(epochs):\n",
    "            print(f'Epoch {epoch + 1}/{epochs}')\n",
    "\n",
    "            # Cycle through batches\n",
    "            for i, batch in enumerate(self.dataloader):\n",
    "                #print(i,batch)\n",
    "                \n",
    "                self.reset(train=True)\n",
    "\n",
    "                input_tensor = batch['input'].cuda()\n",
    "                target_tensor = batch['target'].cuda()\n",
    "\n",
    "                loss = self.train_step(input_tensor, target_tensor)\n",
    "\n",
    "                if i % print_every_n_batches == 0 and i != 0:\n",
    "                    #print('i=',i)\n",
    "                    val_loss = self.get_val_loss(self.val, self.val)\n",
    "                    print(f'train loss: {round(loss, 8)} | ' +\n",
    "                          f'validation loss: {round(val_loss, 8)}')\n",
    "                    self.train_losses.append(loss)\n",
    "                    self.val_losses.append(val_loss)\n",
    "\n",
    "    def get_encoded_representations(self):\n",
    "        to_encode = torch.from_numpy(self.data.values).type(\n",
    "            torch.FloatTensor).cuda()\n",
    "        self.reset(train=False)\n",
    "        encodings = self.encoder(to_encode).cpu().data.numpy()\n",
    "        return encodings\n",
    "\n",
    "\n",
    "class AETrainingData(Dataset):\n",
    "    \"\"\"\n",
    "    Format the training dataset to be input into the auto encoder.\n",
    "    Takes in dataframe and converts it to a PyTorch Tensor\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x_train):\n",
    "        self.x = x_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a example from the data set as a pytorch tensor.\n",
    "        \"\"\"\n",
    "        # Get example/target pair at idx as numpy arrays\n",
    "        x, y = self.x.iloc[idx].values, self.x.iloc[idx].values\n",
    "\n",
    "        # Convert to torch tensor\n",
    "        x = torch.from_numpy(x).type(torch.FloatTensor)\n",
    "        y = torch.from_numpy(y).type(torch.FloatTensor)\n",
    "\n",
    "        # Return pair\n",
    "        return {'input': x, 'target': y}\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, intermediate_size, encoding_size):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, intermediate_size),\n",
    "            nn.BatchNorm1d(intermediate_size),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(intermediate_size, encoding_size),\n",
    "            nn.BatchNorm1d(encoding_size),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, intermediate_size, encoding_size):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_size, intermediate_size),\n",
    "            nn.BatchNorm1d(intermediate_size),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(intermediate_size, output_size),\n",
    "            nn.BatchNorm1d(output_size),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'new_df_matrix.pkl', 'rb') as fh:\n",
    "    new_df1 = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae3 = AutoEncoder(new_df1, validation_perc=0.1, lr=1e-3, intermediate_size=1000, encoded_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae3.train_loop(epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae3.train_loop(epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae3.train_loop(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae3.train_loop(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses2 = pd.DataFrame(data=list(zip(ae3.train_losses, ae3.val_losses)), columns=['train_loss', 'validation_loss'])\n",
    "losses2['epoch'] = (losses2.index + 1) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded3 = ae3.get_encoded_representations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('autoencodercoll31_embeddings.pkl', 'wb') as fh:\n",
    "    pickle.dump(encoded3, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae_4 = AutoEncoder(new_df1, validation_perc=0.1, lr=1e-3, intermediate_size=1000, encoded_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae_4.train_loop(epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae_4.train_loop(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf=new_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf=ndf.apply(lambda x: x/x.max(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>69868</th>\n",
       "      <th>69869</th>\n",
       "      <th>69870</th>\n",
       "      <th>69871</th>\n",
       "      <th>69872</th>\n",
       "      <th>69873</th>\n",
       "      <th>69874</th>\n",
       "      <th>69875</th>\n",
       "      <th>69876</th>\n",
       "      <th>69877</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69878 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "1    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "2    1.0    0.0    0.0    0.2    0.0    0.0    0.0    0.6    0.0    0.0  ...   \n",
       "3    1.0    0.0    0.0    0.6    0.0    0.0    0.0    0.7    0.0    0.0  ...   \n",
       "4    1.0    0.0    0.0    1.0    0.0    0.0    0.0    0.9    0.0    0.0  ...   \n",
       "\n",
       "   69868  69869  69870  69871  69872  69873  69874  69875  69876  69877  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.4    0.0    0.0    0.0    0.0    0.0    0.6    0.0  \n",
       "2    0.0    0.0    0.2    0.0    0.4    0.0    0.6    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.6    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.6    0.0    0.0    0.0    0.0    0.0    0.6    0.8  \n",
       "\n",
       "[5 rows x 69878 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('ndf.pkl', 'wb') as fh:\n",
    "#     pickle.dump(ndf, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'ndf.pkl', 'rb') as fh:\n",
    "#     ndf1 = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_4 = AutoEncoder(ndf, validation_perc=0.1, lr=1e-3, intermediate_size=1000, encoded_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "train loss: 0.22579755 | validation loss: 0.24893086\n",
      "train loss: 0.2182643 | validation loss: 0.21357031\n",
      "train loss: 0.21496026 | validation loss: 0.20806929\n",
      "train loss: 0.21106842 | validation loss: 0.20373096\n",
      "train loss: 0.20224987 | validation loss: 0.19790372\n",
      "train loss: 0.19804391 | validation loss: 0.19965415\n",
      "train loss: 0.19187984 | validation loss: 0.18708843\n",
      "Epoch 2/50\n",
      "train loss: 0.1933123 | validation loss: 0.18844429\n",
      "train loss: 0.19149779 | validation loss: 0.18113759\n",
      "train loss: 0.17587638 | validation loss: 0.16672805\n",
      "train loss: 0.17481491 | validation loss: 0.1630431\n",
      "train loss: 0.17034365 | validation loss: 0.16115648\n",
      "train loss: 0.16301687 | validation loss: 0.16274516\n",
      "train loss: 0.18125041 | validation loss: 0.15972771\n",
      "Epoch 3/50\n",
      "train loss: 0.16036288 | validation loss: 0.15345499\n",
      "train loss: 0.15580224 | validation loss: 0.1512844\n",
      "train loss: 0.15296936 | validation loss: 0.14347586\n",
      "train loss: 0.15924722 | validation loss: 0.14307053\n",
      "train loss: 0.14570333 | validation loss: 0.13703826\n",
      "train loss: 0.1430784 | validation loss: 0.13806421\n",
      "train loss: 0.13836506 | validation loss: 0.12474991\n",
      "Epoch 4/50\n",
      "train loss: 0.13669597 | validation loss: 0.13230756\n",
      "train loss: 0.13477606 | validation loss: 0.12437446\n",
      "train loss: 0.1294955 | validation loss: 0.12561466\n",
      "train loss: 0.12604538 | validation loss: 0.12597589\n",
      "train loss: 0.12169126 | validation loss: 0.12063937\n",
      "train loss: 0.12188154 | validation loss: 0.1174822\n",
      "train loss: 0.13355441 | validation loss: 0.11304237\n",
      "Epoch 5/50\n",
      "train loss: 0.12496763 | validation loss: 0.11066609\n",
      "train loss: 0.11499049 | validation loss: 0.10595851\n",
      "train loss: 0.11887052 | validation loss: 0.10109407\n",
      "train loss: 0.11266433 | validation loss: 0.09507645\n",
      "train loss: 0.11230472 | validation loss: 0.0956967\n",
      "train loss: 0.11202075 | validation loss: 0.09729046\n",
      "train loss: 0.11361545 | validation loss: 0.09202866\n",
      "Epoch 6/50\n",
      "train loss: 0.0995746 | validation loss: 0.10046508\n",
      "train loss: 0.11012918 | validation loss: 0.08784048\n",
      "train loss: 0.09926321 | validation loss: 0.08529758\n",
      "train loss: 0.09431721 | validation loss: 0.08645413\n",
      "train loss: 0.09219228 | validation loss: 0.08590466\n",
      "train loss: 0.16562487 | validation loss: 0.08330279\n",
      "train loss: 0.08921717 | validation loss: 0.07898757\n",
      "Epoch 7/50\n",
      "train loss: 0.10205448 | validation loss: 0.08383088\n",
      "train loss: 0.08787658 | validation loss: 0.07982487\n",
      "train loss: 0.08342042 | validation loss: 0.07743493\n",
      "train loss: 0.08555569 | validation loss: 0.07521107\n",
      "train loss: 0.08664882 | validation loss: 0.07072093\n",
      "train loss: 0.07716206 | validation loss: 0.07064071\n",
      "train loss: 0.08495084 | validation loss: 0.07336962\n",
      "Epoch 8/50\n",
      "train loss: 0.0819416 | validation loss: 0.07275136\n",
      "train loss: 0.08767929 | validation loss: 0.07122836\n",
      "train loss: 0.07251195 | validation loss: 0.07035212\n",
      "train loss: 0.0736628 | validation loss: 0.06885295\n",
      "train loss: 0.0909421 | validation loss: 0.06980658\n",
      "train loss: 0.07555342 | validation loss: 0.06145224\n",
      "train loss: 0.07981082 | validation loss: 0.0633214\n",
      "Epoch 9/50\n",
      "train loss: 0.07328637 | validation loss: 0.06090964\n",
      "train loss: 0.06365324 | validation loss: 0.0582291\n",
      "train loss: 0.07319098 | validation loss: 0.0594477\n",
      "train loss: 0.06470902 | validation loss: 0.06095552\n",
      "train loss: 0.06029283 | validation loss: 0.05376841\n",
      "train loss: 0.06356253 | validation loss: 0.05963733\n",
      "train loss: 0.07306141 | validation loss: 0.05041966\n",
      "Epoch 10/50\n",
      "train loss: 0.06865948 | validation loss: 0.05384964\n",
      "train loss: 0.07756195 | validation loss: 0.05411961\n",
      "train loss: 0.05993765 | validation loss: 0.05252704\n",
      "train loss: 0.05711741 | validation loss: 0.05043235\n",
      "train loss: 0.05754621 | validation loss: 0.04824724\n",
      "train loss: 0.06631197 | validation loss: 0.04719486\n",
      "train loss: 0.05787111 | validation loss: 0.04839342\n",
      "Epoch 11/50\n",
      "train loss: 0.06652599 | validation loss: 0.05657785\n",
      "train loss: 0.05954397 | validation loss: 0.05038397\n",
      "train loss: 0.05403827 | validation loss: 0.05252659\n",
      "train loss: 0.05714065 | validation loss: 0.0498479\n",
      "train loss: 0.06126499 | validation loss: 0.04998242\n",
      "train loss: 0.05172008 | validation loss: 0.04795113\n",
      "train loss: 0.04791233 | validation loss: 0.04316279\n",
      "Epoch 12/50\n",
      "train loss: 0.05818111 | validation loss: 0.0451232\n",
      "train loss: 0.07239279 | validation loss: 0.04858153\n",
      "train loss: 0.06682017 | validation loss: 0.04710077\n",
      "train loss: 0.04593291 | validation loss: 0.04534511\n",
      "train loss: 0.056844 | validation loss: 0.04018354\n",
      "train loss: 0.04743845 | validation loss: 0.03889966\n",
      "train loss: 0.04600153 | validation loss: 0.03843632\n",
      "Epoch 13/50\n",
      "train loss: 0.04780691 | validation loss: 0.0385889\n",
      "train loss: 0.04664168 | validation loss: 0.04147962\n",
      "train loss: 0.04753462 | validation loss: 0.03932753\n",
      "train loss: 0.05691499 | validation loss: 0.03779915\n",
      "train loss: 0.04996948 | validation loss: 0.03853875\n",
      "train loss: 0.05996865 | validation loss: 0.03754724\n",
      "train loss: 0.05141435 | validation loss: 0.03925369\n",
      "Epoch 14/50\n",
      "train loss: 0.04364158 | validation loss: 0.03871541\n",
      "train loss: 0.0544399 | validation loss: 0.03535954\n",
      "train loss: 0.04057198 | validation loss: 0.0420729\n",
      "train loss: 0.04208669 | validation loss: 0.03274164\n",
      "train loss: 0.03820991 | validation loss: 0.0351312\n",
      "train loss: 0.03755228 | validation loss: 0.03358386\n",
      "train loss: 0.04001712 | validation loss: 0.04142733\n",
      "Epoch 15/50\n",
      "train loss: 0.03966704 | validation loss: 0.03340122\n",
      "train loss: 0.03933822 | validation loss: 0.03420233\n",
      "train loss: 0.0387022 | validation loss: 0.03646882\n",
      "train loss: 0.03703222 | validation loss: 0.03603695\n",
      "train loss: 0.03444487 | validation loss: 0.03087715\n",
      "train loss: 0.037281 | validation loss: 0.03167011\n",
      "train loss: 0.03824179 | validation loss: 0.03158266\n",
      "Epoch 16/50\n",
      "train loss: 0.03776839 | validation loss: 0.03244634\n",
      "train loss: 0.05602539 | validation loss: 0.02965615\n",
      "train loss: 0.04760494 | validation loss: 0.03154574\n",
      "train loss: 0.05003081 | validation loss: 0.03415216\n",
      "train loss: 0.0403887 | validation loss: 0.03454074\n",
      "train loss: 0.03487561 | validation loss: 0.02874749\n",
      "train loss: 0.03720374 | validation loss: 0.03590798\n",
      "Epoch 17/50\n",
      "train loss: 0.03343636 | validation loss: 0.03266357\n",
      "train loss: 0.05560186 | validation loss: 0.03436961\n",
      "train loss: 0.03437287 | validation loss: 0.03072675\n",
      "train loss: 0.0351631 | validation loss: 0.02858756\n",
      "train loss: 0.03518314 | validation loss: 0.02728412\n",
      "train loss: 0.04155602 | validation loss: 0.02968671\n",
      "train loss: 0.03247014 | validation loss: 0.02670369\n",
      "Epoch 18/50\n",
      "train loss: 0.04507595 | validation loss: 0.02831605\n",
      "train loss: 0.03243715 | validation loss: 0.02703402\n",
      "train loss: 0.03342899 | validation loss: 0.02489177\n",
      "train loss: 0.04398121 | validation loss: 0.0267389\n",
      "train loss: 0.03314945 | validation loss: 0.0256888\n",
      "train loss: 0.03233882 | validation loss: 0.02636336\n",
      "train loss: 0.04031116 | validation loss: 0.02684715\n",
      "Epoch 19/50\n",
      "train loss: 0.04376067 | validation loss: 0.03025929\n",
      "train loss: 0.0368471 | validation loss: 0.03288858\n",
      "train loss: 0.03589861 | validation loss: 0.03599983\n",
      "train loss: 0.0398681 | validation loss: 0.03555903\n",
      "train loss: 0.03503711 | validation loss: 0.03348242\n",
      "train loss: 0.04121142 | validation loss: 0.03220974\n",
      "train loss: 0.03348574 | validation loss: 0.03246436\n",
      "Epoch 20/50\n",
      "train loss: 0.03358559 | validation loss: 0.03111608\n",
      "train loss: 0.03130177 | validation loss: 0.02909146\n",
      "train loss: 0.03069987 | validation loss: 0.02984348\n",
      "train loss: 0.03074942 | validation loss: 0.0312225\n",
      "train loss: 0.03193131 | validation loss: 0.02833172\n",
      "train loss: 0.02869946 | validation loss: 0.02877029\n",
      "train loss: 0.02945196 | validation loss: 0.02798929\n",
      "Epoch 21/50\n",
      "train loss: 0.02684584 | validation loss: 0.02641722\n",
      "train loss: 0.0354484 | validation loss: 0.02759003\n",
      "train loss: 0.02620084 | validation loss: 0.02647152\n",
      "train loss: 0.02751138 | validation loss: 0.02488604\n",
      "train loss: 0.02652395 | validation loss: 0.02446075\n",
      "train loss: 0.02601123 | validation loss: 0.02529327\n",
      "train loss: 0.03197798 | validation loss: 0.02561501\n",
      "Epoch 22/50\n",
      "train loss: 0.03412442 | validation loss: 0.02449881\n",
      "train loss: 0.02467418 | validation loss: 0.0237698\n",
      "train loss: 0.02679307 | validation loss: 0.02299947\n",
      "train loss: 0.02837506 | validation loss: 0.0235089\n",
      "train loss: 0.0257979 | validation loss: 0.02342861\n",
      "train loss: 0.02363234 | validation loss: 0.02175792\n",
      "train loss: 0.02450475 | validation loss: 0.02276509\n",
      "Epoch 23/50\n",
      "train loss: 0.02352849 | validation loss: 0.0231213\n",
      "train loss: 0.02183286 | validation loss: 0.02073845\n",
      "train loss: 0.02571988 | validation loss: 0.02184836\n",
      "train loss: 0.02820238 | validation loss: 0.02337663\n",
      "train loss: 0.02354555 | validation loss: 0.02042743\n",
      "train loss: 0.02295209 | validation loss: 0.02089835\n",
      "train loss: 0.02565403 | validation loss: 0.02073235\n",
      "Epoch 24/50\n",
      "train loss: 0.02268556 | validation loss: 0.01957588\n",
      "train loss: 0.02268188 | validation loss: 0.01891136\n",
      "train loss: 0.02126337 | validation loss: 0.02001074\n",
      "train loss: 0.02418836 | validation loss: 0.01986273\n",
      "train loss: 0.02226682 | validation loss: 0.01884356\n",
      "train loss: 0.02064933 | validation loss: 0.01960647\n",
      "train loss: 0.02089026 | validation loss: 0.01898895\n",
      "Epoch 25/50\n",
      "train loss: 0.01914419 | validation loss: 0.01880465\n",
      "train loss: 0.02126202 | validation loss: 0.01838822\n",
      "train loss: 0.02260027 | validation loss: 0.01987518\n",
      "train loss: 0.02196302 | validation loss: 0.02004934\n",
      "train loss: 0.0190865 | validation loss: 0.01792875\n",
      "train loss: 0.02181627 | validation loss: 0.01700591\n",
      "train loss: 0.01898898 | validation loss: 0.01690708\n",
      "Epoch 26/50\n",
      "train loss: 0.01958611 | validation loss: 0.01971502\n",
      "train loss: 0.01832099 | validation loss: 0.01674149\n",
      "train loss: 0.01977476 | validation loss: 0.01731209\n",
      "train loss: 0.02021538 | validation loss: 0.01658557\n",
      "train loss: 0.02316285 | validation loss: 0.01706255\n",
      "train loss: 0.01830141 | validation loss: 0.01635171\n",
      "train loss: 0.01842011 | validation loss: 0.01619978\n",
      "Epoch 27/50\n",
      "train loss: 0.01882432 | validation loss: 0.01579586\n",
      "train loss: 0.0180988 | validation loss: 0.01690997\n",
      "train loss: 0.02305916 | validation loss: 0.01594198\n",
      "train loss: 0.02342589 | validation loss: 0.01619258\n",
      "train loss: 0.01612134 | validation loss: 0.01574199\n",
      "train loss: 0.02291967 | validation loss: 0.01603664\n",
      "train loss: 0.01788931 | validation loss: 0.01577286\n",
      "Epoch 28/50\n",
      "train loss: 0.0199372 | validation loss: 0.01591786\n",
      "train loss: 0.01697077 | validation loss: 0.01540778\n",
      "train loss: 0.01716285 | validation loss: 0.01554252\n",
      "train loss: 0.01733717 | validation loss: 0.01482703\n",
      "train loss: 0.01915299 | validation loss: 0.01525128\n",
      "train loss: 0.02185672 | validation loss: 0.01561841\n",
      "train loss: 0.01394473 | validation loss: 0.01485835\n",
      "Epoch 29/50\n",
      "train loss: 0.0170257 | validation loss: 0.01486762\n",
      "train loss: 0.01648131 | validation loss: 0.01498713\n",
      "train loss: 0.01713171 | validation loss: 0.01450814\n",
      "train loss: 0.01630967 | validation loss: 0.01466644\n",
      "train loss: 0.01578024 | validation loss: 0.01490088\n",
      "train loss: 0.01546645 | validation loss: 0.01416835\n",
      "train loss: 0.01414172 | validation loss: 0.01380969\n",
      "Epoch 30/50\n",
      "train loss: 0.01319317 | validation loss: 0.01469538\n",
      "train loss: 0.01659873 | validation loss: 0.01452657\n",
      "train loss: 0.0128389 | validation loss: 0.01416968\n",
      "train loss: 0.01456223 | validation loss: 0.01392631\n",
      "train loss: 0.01730822 | validation loss: 0.01343256\n",
      "train loss: 0.01863618 | validation loss: 0.0136408\n",
      "train loss: 0.01554222 | validation loss: 0.01338541\n",
      "Epoch 31/50\n",
      "train loss: 0.01221668 | validation loss: 0.0138757\n",
      "train loss: 0.01486576 | validation loss: 0.01345318\n",
      "train loss: 0.01662349 | validation loss: 0.01314489\n",
      "train loss: 0.01432246 | validation loss: 0.01301456\n",
      "train loss: 0.01256802 | validation loss: 0.01283426\n",
      "train loss: 0.01170397 | validation loss: 0.01262272\n",
      "train loss: 0.01206899 | validation loss: 0.01260396\n",
      "Epoch 32/50\n",
      "train loss: 0.01544889 | validation loss: 0.01241474\n",
      "train loss: 0.01180338 | validation loss: 0.01275855\n",
      "train loss: 0.0112286 | validation loss: 0.0126328\n",
      "train loss: 0.01899876 | validation loss: 0.01222087\n",
      "train loss: 0.01617943 | validation loss: 0.0123848\n",
      "train loss: 0.01947965 | validation loss: 0.01198702\n",
      "train loss: 0.01342839 | validation loss: 0.01242848\n",
      "Epoch 33/50\n",
      "train loss: 0.01530862 | validation loss: 0.01201455\n",
      "train loss: 0.01213534 | validation loss: 0.01246233\n",
      "train loss: 0.01193998 | validation loss: 0.01227933\n",
      "train loss: 0.01184953 | validation loss: 0.01173115\n",
      "train loss: 0.01432964 | validation loss: 0.01179964\n",
      "train loss: 0.01117915 | validation loss: 0.01157414\n",
      "train loss: 0.01082201 | validation loss: 0.01146504\n",
      "Epoch 34/50\n",
      "train loss: 0.01331802 | validation loss: 0.0113222\n",
      "train loss: 0.0149331 | validation loss: 0.01160042\n",
      "train loss: 0.01069364 | validation loss: 0.01190814\n",
      "train loss: 0.01282603 | validation loss: 0.01122292\n",
      "train loss: 0.01037766 | validation loss: 0.01114159\n",
      "train loss: 0.01111126 | validation loss: 0.01131505\n",
      "train loss: 0.01286484 | validation loss: 0.01119\n",
      "Epoch 35/50\n",
      "train loss: 0.01115922 | validation loss: 0.01091614\n",
      "train loss: 0.00979964 | validation loss: 0.01102492\n",
      "train loss: 0.01027255 | validation loss: 0.0108961\n",
      "train loss: 0.00968658 | validation loss: 0.0107181\n",
      "train loss: 0.01214584 | validation loss: 0.01078634\n",
      "train loss: 0.0117877 | validation loss: 0.01068673\n",
      "train loss: 0.01004959 | validation loss: 0.01049555\n",
      "Epoch 36/50\n",
      "train loss: 0.01596758 | validation loss: 0.0106537\n",
      "train loss: 0.01211829 | validation loss: 0.01049343\n",
      "train loss: 0.01225449 | validation loss: 0.01079937\n",
      "train loss: 0.0096815 | validation loss: 0.0104044\n",
      "train loss: 0.01119652 | validation loss: 0.01024876\n",
      "train loss: 0.01116038 | validation loss: 0.01001704\n",
      "train loss: 0.01057459 | validation loss: 0.00995587\n",
      "Epoch 37/50\n",
      "train loss: 0.01173826 | validation loss: 0.0100385\n",
      "train loss: 0.01053856 | validation loss: 0.01005812\n",
      "train loss: 0.0111774 | validation loss: 0.00998801\n",
      "train loss: 0.01060044 | validation loss: 0.01002981\n",
      "train loss: 0.01133926 | validation loss: 0.01015395\n",
      "train loss: 0.01023459 | validation loss: 0.00983815\n",
      "train loss: 0.01275377 | validation loss: 0.00972519\n",
      "Epoch 38/50\n",
      "train loss: 0.01175802 | validation loss: 0.00983601\n",
      "train loss: 0.01041677 | validation loss: 0.0097449\n",
      "train loss: 0.00812484 | validation loss: 0.01003715\n",
      "train loss: 0.01080004 | validation loss: 0.00980154\n",
      "train loss: 0.00860819 | validation loss: 0.01016704\n",
      "train loss: 0.00965794 | validation loss: 0.0096399\n",
      "train loss: 0.00973613 | validation loss: 0.00962815\n",
      "Epoch 39/50\n",
      "train loss: 0.00884 | validation loss: 0.0095974\n",
      "train loss: 0.00777208 | validation loss: 0.00954084\n",
      "train loss: 0.01145126 | validation loss: 0.00929957\n",
      "train loss: 0.01169514 | validation loss: 0.00941307\n",
      "train loss: 0.01074205 | validation loss: 0.0095427\n",
      "train loss: 0.01029305 | validation loss: 0.00937153\n",
      "train loss: 0.00877123 | validation loss: 0.00963956\n",
      "Epoch 40/50\n",
      "train loss: 0.00754625 | validation loss: 0.00926204\n",
      "train loss: 0.00844814 | validation loss: 0.00924175\n",
      "train loss: 0.00869155 | validation loss: 0.009254\n",
      "train loss: 0.00915849 | validation loss: 0.00888391\n",
      "train loss: 0.01298459 | validation loss: 0.00884607\n",
      "train loss: 0.00891849 | validation loss: 0.00889261\n",
      "train loss: 0.00937742 | validation loss: 0.00925942\n",
      "Epoch 41/50\n",
      "train loss: 0.01156748 | validation loss: 0.00873962\n",
      "train loss: 0.00808102 | validation loss: 0.00892059\n",
      "train loss: 0.01288133 | validation loss: 0.00866696\n",
      "train loss: 0.00992507 | validation loss: 0.00894209\n",
      "train loss: 0.00881729 | validation loss: 0.00895147\n",
      "train loss: 0.01180641 | validation loss: 0.00893182\n",
      "train loss: 0.00795086 | validation loss: 0.00889276\n",
      "Epoch 42/50\n",
      "train loss: 0.0115372 | validation loss: 0.00873098\n",
      "train loss: 0.00956844 | validation loss: 0.00875077\n",
      "train loss: 0.01069833 | validation loss: 0.00838729\n",
      "train loss: 0.00915294 | validation loss: 0.00866325\n",
      "train loss: 0.0165974 | validation loss: 0.00843142\n",
      "train loss: 0.00926244 | validation loss: 0.00856496\n",
      "train loss: 0.00905874 | validation loss: 0.00870648\n",
      "Epoch 43/50\n",
      "train loss: 0.00990428 | validation loss: 0.00869688\n",
      "train loss: 0.0106086 | validation loss: 0.00861526\n",
      "train loss: 0.00916652 | validation loss: 0.00861536\n",
      "train loss: 0.00805509 | validation loss: 0.0084383\n",
      "train loss: 0.01052304 | validation loss: 0.00836266\n",
      "train loss: 0.00966107 | validation loss: 0.00826498\n",
      "train loss: 0.01187091 | validation loss: 0.00820766\n",
      "Epoch 44/50\n",
      "train loss: 0.0101934 | validation loss: 0.00828505\n",
      "train loss: 0.00901481 | validation loss: 0.00824753\n",
      "train loss: 0.00817541 | validation loss: 0.00817703\n",
      "train loss: 0.00760556 | validation loss: 0.00833845\n",
      "train loss: 0.00803416 | validation loss: 0.00832927\n",
      "train loss: 0.00950847 | validation loss: 0.00814294\n",
      "train loss: 0.00704412 | validation loss: 0.00831717\n",
      "Epoch 45/50\n",
      "train loss: 0.00750088 | validation loss: 0.00813633\n",
      "train loss: 0.00944605 | validation loss: 0.00821639\n",
      "train loss: 0.00704331 | validation loss: 0.00816335\n",
      "train loss: 0.00844238 | validation loss: 0.008092\n",
      "train loss: 0.00904512 | validation loss: 0.00813321\n",
      "train loss: 0.00727859 | validation loss: 0.00812034\n",
      "train loss: 0.00852678 | validation loss: 0.00795623\n",
      "Epoch 46/50\n",
      "train loss: 0.00677697 | validation loss: 0.00795528\n",
      "train loss: 0.00824129 | validation loss: 0.00852984\n",
      "train loss: 0.01064092 | validation loss: 0.00822446\n",
      "train loss: 0.01044911 | validation loss: 0.00793562\n",
      "train loss: 0.00735668 | validation loss: 0.00800218\n",
      "train loss: 0.00773382 | validation loss: 0.00798998\n",
      "train loss: 0.00673587 | validation loss: 0.00813028\n",
      "Epoch 47/50\n",
      "train loss: 0.00938836 | validation loss: 0.00802999\n",
      "train loss: 0.00880452 | validation loss: 0.00787217\n",
      "train loss: 0.01114038 | validation loss: 0.00796998\n",
      "train loss: 0.00968753 | validation loss: 0.00784098\n",
      "train loss: 0.00980897 | validation loss: 0.00794278\n",
      "train loss: 0.00717018 | validation loss: 0.00787547\n",
      "train loss: 0.01176144 | validation loss: 0.00763766\n",
      "Epoch 48/50\n",
      "train loss: 0.00849375 | validation loss: 0.00767565\n",
      "train loss: 0.00971686 | validation loss: 0.00784647\n",
      "train loss: 0.00800472 | validation loss: 0.00788981\n",
      "train loss: 0.00850081 | validation loss: 0.00764992\n",
      "train loss: 0.00764239 | validation loss: 0.00771861\n",
      "train loss: 0.00900571 | validation loss: 0.00756903\n",
      "train loss: 0.01214402 | validation loss: 0.0075906\n",
      "Epoch 49/50\n",
      "train loss: 0.00636307 | validation loss: 0.00773098\n",
      "train loss: 0.00517705 | validation loss: 0.00773733\n",
      "train loss: 0.0058558 | validation loss: 0.00754821\n",
      "train loss: 0.0106182 | validation loss: 0.00746704\n",
      "train loss: 0.00555154 | validation loss: 0.00757849\n",
      "train loss: 0.00514037 | validation loss: 0.00759557\n",
      "train loss: 0.01024292 | validation loss: 0.00751217\n",
      "Epoch 50/50\n",
      "train loss: 0.0076662 | validation loss: 0.00757448\n",
      "train loss: 0.00761158 | validation loss: 0.00734512\n",
      "train loss: 0.00697927 | validation loss: 0.00759788\n",
      "train loss: 0.00709557 | validation loss: 0.00748042\n",
      "train loss: 0.0058442 | validation loss: 0.00754907\n",
      "train loss: 0.00545389 | validation loss: 0.00740749\n",
      "train loss: 0.00531337 | validation loss: 0.00720689\n"
     ]
    }
   ],
   "source": [
    "ae_4.train_loop(epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "train loss: 0.00686787 | validation loss: 0.00756736\n",
      "train loss: 0.00717324 | validation loss: 0.00737017\n",
      "train loss: 0.01046933 | validation loss: 0.0072428\n",
      "train loss: 0.00721075 | validation loss: 0.00744201\n",
      "train loss: 0.00838955 | validation loss: 0.00727072\n",
      "train loss: 0.00565965 | validation loss: 0.00749205\n",
      "train loss: 0.00684001 | validation loss: 0.00707733\n",
      "Epoch 2/20\n",
      "train loss: 0.00559237 | validation loss: 0.00739102\n",
      "train loss: 0.00613396 | validation loss: 0.00728957\n",
      "train loss: 0.00593679 | validation loss: 0.00717643\n",
      "train loss: 0.00574867 | validation loss: 0.00711014\n",
      "train loss: 0.01034911 | validation loss: 0.0071165\n",
      "train loss: 0.00511383 | validation loss: 0.00700862\n",
      "train loss: 0.00742158 | validation loss: 0.00713419\n",
      "Epoch 3/20\n",
      "train loss: 0.00689163 | validation loss: 0.00726537\n",
      "train loss: 0.00949097 | validation loss: 0.0069458\n",
      "train loss: 0.00872581 | validation loss: 0.00688298\n",
      "train loss: 0.00570961 | validation loss: 0.00692019\n",
      "train loss: 0.00430013 | validation loss: 0.00699931\n",
      "train loss: 0.00668717 | validation loss: 0.00708716\n",
      "train loss: 0.00597492 | validation loss: 0.00686915\n",
      "Epoch 4/20\n",
      "train loss: 0.00598117 | validation loss: 0.00682801\n",
      "train loss: 0.00807272 | validation loss: 0.00684098\n",
      "train loss: 0.00722644 | validation loss: 0.00678098\n",
      "train loss: 0.00915498 | validation loss: 0.00669911\n",
      "train loss: 0.00478931 | validation loss: 0.0066654\n",
      "train loss: 0.00539957 | validation loss: 0.00692548\n",
      "train loss: 0.00822198 | validation loss: 0.00666568\n",
      "Epoch 5/20\n",
      "train loss: 0.01157162 | validation loss: 0.00669101\n",
      "train loss: 0.00646002 | validation loss: 0.00670026\n",
      "train loss: 0.00587485 | validation loss: 0.00655199\n",
      "train loss: 0.00486986 | validation loss: 0.00665109\n",
      "train loss: 0.00701539 | validation loss: 0.00658813\n",
      "train loss: 0.00602909 | validation loss: 0.00660396\n",
      "train loss: 0.0069816 | validation loss: 0.00661017\n",
      "Epoch 6/20\n",
      "train loss: 0.00559893 | validation loss: 0.00659748\n",
      "train loss: 0.00640509 | validation loss: 0.00666702\n",
      "train loss: 0.01162434 | validation loss: 0.00650914\n",
      "train loss: 0.0058849 | validation loss: 0.00651346\n",
      "train loss: 0.00432704 | validation loss: 0.00648131\n",
      "train loss: 0.00541053 | validation loss: 0.00649879\n",
      "train loss: 0.00478182 | validation loss: 0.00645129\n",
      "Epoch 7/20\n",
      "train loss: 0.00553155 | validation loss: 0.00661125\n",
      "train loss: 0.00702519 | validation loss: 0.00644026\n",
      "train loss: 0.00658636 | validation loss: 0.00641034\n",
      "train loss: 0.00673005 | validation loss: 0.00639752\n",
      "train loss: 0.00900368 | validation loss: 0.00641823\n",
      "train loss: 0.00694062 | validation loss: 0.00648454\n",
      "train loss: 0.00626591 | validation loss: 0.00641718\n",
      "Epoch 8/20\n",
      "train loss: 0.00549045 | validation loss: 0.00641411\n",
      "train loss: 0.00570162 | validation loss: 0.0063928\n",
      "train loss: 0.00646604 | validation loss: 0.00650708\n",
      "train loss: 0.0052547 | validation loss: 0.00649802\n",
      "train loss: 0.00900962 | validation loss: 0.00637162\n",
      "train loss: 0.0050406 | validation loss: 0.00640295\n",
      "train loss: 0.00556764 | validation loss: 0.00646518\n",
      "Epoch 9/20\n",
      "train loss: 0.00651192 | validation loss: 0.00635829\n",
      "train loss: 0.00769146 | validation loss: 0.00650363\n",
      "train loss: 0.00579453 | validation loss: 0.00632974\n",
      "train loss: 0.00637945 | validation loss: 0.00642617\n",
      "train loss: 0.0075834 | validation loss: 0.0063932\n",
      "train loss: 0.00545047 | validation loss: 0.00641084\n",
      "train loss: 0.00628172 | validation loss: 0.00635669\n",
      "Epoch 10/20\n",
      "train loss: 0.00702135 | validation loss: 0.00630836\n",
      "train loss: 0.00794302 | validation loss: 0.00632779\n",
      "train loss: 0.00504024 | validation loss: 0.00650717\n",
      "train loss: 0.00679212 | validation loss: 0.00632679\n",
      "train loss: 0.00829446 | validation loss: 0.00634505\n",
      "train loss: 0.00924467 | validation loss: 0.00633134\n",
      "train loss: 0.00598198 | validation loss: 0.00634049\n",
      "Epoch 11/20\n",
      "train loss: 0.00427517 | validation loss: 0.0062986\n",
      "train loss: 0.00764826 | validation loss: 0.00628698\n",
      "train loss: 0.00590404 | validation loss: 0.00626452\n",
      "train loss: 0.00708234 | validation loss: 0.00626446\n",
      "train loss: 0.00785086 | validation loss: 0.00626954\n",
      "train loss: 0.00545961 | validation loss: 0.00627791\n",
      "train loss: 0.00518332 | validation loss: 0.00624426\n",
      "Epoch 12/20\n",
      "train loss: 0.004472 | validation loss: 0.00620715\n",
      "train loss: 0.00679233 | validation loss: 0.00630187\n",
      "train loss: 0.00564191 | validation loss: 0.00622528\n",
      "train loss: 0.004572 | validation loss: 0.00620725\n",
      "train loss: 0.00654685 | validation loss: 0.00621105\n",
      "train loss: 0.00635181 | validation loss: 0.00616322\n",
      "train loss: 0.00782548 | validation loss: 0.00625614\n",
      "Epoch 13/20\n",
      "train loss: 0.00724062 | validation loss: 0.00618096\n",
      "train loss: 0.00673736 | validation loss: 0.00615823\n",
      "train loss: 0.00517886 | validation loss: 0.0061789\n",
      "train loss: 0.00562339 | validation loss: 0.00617904\n",
      "train loss: 0.00941352 | validation loss: 0.00619738\n",
      "train loss: 0.00551227 | validation loss: 0.00617349\n",
      "train loss: 0.00868674 | validation loss: 0.00616744\n",
      "Epoch 14/20\n",
      "train loss: 0.00448319 | validation loss: 0.00627512\n",
      "train loss: 0.00636728 | validation loss: 0.0061434\n",
      "train loss: 0.00492526 | validation loss: 0.0061626\n",
      "train loss: 0.00779416 | validation loss: 0.00615087\n",
      "train loss: 0.00649515 | validation loss: 0.0061057\n",
      "train loss: 0.00454658 | validation loss: 0.00620523\n",
      "train loss: 0.00551686 | validation loss: 0.00616598\n",
      "Epoch 15/20\n",
      "train loss: 0.00823276 | validation loss: 0.00616551\n",
      "train loss: 0.00776581 | validation loss: 0.00610335\n",
      "train loss: 0.0052089 | validation loss: 0.00613822\n",
      "train loss: 0.0063918 | validation loss: 0.00613624\n",
      "train loss: 0.00689541 | validation loss: 0.00625795\n",
      "train loss: 0.00580203 | validation loss: 0.00616787\n",
      "train loss: 0.004638 | validation loss: 0.00618261\n",
      "Epoch 16/20\n",
      "train loss: 0.00438517 | validation loss: 0.00607106\n",
      "train loss: 0.00559983 | validation loss: 0.00617272\n",
      "train loss: 0.00630349 | validation loss: 0.00615283\n",
      "train loss: 0.00496009 | validation loss: 0.00613782\n",
      "train loss: 0.00530484 | validation loss: 0.0061594\n",
      "train loss: 0.00534369 | validation loss: 0.00611925\n",
      "train loss: 0.00481256 | validation loss: 0.006159\n",
      "Epoch 17/20\n",
      "train loss: 0.00689242 | validation loss: 0.00610901\n",
      "train loss: 0.00557163 | validation loss: 0.00621569\n",
      "train loss: 0.00627406 | validation loss: 0.00609441\n",
      "train loss: 0.00596391 | validation loss: 0.00608561\n",
      "train loss: 0.00447349 | validation loss: 0.00613939\n",
      "train loss: 0.00678145 | validation loss: 0.00607701\n",
      "train loss: 0.00660719 | validation loss: 0.00607757\n",
      "Epoch 18/20\n",
      "train loss: 0.00494681 | validation loss: 0.00604321\n",
      "train loss: 0.00476434 | validation loss: 0.00614464\n",
      "train loss: 0.00540651 | validation loss: 0.006032\n",
      "train loss: 0.00582355 | validation loss: 0.00622448\n",
      "train loss: 0.00582462 | validation loss: 0.00612447\n",
      "train loss: 0.0040781 | validation loss: 0.00613209\n",
      "train loss: 0.00740488 | validation loss: 0.00610417\n",
      "Epoch 19/20\n",
      "train loss: 0.00451422 | validation loss: 0.00609625\n",
      "train loss: 0.0078183 | validation loss: 0.00606903\n",
      "train loss: 0.00523183 | validation loss: 0.0061092\n",
      "train loss: 0.00710526 | validation loss: 0.00613395\n",
      "train loss: 0.00727343 | validation loss: 0.00611046\n",
      "train loss: 0.00554079 | validation loss: 0.00612498\n",
      "train loss: 0.0046658 | validation loss: 0.00612303\n",
      "Epoch 20/20\n",
      "train loss: 0.00762851 | validation loss: 0.00609384\n",
      "train loss: 0.00436352 | validation loss: 0.00613003\n",
      "train loss: 0.00495983 | validation loss: 0.00605533\n",
      "train loss: 0.00724226 | validation loss: 0.00609002\n",
      "train loss: 0.00504029 | validation loss: 0.00613058\n",
      "train loss: 0.00561051 | validation loss: 0.00608535\n",
      "train loss: 0.00582003 | validation loss: 0.00616841\n"
     ]
    }
   ],
   "source": [
    "ae_4.train_loop(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "train loss: 0.21489999 | validation loss: 0.21649054\n",
      "train loss: 0.19971737 | validation loss: 0.19290787\n",
      "train loss: 0.23356685 | validation loss: 0.18819165\n",
      "Epoch 2/50\n",
      "train loss: 0.18743429 | validation loss: 0.17428115\n",
      "train loss: 0.17178538 | validation loss: 0.16203174\n",
      "train loss: 0.2356452 | validation loss: 0.1503925\n",
      "Epoch 3/50\n",
      "train loss: 0.15602335 | validation loss: 0.14724115\n",
      "train loss: 0.15021554 | validation loss: 0.14173602\n",
      "train loss: 0.16970026 | validation loss: 0.12773024\n",
      "Epoch 4/50\n",
      "train loss: 0.14281948 | validation loss: 0.1233262\n",
      "train loss: 0.12688211 | validation loss: 0.11928833\n",
      "train loss: 0.20054783 | validation loss: 0.1079348\n",
      "Epoch 5/50\n",
      "train loss: 0.11612576 | validation loss: 0.10873526\n",
      "train loss: 0.10732884 | validation loss: 0.10154027\n",
      "train loss: 0.18133566 | validation loss: 0.0952955\n",
      "Epoch 6/50\n",
      "train loss: 0.09748188 | validation loss: 0.09069753\n",
      "train loss: 0.09065448 | validation loss: 0.08849635\n",
      "train loss: 0.13726079 | validation loss: 0.08696993\n",
      "Epoch 7/50\n",
      "train loss: 0.09583498 | validation loss: 0.07549422\n",
      "train loss: 0.08214475 | validation loss: 0.07430539\n",
      "train loss: 0.127575 | validation loss: 0.07166164\n",
      "Epoch 8/50\n",
      "train loss: 0.07947515 | validation loss: 0.06727619\n",
      "train loss: 0.07310367 | validation loss: 0.06270839\n",
      "train loss: 0.1193138 | validation loss: 0.06100456\n",
      "Epoch 9/50\n",
      "train loss: 0.07170927 | validation loss: 0.05885999\n",
      "train loss: 0.06251802 | validation loss: 0.05471649\n",
      "train loss: 0.19366194 | validation loss: 0.05594346\n",
      "Epoch 10/50\n",
      "train loss: 0.06159939 | validation loss: 0.05116374\n",
      "train loss: 0.05678038 | validation loss: 0.04988757\n",
      "train loss: 0.17936333 | validation loss: 0.0466866\n",
      "Epoch 11/50\n",
      "train loss: 0.05557634 | validation loss: 0.04876084\n",
      "train loss: 0.05388546 | validation loss: 0.04946562\n",
      "train loss: 0.11544081 | validation loss: 0.04567531\n",
      "Epoch 12/50\n",
      "train loss: 0.06752976 | validation loss: 0.04605537\n",
      "train loss: 0.0541306 | validation loss: 0.04262486\n",
      "train loss: 0.14398831 | validation loss: 0.04098975\n",
      "Epoch 13/50\n",
      "train loss: 0.04396751 | validation loss: 0.04077075\n",
      "train loss: 0.04279431 | validation loss: 0.0401032\n",
      "train loss: 0.16244945 | validation loss: 0.03676727\n",
      "Epoch 14/50\n",
      "train loss: 0.03906173 | validation loss: 0.03552839\n",
      "train loss: 0.05997774 | validation loss: 0.03743982\n",
      "train loss: 0.13215208 | validation loss: 0.03432353\n",
      "Epoch 15/50\n",
      "train loss: 0.03983034 | validation loss: 0.03655335\n",
      "train loss: 0.03852176 | validation loss: 0.03684319\n",
      "train loss: 0.17077905 | validation loss: 0.03166696\n",
      "Epoch 16/50\n",
      "train loss: 0.03978527 | validation loss: 0.02997017\n",
      "train loss: 0.03587788 | validation loss: 0.03211341\n",
      "train loss: 0.11491206 | validation loss: 0.03514872\n",
      "Epoch 17/50\n",
      "train loss: 0.03418889 | validation loss: 0.03169322\n",
      "train loss: 0.03576991 | validation loss: 0.0340048\n",
      "train loss: 0.1000298 | validation loss: 0.03406278\n",
      "Epoch 18/50\n",
      "train loss: 0.04349921 | validation loss: 0.02790454\n",
      "train loss: 0.03266509 | validation loss: 0.02706709\n",
      "train loss: 0.10937904 | validation loss: 0.02516426\n",
      "Epoch 19/50\n",
      "train loss: 0.03079343 | validation loss: 0.02550152\n",
      "train loss: 0.03086828 | validation loss: 0.02364547\n",
      "train loss: 0.09647974 | validation loss: 0.02639907\n",
      "Epoch 20/50\n",
      "train loss: 0.04038645 | validation loss: 0.02318856\n",
      "train loss: 0.03226613 | validation loss: 0.02530434\n",
      "train loss: 0.09254486 | validation loss: 0.02674528\n",
      "Epoch 21/50\n",
      "train loss: 0.02975139 | validation loss: 0.02306396\n",
      "train loss: 0.03078422 | validation loss: 0.02115416\n",
      "train loss: 0.09485436 | validation loss: 0.0240155\n",
      "Epoch 22/50\n",
      "train loss: 0.02775521 | validation loss: 0.0218017\n",
      "train loss: 0.02774073 | validation loss: 0.02410278\n",
      "train loss: 0.07689615 | validation loss: 0.02086374\n",
      "Epoch 23/50\n",
      "train loss: 0.02678079 | validation loss: 0.01922593\n",
      "train loss: 0.03817041 | validation loss: 0.02008189\n",
      "train loss: 0.10809445 | validation loss: 0.02266252\n",
      "Epoch 24/50\n",
      "train loss: 0.02829364 | validation loss: 0.02000592\n",
      "train loss: 0.02151495 | validation loss: 0.01959274\n",
      "train loss: 0.06324402 | validation loss: 0.02023501\n",
      "Epoch 25/50\n",
      "train loss: 0.02433285 | validation loss: 0.02390386\n",
      "train loss: 0.02175586 | validation loss: 0.01875656\n",
      "train loss: 0.05582563 | validation loss: 0.01942728\n",
      "Epoch 26/50\n",
      "train loss: 0.02204612 | validation loss: 0.0184012\n",
      "train loss: 0.02353078 | validation loss: 0.01959473\n",
      "train loss: 0.08736596 | validation loss: 0.02038066\n",
      "Epoch 27/50\n",
      "train loss: 0.02302162 | validation loss: 0.01868815\n",
      "train loss: 0.03018275 | validation loss: 0.01902821\n",
      "train loss: 0.0570403 | validation loss: 0.01858088\n",
      "Epoch 28/50\n",
      "train loss: 0.02512706 | validation loss: 0.01958294\n",
      "train loss: 0.02140434 | validation loss: 0.01956765\n",
      "train loss: 0.05080737 | validation loss: 0.01945299\n",
      "Epoch 29/50\n",
      "train loss: 0.02072918 | validation loss: 0.01844115\n",
      "train loss: 0.01769993 | validation loss: 0.01721888\n",
      "train loss: 0.06567651 | validation loss: 0.01785355\n",
      "Epoch 30/50\n",
      "train loss: 0.01690689 | validation loss: 0.01675978\n",
      "train loss: 0.02197725 | validation loss: 0.01654793\n",
      "train loss: 0.04082411 | validation loss: 0.01659156\n",
      "Epoch 31/50\n",
      "train loss: 0.01661212 | validation loss: 0.01587999\n",
      "train loss: 0.01632165 | validation loss: 0.01535039\n",
      "train loss: 0.03378523 | validation loss: 0.01548204\n",
      "Epoch 32/50\n",
      "train loss: 0.01434828 | validation loss: 0.01441082\n",
      "train loss: 0.01990896 | validation loss: 0.01468348\n",
      "train loss: 0.02679783 | validation loss: 0.01421068\n",
      "Epoch 33/50\n",
      "train loss: 0.02058614 | validation loss: 0.01371025\n",
      "train loss: 0.01672954 | validation loss: 0.01352477\n",
      "train loss: 0.02245232 | validation loss: 0.01352204\n",
      "Epoch 34/50\n",
      "train loss: 0.01410434 | validation loss: 0.01300605\n",
      "train loss: 0.01545405 | validation loss: 0.01275362\n",
      "train loss: 0.02473306 | validation loss: 0.0124926\n",
      "Epoch 35/50\n",
      "train loss: 0.01360495 | validation loss: 0.01185692\n",
      "train loss: 0.01197631 | validation loss: 0.01151422\n",
      "train loss: 0.01892407 | validation loss: 0.01181289\n",
      "Epoch 36/50\n",
      "train loss: 0.01009854 | validation loss: 0.01152387\n",
      "train loss: 0.01110914 | validation loss: 0.01110376\n",
      "train loss: 0.02018092 | validation loss: 0.01103621\n",
      "Epoch 37/50\n",
      "train loss: 0.00826739 | validation loss: 0.01060802\n",
      "train loss: 0.0104602 | validation loss: 0.0107663\n",
      "train loss: 0.02308325 | validation loss: 0.01066135\n",
      "Epoch 38/50\n",
      "train loss: 0.00976896 | validation loss: 0.01022311\n",
      "train loss: 0.01234545 | validation loss: 0.00990456\n",
      "train loss: 0.02054848 | validation loss: 0.0101407\n",
      "Epoch 39/50\n",
      "train loss: 0.0130974 | validation loss: 0.00966643\n",
      "train loss: 0.01088939 | validation loss: 0.00988885\n",
      "train loss: 0.01406675 | validation loss: 0.00966801\n",
      "Epoch 40/50\n",
      "train loss: 0.00856629 | validation loss: 0.00937908\n",
      "train loss: 0.01146068 | validation loss: 0.0092805\n",
      "train loss: 0.01529311 | validation loss: 0.00936085\n",
      "Epoch 41/50\n",
      "train loss: 0.0085671 | validation loss: 0.00921431\n",
      "train loss: 0.00873337 | validation loss: 0.00926041\n",
      "train loss: 0.01215403 | validation loss: 0.00903608\n",
      "Epoch 42/50\n",
      "train loss: 0.0083638 | validation loss: 0.00888656\n",
      "train loss: 0.00944102 | validation loss: 0.00887571\n",
      "train loss: 0.00995863 | validation loss: 0.0090898\n",
      "Epoch 43/50\n",
      "train loss: 0.01028789 | validation loss: 0.0087752\n",
      "train loss: 0.00769598 | validation loss: 0.00860504\n",
      "train loss: 0.01018927 | validation loss: 0.00874214\n",
      "Epoch 44/50\n",
      "train loss: 0.00794622 | validation loss: 0.00850775\n",
      "train loss: 0.00683651 | validation loss: 0.00855164\n",
      "train loss: 0.00940109 | validation loss: 0.00848205\n",
      "Epoch 45/50\n",
      "train loss: 0.00828142 | validation loss: 0.00821012\n",
      "train loss: 0.00612471 | validation loss: 0.00832074\n",
      "train loss: 0.00849838 | validation loss: 0.00816162\n",
      "Epoch 46/50\n",
      "train loss: 0.00774309 | validation loss: 0.00823907\n",
      "train loss: 0.00634504 | validation loss: 0.00804137\n",
      "train loss: 0.01007235 | validation loss: 0.00810737\n",
      "Epoch 47/50\n",
      "train loss: 0.00733587 | validation loss: 0.00797753\n",
      "train loss: 0.01021955 | validation loss: 0.00807393\n",
      "train loss: 0.00608171 | validation loss: 0.00801521\n",
      "Epoch 48/50\n",
      "train loss: 0.01038242 | validation loss: 0.00790174\n",
      "train loss: 0.00679397 | validation loss: 0.00791185\n",
      "train loss: 0.00859111 | validation loss: 0.00785715\n",
      "Epoch 49/50\n",
      "train loss: 0.01290857 | validation loss: 0.00767308\n",
      "train loss: 0.00529531 | validation loss: 0.00765237\n",
      "train loss: 0.0058791 | validation loss: 0.00756624\n",
      "Epoch 50/50\n",
      "train loss: 0.0076392 | validation loss: 0.00745077\n",
      "train loss: 0.00897505 | validation loss: 0.00757403\n",
      "train loss: 0.00728147 | validation loss: 0.00763965\n"
     ]
    }
   ],
   "source": [
    "ae_4.train_loop(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "train loss: 0.00669099 | validation loss: 0.00601894\n",
      "train loss: 0.00469608 | validation loss: 0.00604354\n",
      "train loss: 0.00656378 | validation loss: 0.00602584\n",
      "train loss: 0.00787973 | validation loss: 0.0060766\n",
      "train loss: 0.0059836 | validation loss: 0.00598687\n",
      "train loss: 0.00387794 | validation loss: 0.00606507\n",
      "train loss: 0.00521555 | validation loss: 0.00605975\n",
      "Epoch 2/10\n",
      "train loss: 0.00510335 | validation loss: 0.00604949\n",
      "train loss: 0.00465114 | validation loss: 0.00600495\n",
      "train loss: 0.00461911 | validation loss: 0.00608244\n",
      "train loss: 0.00607927 | validation loss: 0.0060724\n",
      "train loss: 0.00485418 | validation loss: 0.00600468\n",
      "train loss: 0.00404608 | validation loss: 0.00609499\n",
      "train loss: 0.00510981 | validation loss: 0.00602119\n",
      "Epoch 3/10\n",
      "train loss: 0.00427753 | validation loss: 0.00609052\n",
      "train loss: 0.00566976 | validation loss: 0.00602321\n",
      "train loss: 0.00624995 | validation loss: 0.00608642\n",
      "train loss: 0.00634583 | validation loss: 0.00598345\n",
      "train loss: 0.00436795 | validation loss: 0.0060211\n",
      "train loss: 0.00529702 | validation loss: 0.00604241\n",
      "train loss: 0.00728479 | validation loss: 0.00604777\n",
      "Epoch 4/10\n",
      "train loss: 0.00548882 | validation loss: 0.00611906\n",
      "train loss: 0.00588188 | validation loss: 0.006026\n",
      "train loss: 0.00644647 | validation loss: 0.00594836\n",
      "train loss: 0.00517144 | validation loss: 0.00597974\n",
      "train loss: 0.00557763 | validation loss: 0.00600542\n",
      "train loss: 0.00865032 | validation loss: 0.00600597\n",
      "train loss: 0.00621971 | validation loss: 0.00599442\n",
      "Epoch 5/10\n",
      "train loss: 0.00557182 | validation loss: 0.00600462\n",
      "train loss: 0.00454939 | validation loss: 0.00606321\n",
      "train loss: 0.00632097 | validation loss: 0.00601686\n",
      "train loss: 0.00485023 | validation loss: 0.00606941\n",
      "train loss: 0.00495838 | validation loss: 0.00597738\n",
      "train loss: 0.00624034 | validation loss: 0.00605741\n",
      "train loss: 0.00521646 | validation loss: 0.00600598\n",
      "Epoch 6/10\n",
      "train loss: 0.00426366 | validation loss: 0.00613255\n",
      "train loss: 0.0053172 | validation loss: 0.00600683\n",
      "train loss: 0.0079721 | validation loss: 0.00601524\n",
      "train loss: 0.00600029 | validation loss: 0.00594874\n",
      "train loss: 0.00416854 | validation loss: 0.00607845\n",
      "train loss: 0.00522697 | validation loss: 0.005951\n",
      "train loss: 0.00496562 | validation loss: 0.00600245\n",
      "Epoch 7/10\n",
      "train loss: 0.00497828 | validation loss: 0.00600653\n",
      "train loss: 0.00495769 | validation loss: 0.0061126\n",
      "train loss: 0.00508899 | validation loss: 0.00599831\n",
      "train loss: 0.00954173 | validation loss: 0.00603022\n",
      "train loss: 0.00462528 | validation loss: 0.00599832\n",
      "train loss: 0.00599233 | validation loss: 0.00600545\n",
      "train loss: 0.00500919 | validation loss: 0.00594744\n",
      "Epoch 8/10\n",
      "train loss: 0.00877517 | validation loss: 0.00599707\n",
      "train loss: 0.00559433 | validation loss: 0.00598905\n",
      "train loss: 0.00495451 | validation loss: 0.0059922\n",
      "train loss: 0.00636467 | validation loss: 0.00599875\n",
      "train loss: 0.00560253 | validation loss: 0.00597163\n",
      "train loss: 0.00886718 | validation loss: 0.00600942\n",
      "train loss: 0.00508821 | validation loss: 0.0059217\n",
      "Epoch 9/10\n",
      "train loss: 0.00576069 | validation loss: 0.0059377\n",
      "train loss: 0.0061749 | validation loss: 0.00598756\n",
      "train loss: 0.00610631 | validation loss: 0.00597795\n",
      "train loss: 0.00624955 | validation loss: 0.00597305\n",
      "train loss: 0.00607724 | validation loss: 0.00600082\n",
      "train loss: 0.00606843 | validation loss: 0.00606791\n",
      "train loss: 0.00458855 | validation loss: 0.00596238\n",
      "Epoch 10/10\n",
      "train loss: 0.00419973 | validation loss: 0.00610575\n",
      "train loss: 0.00788574 | validation loss: 0.00604707\n",
      "train loss: 0.0055316 | validation loss: 0.00601065\n",
      "train loss: 0.00601404 | validation loss: 0.00600269\n",
      "train loss: 0.00690261 | validation loss: 0.00600532\n",
      "train loss: 0.00597021 | validation loss: 0.00606054\n",
      "train loss: 0.00551478 | validation loss: 0.00596975\n"
     ]
    }
   ],
   "source": [
    "ae_4.train_loop(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae_4.train_loop(epochs=145)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses3 = pd.DataFrame(data=list(zip(ae_4.train_losses, ae_4.val_losses)), columns=['train_loss', 'validation_loss'])\n",
    "losses3['epoch'] = (losses3.index + 1) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses3 = pd.DataFrame(data=list(zip(ae_4.train_losses, ae_4.val_losses)), columns=['train_loss', 'validation_loss'])\n",
    "losses3['epoch'] = (losses3.index + 1) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'autoencoder loss over time')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 392.14375 277.314375\" width=\"392.14375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 277.314375 \n",
       "L 392.14375 277.314375 \n",
       "L 392.14375 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 384.94375 239.758125 \n",
       "L 384.94375 22.318125 \n",
       "L 50.14375 22.318125 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"me862a568e6\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"64.817453\" xlink:href=\"#me862a568e6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(61.636203 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"105.653361\" xlink:href=\"#me862a568e6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 25 -->\n",
       "      <defs>\n",
       "       <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "       <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(99.290861 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"146.48927\" xlink:href=\"#me862a568e6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 50 -->\n",
       "      <g transform=\"translate(140.12677 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"187.325178\" xlink:href=\"#me862a568e6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 75 -->\n",
       "      <defs>\n",
       "       <path d=\"M 8.203125 72.90625 \n",
       "L 55.078125 72.90625 \n",
       "L 55.078125 68.703125 \n",
       "L 28.609375 0 \n",
       "L 18.3125 0 \n",
       "L 43.21875 64.59375 \n",
       "L 8.203125 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-55\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(180.962678 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-55\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"228.161086\" xlink:href=\"#me862a568e6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 100 -->\n",
       "      <defs>\n",
       "       <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(218.617336 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"268.996994\" xlink:href=\"#me862a568e6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 125 -->\n",
       "      <g transform=\"translate(259.453244 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"309.832903\" xlink:href=\"#me862a568e6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 150 -->\n",
       "      <g transform=\"translate(300.289153 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"350.668811\" xlink:href=\"#me862a568e6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 175 -->\n",
       "      <g transform=\"translate(341.125061 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_9\">\n",
       "     <!-- epoch -->\n",
       "     <defs>\n",
       "      <path d=\"M 56.203125 29.59375 \n",
       "L 56.203125 25.203125 \n",
       "L 14.890625 25.203125 \n",
       "Q 15.484375 15.921875 20.484375 11.0625 \n",
       "Q 25.484375 6.203125 34.421875 6.203125 \n",
       "Q 39.59375 6.203125 44.453125 7.46875 \n",
       "Q 49.3125 8.734375 54.109375 11.28125 \n",
       "L 54.109375 2.78125 \n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \n",
       "Q 5.515625 13.8125 5.515625 26.8125 \n",
       "Q 5.515625 40.234375 12.765625 48.109375 \n",
       "Q 20.015625 56 32.328125 56 \n",
       "Q 43.359375 56 49.78125 48.890625 \n",
       "Q 56.203125 41.796875 56.203125 29.59375 \n",
       "z\n",
       "M 47.21875 32.234375 \n",
       "Q 47.125 39.59375 43.09375 43.984375 \n",
       "Q 39.0625 48.390625 32.421875 48.390625 \n",
       "Q 24.90625 48.390625 20.390625 44.140625 \n",
       "Q 15.875 39.890625 15.1875 32.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-101\"/>\n",
       "      <path d=\"M 18.109375 8.203125 \n",
       "L 18.109375 -20.796875 \n",
       "L 9.078125 -20.796875 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.390625 \n",
       "Q 20.953125 51.265625 25.265625 53.625 \n",
       "Q 29.59375 56 35.59375 56 \n",
       "Q 45.5625 56 51.78125 48.09375 \n",
       "Q 58.015625 40.1875 58.015625 27.296875 \n",
       "Q 58.015625 14.40625 51.78125 6.484375 \n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \n",
       "Q 20.953125 3.328125 18.109375 8.203125 \n",
       "z\n",
       "M 48.6875 27.296875 \n",
       "Q 48.6875 37.203125 44.609375 42.84375 \n",
       "Q 40.53125 48.484375 33.40625 48.484375 \n",
       "Q 26.265625 48.484375 22.1875 42.84375 \n",
       "Q 18.109375 37.203125 18.109375 27.296875 \n",
       "Q 18.109375 17.390625 22.1875 11.75 \n",
       "Q 26.265625 6.109375 33.40625 6.109375 \n",
       "Q 40.53125 6.109375 44.609375 11.75 \n",
       "Q 48.6875 17.390625 48.6875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-112\"/>\n",
       "      <path d=\"M 30.609375 48.390625 \n",
       "Q 23.390625 48.390625 19.1875 42.75 \n",
       "Q 14.984375 37.109375 14.984375 27.296875 \n",
       "Q 14.984375 17.484375 19.15625 11.84375 \n",
       "Q 23.34375 6.203125 30.609375 6.203125 \n",
       "Q 37.796875 6.203125 41.984375 11.859375 \n",
       "Q 46.1875 17.53125 46.1875 27.296875 \n",
       "Q 46.1875 37.015625 41.984375 42.703125 \n",
       "Q 37.796875 48.390625 30.609375 48.390625 \n",
       "z\n",
       "M 30.609375 56 \n",
       "Q 42.328125 56 49.015625 48.375 \n",
       "Q 55.71875 40.765625 55.71875 27.296875 \n",
       "Q 55.71875 13.875 49.015625 6.21875 \n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \n",
       "Q 5.515625 13.875 5.515625 27.296875 \n",
       "Q 5.515625 40.765625 12.171875 48.375 \n",
       "Q 18.84375 56 30.609375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-111\"/>\n",
       "      <path d=\"M 48.78125 52.59375 \n",
       "L 48.78125 44.1875 \n",
       "Q 44.96875 46.296875 41.140625 47.34375 \n",
       "Q 37.3125 48.390625 33.40625 48.390625 \n",
       "Q 24.65625 48.390625 19.8125 42.84375 \n",
       "Q 14.984375 37.3125 14.984375 27.296875 \n",
       "Q 14.984375 17.28125 19.8125 11.734375 \n",
       "Q 24.65625 6.203125 33.40625 6.203125 \n",
       "Q 37.3125 6.203125 41.140625 7.25 \n",
       "Q 44.96875 8.296875 48.78125 10.40625 \n",
       "L 48.78125 2.09375 \n",
       "Q 45.015625 0.34375 40.984375 -0.53125 \n",
       "Q 36.96875 -1.421875 32.421875 -1.421875 \n",
       "Q 20.0625 -1.421875 12.78125 6.34375 \n",
       "Q 5.515625 14.109375 5.515625 27.296875 \n",
       "Q 5.515625 40.671875 12.859375 48.328125 \n",
       "Q 20.21875 56 33.015625 56 \n",
       "Q 37.15625 56 41.109375 55.140625 \n",
       "Q 45.0625 54.296875 48.78125 52.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-99\"/>\n",
       "      <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 75.984375 \n",
       "L 18.109375 75.984375 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-104\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(202.315625 268.034687)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m7a0d4d21fe\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m7a0d4d21fe\" y=\"233.002643\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.00 -->\n",
       "      <defs>\n",
       "       <path d=\"M 10.6875 12.40625 \n",
       "L 21 12.40625 \n",
       "L 21 0 \n",
       "L 10.6875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-46\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(20.878125 236.801862)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m7a0d4d21fe\" y=\"192.669981\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.05 -->\n",
       "      <g transform=\"translate(20.878125 196.4692)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m7a0d4d21fe\" y=\"152.337319\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.10 -->\n",
       "      <g transform=\"translate(20.878125 156.136538)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m7a0d4d21fe\" y=\"112.004657\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.15 -->\n",
       "      <g transform=\"translate(20.878125 115.803876)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m7a0d4d21fe\" y=\"71.671995\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 0.20 -->\n",
       "      <g transform=\"translate(20.878125 75.471214)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m7a0d4d21fe\" y=\"31.339333\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 0.25 -->\n",
       "      <g transform=\"translate(20.878125 35.138552)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- MSE loss -->\n",
       "     <defs>\n",
       "      <path d=\"M 9.8125 72.90625 \n",
       "L 24.515625 72.90625 \n",
       "L 43.109375 23.296875 \n",
       "L 61.8125 72.90625 \n",
       "L 76.515625 72.90625 \n",
       "L 76.515625 0 \n",
       "L 66.890625 0 \n",
       "L 66.890625 64.015625 \n",
       "L 48.09375 14.015625 \n",
       "L 38.1875 14.015625 \n",
       "L 19.390625 64.015625 \n",
       "L 19.390625 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-77\"/>\n",
       "      <path d=\"M 53.515625 70.515625 \n",
       "L 53.515625 60.890625 \n",
       "Q 47.90625 63.578125 42.921875 64.890625 \n",
       "Q 37.9375 66.21875 33.296875 66.21875 \n",
       "Q 25.25 66.21875 20.875 63.09375 \n",
       "Q 16.5 59.96875 16.5 54.203125 \n",
       "Q 16.5 49.359375 19.40625 46.890625 \n",
       "Q 22.3125 44.4375 30.421875 42.921875 \n",
       "L 36.375 41.703125 \n",
       "Q 47.40625 39.59375 52.65625 34.296875 \n",
       "Q 57.90625 29 57.90625 20.125 \n",
       "Q 57.90625 9.515625 50.796875 4.046875 \n",
       "Q 43.703125 -1.421875 29.984375 -1.421875 \n",
       "Q 24.8125 -1.421875 18.96875 -0.25 \n",
       "Q 13.140625 0.921875 6.890625 3.21875 \n",
       "L 6.890625 13.375 \n",
       "Q 12.890625 10.015625 18.65625 8.296875 \n",
       "Q 24.421875 6.59375 29.984375 6.59375 \n",
       "Q 38.421875 6.59375 43.015625 9.90625 \n",
       "Q 47.609375 13.234375 47.609375 19.390625 \n",
       "Q 47.609375 24.75 44.3125 27.78125 \n",
       "Q 41.015625 30.8125 33.5 32.328125 \n",
       "L 27.484375 33.5 \n",
       "Q 16.453125 35.6875 11.515625 40.375 \n",
       "Q 6.59375 45.0625 6.59375 53.421875 \n",
       "Q 6.59375 63.09375 13.40625 68.65625 \n",
       "Q 20.21875 74.21875 32.171875 74.21875 \n",
       "Q 37.3125 74.21875 42.625 73.28125 \n",
       "Q 47.953125 72.359375 53.515625 70.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-83\"/>\n",
       "      <path d=\"M 9.8125 72.90625 \n",
       "L 55.90625 72.90625 \n",
       "L 55.90625 64.59375 \n",
       "L 19.671875 64.59375 \n",
       "L 19.671875 43.015625 \n",
       "L 54.390625 43.015625 \n",
       "L 54.390625 34.71875 \n",
       "L 19.671875 34.71875 \n",
       "L 19.671875 8.296875 \n",
       "L 56.78125 8.296875 \n",
       "L 56.78125 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-69\"/>\n",
       "      <path id=\"DejaVuSans-32\"/>\n",
       "      <path d=\"M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-108\"/>\n",
       "      <path d=\"M 44.28125 53.078125 \n",
       "L 44.28125 44.578125 \n",
       "Q 40.484375 46.53125 36.375 47.5 \n",
       "Q 32.28125 48.484375 27.875 48.484375 \n",
       "Q 21.1875 48.484375 17.84375 46.4375 \n",
       "Q 14.5 44.390625 14.5 40.28125 \n",
       "Q 14.5 37.15625 16.890625 35.375 \n",
       "Q 19.28125 33.59375 26.515625 31.984375 \n",
       "L 29.59375 31.296875 \n",
       "Q 39.15625 29.25 43.1875 25.515625 \n",
       "Q 47.21875 21.78125 47.21875 15.09375 \n",
       "Q 47.21875 7.46875 41.1875 3.015625 \n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \n",
       "Q 10.6875 0.296875 5.421875 2 \n",
       "L 5.421875 11.28125 \n",
       "Q 10.40625 8.6875 15.234375 7.390625 \n",
       "Q 20.0625 6.109375 24.8125 6.109375 \n",
       "Q 31.15625 6.109375 34.5625 8.28125 \n",
       "Q 37.984375 10.453125 37.984375 14.40625 \n",
       "Q 37.984375 18.0625 35.515625 20.015625 \n",
       "Q 33.0625 21.96875 24.703125 23.78125 \n",
       "L 21.578125 24.515625 \n",
       "Q 13.234375 26.265625 9.515625 29.90625 \n",
       "Q 5.8125 33.546875 5.8125 39.890625 \n",
       "Q 5.8125 47.609375 11.28125 51.796875 \n",
       "Q 16.75 56 26.8125 56 \n",
       "Q 31.78125 56 36.171875 55.265625 \n",
       "Q 40.578125 54.546875 44.28125 53.078125 \n",
       "z\n",
       "\" id=\"DejaVuSans-115\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(14.798438 152.932656)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-77\"/>\n",
       "      <use x=\"86.279297\" xlink:href=\"#DejaVuSans-83\"/>\n",
       "      <use x=\"149.755859\" xlink:href=\"#DejaVuSans-69\"/>\n",
       "      <use x=\"212.939453\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"244.726562\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "      <use x=\"272.509766\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"333.691406\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"385.791016\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path clip-path=\"url(#p5169031828)\" d=\"M 65.361932 50.862319 \n",
       "L 65.906411 56.939041 \n",
       "L 66.995368 62.743617 \n",
       "L 67.539847 69.857131 \n",
       "L 68.084326 73.24988 \n",
       "L 68.628804 78.22215 \n",
       "L 69.173283 77.066648 \n",
       "L 69.717762 78.530332 \n",
       "L 70.262241 91.131392 \n",
       "L 70.80672 91.98763 \n",
       "L 71.351198 95.594384 \n",
       "L 71.895677 101.504556 \n",
       "L 72.440156 86.796414 \n",
       "L 72.984635 103.645403 \n",
       "L 73.529113 107.324266 \n",
       "L 74.073592 109.609413 \n",
       "L 74.618071 104.545358 \n",
       "L 75.16255 115.47058 \n",
       "L 75.707029 117.587987 \n",
       "L 76.251507 121.390019 \n",
       "L 77.340465 124.285101 \n",
       "L 77.884944 128.544677 \n",
       "L 78.429422 131.327732 \n",
       "L 78.973901 134.839997 \n",
       "L 79.51838 134.6865 \n",
       "L 80.062859 125.270543 \n",
       "L 81.151816 140.245194 \n",
       "L 81.696295 137.115354 \n",
       "L 82.240774 142.121599 \n",
       "L 83.329731 142.64074 \n",
       "L 83.87421 141.35437 \n",
       "L 84.418689 152.680467 \n",
       "L 84.963168 144.166585 \n",
       "L 85.507647 152.93165 \n",
       "L 86.052125 156.921364 \n",
       "L 86.596604 158.635444 \n",
       "L 87.141083 99.400804 \n",
       "L 87.685562 161.035323 \n",
       "L 88.23004 150.680063 \n",
       "L 88.774519 162.116715 \n",
       "L 89.318998 165.711293 \n",
       "L 89.863477 163.988865 \n",
       "L 90.407956 163.10709 \n",
       "L 90.952434 170.759614 \n",
       "L 91.496913 164.476771 \n",
       "L 92.041392 166.904188 \n",
       "L 92.585871 162.275861 \n",
       "L 93.130349 174.510645 \n",
       "L 93.674828 173.582305 \n",
       "L 94.219307 159.643904 \n",
       "L 94.763786 172.057235 \n",
       "L 95.308265 168.622986 \n",
       "L 95.852743 173.885956 \n",
       "L 96.397222 181.656553 \n",
       "L 96.941701 173.962902 \n",
       "L 97.48618 180.804901 \n",
       "L 98.030658 184.367235 \n",
       "L 98.575137 181.729719 \n",
       "L 99.119616 174.067417 \n",
       "L 99.664095 177.618248 \n",
       "L 100.208574 170.437043 \n",
       "L 100.753052 184.653742 \n",
       "L 101.297531 186.928699 \n",
       "L 101.84201 186.582807 \n",
       "L 102.386489 179.511878 \n",
       "L 102.930967 186.320724 \n",
       "L 103.475446 179.339239 \n",
       "L 104.019925 184.971309 \n",
       "L 104.564404 189.412497 \n",
       "L 105.108883 186.909951 \n",
       "L 105.653361 183.583039 \n",
       "L 106.19784 191.282474 \n",
       "L 106.742319 194.354011 \n",
       "L 107.286798 186.070659 \n",
       "L 107.831276 174.606763 \n",
       "L 108.375755 179.101939 \n",
       "L 108.920234 195.950715 \n",
       "L 109.464713 187.149244 \n",
       "L 110.009192 194.736267 \n",
       "L 110.55367 195.895362 \n",
       "L 111.098149 194.439044 \n",
       "L 111.642628 195.378983 \n",
       "L 112.187107 194.658689 \n",
       "L 112.731585 187.09198 \n",
       "L 113.276064 192.694601 \n",
       "L 113.820543 184.62874 \n",
       "L 114.909501 197.79902 \n",
       "L 115.453979 189.088523 \n",
       "L 115.998458 200.275121 \n",
       "L 116.542937 199.053278 \n",
       "L 117.087416 202.180494 \n",
       "L 117.631894 202.710976 \n",
       "L 118.176373 200.722703 \n",
       "L 119.265331 201.270344 \n",
       "L 119.80981 201.78339 \n",
       "L 120.354288 203.13048 \n",
       "L 120.898767 205.217578 \n",
       "L 121.443246 202.929808 \n",
       "L 121.987725 202.154778 \n",
       "L 122.532203 202.536652 \n",
       "L 123.076682 187.809581 \n",
       "L 123.621161 194.601964 \n",
       "L 124.16564 192.645126 \n",
       "L 124.710119 200.422965 \n",
       "L 125.254597 204.870117 \n",
       "L 125.799076 202.992126 \n",
       "L 126.343555 206.031097 \n",
       "L 126.888034 188.151225 \n",
       "L 127.432512 205.275653 \n",
       "L 127.976991 204.638217 \n",
       "L 128.52147 204.622047 \n",
       "L 129.065949 199.481346 \n",
       "L 129.610428 206.810496 \n",
       "L 130.154906 196.641983 \n",
       "L 130.699385 206.837112 \n",
       "L 131.243864 206.037044 \n",
       "L 131.788343 197.525055 \n",
       "L 132.332821 206.262531 \n",
       "L 132.8773 206.916429 \n",
       "L 133.421779 200.485514 \n",
       "L 133.966258 197.702955 \n",
       "L 134.510737 203.279814 \n",
       "L 135.055215 204.044909 \n",
       "L 135.599694 200.84291 \n",
       "L 136.144173 204.739844 \n",
       "L 136.688652 199.759319 \n",
       "L 137.23313 205.991262 \n",
       "L 137.777609 205.910719 \n",
       "L 138.322088 207.752969 \n",
       "L 138.866567 208.238491 \n",
       "L 139.411045 208.198524 \n",
       "L 139.955524 207.245151 \n",
       "L 140.500003 209.852128 \n",
       "L 141.044482 209.245127 \n",
       "L 141.588961 211.34736 \n",
       "L 142.133439 204.408075 \n",
       "L 142.677918 211.867654 \n",
       "L 143.222397 210.810497 \n",
       "L 143.766876 211.607016 \n",
       "L 144.311354 212.0206 \n",
       "L 144.855833 207.207501 \n",
       "L 145.400312 205.476067 \n",
       "L 145.944791 213.099138 \n",
       "L 146.48927 211.389925 \n",
       "L 147.033748 210.113808 \n",
       "L 148.122706 213.939541 \n",
       "L 148.667185 213.23581 \n",
       "L 149.211663 214.02331 \n",
       "L 149.756142 215.391097 \n",
       "L 150.300621 212.255621 \n",
       "L 150.8451 210.253101 \n",
       "L 151.389579 214.009552 \n",
       "L 151.934057 214.488268 \n",
       "L 152.478536 212.308738 \n",
       "L 153.023015 214.703262 \n",
       "L 153.567494 214.706235 \n",
       "L 154.111972 215.85048 \n",
       "L 154.656451 213.491026 \n",
       "L 155.745409 216.345792 \n",
       "L 156.289888 216.151446 \n",
       "L 156.834366 217.559917 \n",
       "L 157.378845 215.851568 \n",
       "L 157.923324 214.772062 \n",
       "L 158.467803 215.286104 \n",
       "L 159.012281 217.606456 \n",
       "L 159.55676 215.404477 \n",
       "L 160.101239 217.685121 \n",
       "L 160.645718 217.203447 \n",
       "L 161.190197 218.223961 \n",
       "L 161.734675 217.051265 \n",
       "L 162.279154 216.695842 \n",
       "L 162.823633 214.318254 \n",
       "L 163.368112 218.23975 \n",
       "L 163.91259 218.144005 \n",
       "L 164.457069 217.817943 \n",
       "L 165.001548 218.403187 \n",
       "L 165.546027 214.401898 \n",
       "L 166.090506 214.106076 \n",
       "L 166.634984 219.998311 \n",
       "L 167.179463 214.514416 \n",
       "L 167.723942 218.572172 \n",
       "L 168.268421 216.920237 \n",
       "L 168.812899 219.313113 \n",
       "L 169.901857 219.017559 \n",
       "L 170.446336 217.552824 \n",
       "L 170.990815 215.371848 \n",
       "L 171.535293 221.754079 \n",
       "L 172.079772 219.268804 \n",
       "L 172.624251 219.70794 \n",
       "L 173.16873 219.183294 \n",
       "L 173.713208 219.846391 \n",
       "L 174.257687 220.273461 \n",
       "L 174.802166 220.526584 \n",
       "L 175.346645 221.595178 \n",
       "L 175.891124 222.360331 \n",
       "L 176.435602 219.613224 \n",
       "L 176.980081 222.646104 \n",
       "L 177.52456 221.255975 \n",
       "L 178.069039 219.040914 \n",
       "L 178.613517 217.969708 \n",
       "L 179.702475 223.14802 \n",
       "L 180.246954 221.011132 \n",
       "L 180.791433 219.59325 \n",
       "L 181.335911 221.449383 \n",
       "L 181.88039 222.864611 \n",
       "L 182.424869 223.561597 \n",
       "L 182.969348 223.267154 \n",
       "L 183.513826 220.540749 \n",
       "L 184.058305 223.48141 \n",
       "L 184.602784 223.945057 \n",
       "L 185.147263 217.677228 \n",
       "L 185.691742 219.951456 \n",
       "L 186.23622 217.289324 \n",
       "L 186.780699 222.170585 \n",
       "L 187.325178 220.653894 \n",
       "L 187.869657 223.213631 \n",
       "L 188.958614 223.444178 \n",
       "L 189.503093 221.443591 \n",
       "L 190.047572 223.984947 \n",
       "L 190.592051 224.273034 \n",
       "L 191.136529 222.259622 \n",
       "L 191.681008 220.956814 \n",
       "L 192.225487 224.376585 \n",
       "L 192.769966 222.656482 \n",
       "L 193.314444 224.631468 \n",
       "L 193.858923 224.039706 \n",
       "L 194.403402 222.625176 \n",
       "L 195.49236 225.097729 \n",
       "L 196.036838 224.716261 \n",
       "L 196.581317 225.188928 \n",
       "L 197.125796 223.205165 \n",
       "L 197.670275 223.494057 \n",
       "L 198.214753 224.89611 \n",
       "L 198.759232 220.122345 \n",
       "L 199.303711 223.227382 \n",
       "L 199.84819 223.117522 \n",
       "L 200.392669 225.193029 \n",
       "L 200.937147 223.970934 \n",
       "L 201.481626 224.000086 \n",
       "L 202.026105 224.472614 \n",
       "L 202.570584 223.533941 \n",
       "L 203.115062 224.501677 \n",
       "L 203.659541 223.986361 \n",
       "L 204.20402 224.451765 \n",
       "L 204.748499 223.855789 \n",
       "L 205.292978 224.746881 \n",
       "L 205.837456 222.714776 \n",
       "L 206.381935 223.517998 \n",
       "L 206.926414 224.599922 \n",
       "L 207.470893 226.448713 \n",
       "L 208.015371 224.290759 \n",
       "L 208.55985 226.058822 \n",
       "L 209.104329 225.212037 \n",
       "L 209.648808 225.148959 \n",
       "L 210.737765 226.733266 \n",
       "L 211.282244 223.765448 \n",
       "L 211.826723 223.568722 \n",
       "L 212.371202 224.337538 \n",
       "L 212.91568 224.699719 \n",
       "L 214.004638 226.915439 \n",
       "L 214.549117 226.187922 \n",
       "L 215.093596 225.991575 \n",
       "L 215.638074 225.614917 \n",
       "L 216.182553 222.528582 \n",
       "L 216.727032 225.808518 \n",
       "L 217.271511 225.438315 \n",
       "L 217.815989 223.671694 \n",
       "L 218.360468 226.484064 \n",
       "L 218.904947 222.611873 \n",
       "L 219.449426 224.996552 \n",
       "L 219.993904 225.890151 \n",
       "L 220.538383 223.478962 \n",
       "L 221.082862 226.589055 \n",
       "L 221.627341 223.696127 \n",
       "L 222.17182 225.28423 \n",
       "L 222.716298 224.3728 \n",
       "L 223.260777 225.619393 \n",
       "L 223.805256 219.614299 \n",
       "L 224.349735 225.531067 \n",
       "L 224.894213 225.695381 \n",
       "L 225.983171 224.445183 \n",
       "L 226.52765 225.608439 \n",
       "L 227.072129 226.50498 \n",
       "L 227.616607 224.514198 \n",
       "L 228.161086 225.20951 \n",
       "L 228.705565 223.426933 \n",
       "L 229.250044 224.780103 \n",
       "L 229.794522 225.730818 \n",
       "L 230.339001 226.407926 \n",
       "L 230.88348 226.867593 \n",
       "L 231.427959 226.521866 \n",
       "L 231.972438 225.332603 \n",
       "L 232.516916 227.320478 \n",
       "L 233.061395 226.952036 \n",
       "L 233.605874 225.382956 \n",
       "L 234.150353 227.321131 \n",
       "L 234.694831 226.19257 \n",
       "L 235.23931 225.706364 \n",
       "L 235.783789 227.131347 \n",
       "L 236.328268 226.124486 \n",
       "L 236.872747 227.535977 \n",
       "L 237.417225 226.354781 \n",
       "L 237.961704 224.41911 \n",
       "L 238.506183 224.573832 \n",
       "L 239.050662 227.068353 \n",
       "L 239.59514 226.764136 \n",
       "L 240.139619 227.569135 \n",
       "L 240.684098 225.429488 \n",
       "L 241.228577 225.900447 \n",
       "L 241.773056 224.016221 \n",
       "L 242.317534 225.188166 \n",
       "L 242.862013 225.090205 \n",
       "L 243.406492 227.218796 \n",
       "L 243.950971 223.515242 \n",
       "L 244.495449 226.151131 \n",
       "L 245.039928 225.164508 \n",
       "L 245.584407 226.545608 \n",
       "L 246.128886 226.145437 \n",
       "L 246.673365 226.837886 \n",
       "L 247.217843 225.738157 \n",
       "L 247.762322 223.206629 \n",
       "L 248.306801 227.869849 \n",
       "L 248.85128 228.826561 \n",
       "L 249.395758 228.279047 \n",
       "L 249.940237 224.437436 \n",
       "L 250.484716 228.524472 \n",
       "L 251.029195 228.856148 \n",
       "L 251.573674 224.740159 \n",
       "L 252.118152 226.81868 \n",
       "L 252.662631 226.862734 \n",
       "L 253.20711 227.372791 \n",
       "L 253.751589 227.27898 \n",
       "L 254.296067 228.288397 \n",
       "L 254.840546 228.603243 \n",
       "L 255.385025 228.716595 \n",
       "L 255.929504 227.46265 \n",
       "L 256.473983 227.216325 \n",
       "L 257.018461 224.557521 \n",
       "L 257.56294 227.186072 \n",
       "L 258.107419 226.235184 \n",
       "L 258.651898 228.437267 \n",
       "L 259.196376 227.485129 \n",
       "L 259.740855 228.491539 \n",
       "L 260.285334 228.054662 \n",
       "L 261.374292 228.365459 \n",
       "L 261.91877 224.654499 \n",
       "L 262.463249 228.877559 \n",
       "L 263.007728 227.016005 \n",
       "L 263.552207 227.443489 \n",
       "L 264.096685 225.346724 \n",
       "L 264.641164 225.96394 \n",
       "L 265.185643 228.396966 \n",
       "L 265.730122 229.533931 \n",
       "L 266.274601 227.608415 \n",
       "L 266.819079 228.182953 \n",
       "L 267.363558 228.177911 \n",
       "L 267.908037 226.490757 \n",
       "L 268.452516 227.173409 \n",
       "L 268.996994 225.617753 \n",
       "L 269.541473 229.139334 \n",
       "L 270.085952 228.647061 \n",
       "L 271.17491 223.66836 \n",
       "L 271.719388 227.791648 \n",
       "L 272.263867 228.263677 \n",
       "L 272.808346 229.074354 \n",
       "L 273.352825 227.343653 \n",
       "L 273.897303 228.139259 \n",
       "L 274.441782 227.370914 \n",
       "L 274.986261 228.486245 \n",
       "L 275.53074 227.835954 \n",
       "L 276.075219 223.625833 \n",
       "L 276.619697 228.255566 \n",
       "L 277.164176 229.512223 \n",
       "L 277.708655 228.63822 \n",
       "L 278.253134 229.14537 \n",
       "L 278.797612 228.540598 \n",
       "L 279.342091 227.335752 \n",
       "L 279.88657 227.689731 \n",
       "L 280.431049 227.573829 \n",
       "L 280.975528 225.739796 \n",
       "L 281.520006 227.403972 \n",
       "L 282.608964 228.573754 \n",
       "L 283.153443 228.403413 \n",
       "L 283.697921 227.78679 \n",
       "L 284.2424 228.763925 \n",
       "L 284.786879 225.735005 \n",
       "L 285.331358 228.936628 \n",
       "L 285.875837 228.511492 \n",
       "L 286.964794 226.798301 \n",
       "L 287.509273 228.328463 \n",
       "L 288.053752 227.856639 \n",
       "L 288.59823 226.885472 \n",
       "L 289.142709 228.606004 \n",
       "L 290.776146 226.595381 \n",
       "L 291.320624 228.936916 \n",
       "L 292.409582 226.31189 \n",
       "L 292.954061 225.545396 \n",
       "L 293.498539 228.177263 \n",
       "L 294.043018 229.554063 \n",
       "L 294.587497 226.833147 \n",
       "L 295.131976 228.240129 \n",
       "L 295.676455 227.289647 \n",
       "L 296.220933 226.669724 \n",
       "L 296.765412 228.59863 \n",
       "L 297.309891 228.821503 \n",
       "L 297.85437 229.39529 \n",
       "L 298.398848 227.523588 \n",
       "L 299.487806 229.314624 \n",
       "L 300.032285 227.721608 \n",
       "L 300.576763 227.878934 \n",
       "L 301.121242 226.690194 \n",
       "L 302.2102 227.567928 \n",
       "L 302.754679 228.825096 \n",
       "L 303.299157 228.466518 \n",
       "L 303.843636 225.409197 \n",
       "L 304.388115 228.556153 \n",
       "L 304.932594 225.995453 \n",
       "L 305.477072 229.386262 \n",
       "L 306.021551 227.866453 \n",
       "L 306.56603 229.029663 \n",
       "L 307.110509 226.715456 \n",
       "L 307.654988 227.763306 \n",
       "L 308.199466 229.335129 \n",
       "L 308.743945 228.552454 \n",
       "L 309.288424 226.361663 \n",
       "L 309.832903 226.738327 \n",
       "L 310.377381 228.800869 \n",
       "L 310.92186 227.846674 \n",
       "L 311.466339 227.440438 \n",
       "L 312.555297 229.261383 \n",
       "L 313.099775 229.465328 \n",
       "L 313.644254 228.485519 \n",
       "L 314.188733 227.917909 \n",
       "L 314.733212 229.001568 \n",
       "L 315.27769 228.723479 \n",
       "L 315.822169 228.692136 \n",
       "L 316.366648 229.120573 \n",
       "L 316.911127 227.442847 \n",
       "L 317.455606 228.50827 \n",
       "L 318.000084 227.941656 \n",
       "L 318.544563 228.19184 \n",
       "L 319.089042 229.394091 \n",
       "L 319.633521 227.532366 \n",
       "L 320.177999 227.672929 \n",
       "L 320.722478 229.012279 \n",
       "L 321.266957 229.159474 \n",
       "L 321.811436 228.641463 \n",
       "L 322.355915 228.305056 \n",
       "L 322.900393 228.304191 \n",
       "L 323.444872 229.713029 \n",
       "L 323.989351 227.029474 \n",
       "L 324.53383 229.361236 \n",
       "L 325.078308 226.695982 \n",
       "L 325.622787 228.78237 \n",
       "L 326.167266 227.271161 \n",
       "L 326.711745 227.135506 \n",
       "L 327.256224 228.533146 \n",
       "L 327.800702 229.238961 \n",
       "L 328.345181 226.849078 \n",
       "L 328.88966 229.482794 \n",
       "L 329.434139 229.001784 \n",
       "L 329.978617 227.160654 \n",
       "L 330.523096 228.936876 \n",
       "L 331.067575 228.476904 \n",
       "L 331.612054 228.307895 \n",
       "L 332.156533 227.605337 \n",
       "L 332.701011 229.214538 \n",
       "L 333.24549 227.707946 \n",
       "L 333.789969 226.646434 \n",
       "L 334.878926 229.874489 \n",
       "L 335.423405 228.795504 \n",
       "L 335.967884 228.88601 \n",
       "L 336.512363 229.250789 \n",
       "L 337.056842 229.276622 \n",
       "L 337.60132 228.098783 \n",
       "L 338.145799 229.087001 \n",
       "L 338.690278 229.738861 \n",
       "L 339.234757 228.880798 \n",
       "L 339.779235 229.552158 \n",
       "L 340.323714 228.429109 \n",
       "L 340.868193 227.961103 \n",
       "L 341.412672 227.883759 \n",
       "L 341.957151 229.479222 \n",
       "L 342.501629 228.729786 \n",
       "L 343.046108 227.126346 \n",
       "L 343.590587 228.575072 \n",
       "L 344.135066 228.258007 \n",
       "L 344.679544 227.802577 \n",
       "L 345.224023 228.831086 \n",
       "L 345.768502 228.503433 \n",
       "L 346.312981 226.024831 \n",
       "L 346.85746 227.985491 \n",
       "L 347.401938 228.508119 \n",
       "L 347.946417 229.332866 \n",
       "L 348.490896 227.903815 \n",
       "L 349.035375 229.090188 \n",
       "L 349.579853 229.002951 \n",
       "L 350.124332 227.968851 \n",
       "L 351.21329 229.563352 \n",
       "L 351.757769 228.71351 \n",
       "L 352.302247 226.571924 \n",
       "L 353.391205 229.640074 \n",
       "L 353.935684 228.786287 \n",
       "L 354.480162 228.99711 \n",
       "L 356.113599 228.897596 \n",
       "L 356.658078 225.305778 \n",
       "L 357.202556 229.271646 \n",
       "L 357.747035 228.168915 \n",
       "L 358.291514 228.961968 \n",
       "L 358.835993 225.924121 \n",
       "L 359.380471 228.489963 \n",
       "L 359.92495 229.006074 \n",
       "L 360.469429 227.868561 \n",
       "L 361.013908 228.483348 \n",
       "L 361.558387 225.849903 \n",
       "L 362.102865 228.898224 \n",
       "L 362.647344 228.355766 \n",
       "L 363.191823 228.02164 \n",
       "L 363.736302 228.076972 \n",
       "L 364.28078 227.961426 \n",
       "L 364.825259 228.100416 \n",
       "L 365.369738 228.107527 \n",
       "L 365.914217 229.301277 \n",
       "L 366.458696 229.614915 \n",
       "L 367.003174 226.641585 \n",
       "L 367.547653 228.540557 \n",
       "L 368.092132 228.151395 \n",
       "L 368.636611 227.434631 \n",
       "L 369.181089 228.186755 \n",
       "L 369.725568 228.554125 \n",
       "L 369.725568 228.554125 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path clip-path=\"url(#p5169031828)\" d=\"M 65.361932 32.201761 \n",
       "L 65.906411 60.725459 \n",
       "L 66.450889 65.162873 \n",
       "L 66.995368 68.662408 \n",
       "L 67.539847 73.362964 \n",
       "L 68.084326 71.950979 \n",
       "L 68.628804 82.087155 \n",
       "L 69.173283 80.993449 \n",
       "L 69.717762 86.887418 \n",
       "L 70.262241 98.510922 \n",
       "L 70.80672 101.483401 \n",
       "L 71.351198 103.00525 \n",
       "L 71.895677 101.72373 \n",
       "L 72.440156 104.157771 \n",
       "L 72.984635 109.217679 \n",
       "L 73.529113 110.968595 \n",
       "L 74.073592 117.267376 \n",
       "L 74.618071 117.594334 \n",
       "L 75.16255 122.460286 \n",
       "L 75.707029 121.632705 \n",
       "L 76.251507 132.372727 \n",
       "L 76.795986 126.276322 \n",
       "L 77.340465 132.675579 \n",
       "L 77.884944 131.675172 \n",
       "L 78.429422 131.383782 \n",
       "L 78.973901 135.688506 \n",
       "L 79.51838 138.235246 \n",
       "L 80.062859 141.81665 \n",
       "L 80.607338 143.733484 \n",
       "L 81.696295 151.454781 \n",
       "L 82.240774 156.308918 \n",
       "L 82.785253 155.808588 \n",
       "L 83.329731 154.522982 \n",
       "L 83.87421 158.767424 \n",
       "L 84.418689 151.96216 \n",
       "L 84.963168 162.145839 \n",
       "L 85.507647 164.197076 \n",
       "L 86.052125 163.264139 \n",
       "L 86.596604 163.707373 \n",
       "L 87.141083 165.806179 \n",
       "L 87.685562 169.287065 \n",
       "L 88.23004 165.380194 \n",
       "L 88.774519 168.611651 \n",
       "L 89.863477 172.33339 \n",
       "L 90.407956 175.955373 \n",
       "L 90.952434 176.020089 \n",
       "L 91.496913 173.8188 \n",
       "L 92.041392 174.317525 \n",
       "L 92.585871 175.546054 \n",
       "L 93.130349 176.252876 \n",
       "L 93.674828 177.462185 \n",
       "L 94.219307 176.692943 \n",
       "L 94.763786 183.431995 \n",
       "L 95.308265 181.924233 \n",
       "L 96.397222 186.031954 \n",
       "L 96.941701 185.048962 \n",
       "L 97.48618 183.832672 \n",
       "L 98.030658 189.630183 \n",
       "L 98.575137 184.896 \n",
       "L 99.119616 192.331462 \n",
       "L 99.664095 189.564656 \n",
       "L 100.208574 189.346882 \n",
       "L 100.753052 190.631539 \n",
       "L 101.84201 194.083853 \n",
       "L 102.386489 194.932759 \n",
       "L 102.930967 193.965937 \n",
       "L 103.475446 187.36394 \n",
       "L 104.019925 192.360248 \n",
       "L 104.564404 190.6319 \n",
       "L 105.108883 192.79267 \n",
       "L 105.653361 192.684158 \n",
       "L 106.19784 194.32271 \n",
       "L 106.742319 198.185243 \n",
       "L 107.286798 196.60387 \n",
       "L 107.831276 193.814198 \n",
       "L 108.920234 196.424861 \n",
       "L 109.464713 200.588457 \n",
       "L 110.009192 201.624109 \n",
       "L 110.55367 201.997865 \n",
       "L 111.098149 201.874785 \n",
       "L 111.642628 199.542973 \n",
       "L 112.187107 201.278965 \n",
       "L 112.731585 202.51184 \n",
       "L 113.276064 201.915233 \n",
       "L 113.820543 202.715042 \n",
       "L 114.365022 201.338531 \n",
       "L 114.909501 201.772729 \n",
       "L 115.453979 204.479757 \n",
       "L 115.998458 199.064405 \n",
       "L 116.542937 206.591494 \n",
       "L 117.087416 204.663943 \n",
       "L 117.631894 205.912113 \n",
       "L 118.176373 199.585157 \n",
       "L 118.720852 206.05944 \n",
       "L 119.265331 205.413226 \n",
       "L 119.80981 203.584949 \n",
       "L 120.354288 203.933324 \n",
       "L 120.898767 208.095493 \n",
       "L 121.443246 207.455848 \n",
       "L 121.987725 207.526387 \n",
       "L 122.532203 206.829695 \n",
       "L 123.076682 209.080411 \n",
       "L 123.621161 207.556167 \n",
       "L 124.16564 205.453692 \n",
       "L 124.710119 205.140244 \n",
       "L 125.254597 209.813389 \n",
       "L 125.799076 204.037352 \n",
       "L 126.343555 206.65447 \n",
       "L 126.888034 205.278286 \n",
       "L 127.432512 208.216811 \n",
       "L 127.976991 209.942395 \n",
       "L 128.52147 210.993816 \n",
       "L 129.065949 209.055766 \n",
       "L 129.610428 211.462021 \n",
       "L 130.154906 210.161411 \n",
       "L 130.699385 211.195566 \n",
       "L 131.243864 212.923614 \n",
       "L 131.788343 211.433621 \n",
       "L 132.332821 212.280686 \n",
       "L 133.421779 211.346303 \n",
       "L 133.966258 208.593887 \n",
       "L 135.055215 203.96326 \n",
       "L 135.599694 204.318835 \n",
       "L 136.144173 205.993943 \n",
       "L 136.688652 207.020553 \n",
       "L 137.23313 206.815163 \n",
       "L 137.777609 207.90276 \n",
       "L 138.322088 209.535921 \n",
       "L 138.866567 208.929301 \n",
       "L 139.411045 207.816913 \n",
       "L 139.955524 210.148767 \n",
       "L 140.500003 209.794998 \n",
       "L 141.044482 210.424994 \n",
       "L 141.588961 211.69311 \n",
       "L 142.133439 210.747059 \n",
       "L 142.677918 211.649305 \n",
       "L 143.222397 212.92824 \n",
       "L 143.766876 213.271302 \n",
       "L 144.311354 212.599742 \n",
       "L 144.855833 212.340212 \n",
       "L 145.400312 213.240601 \n",
       "L 146.48927 214.450047 \n",
       "L 147.033748 214.039109 \n",
       "L 147.578227 214.103881 \n",
       "L 148.122706 215.451546 \n",
       "L 148.667185 214.639114 \n",
       "L 149.211663 214.351775 \n",
       "L 149.756142 216.273902 \n",
       "L 150.300621 215.378594 \n",
       "L 150.8451 214.145811 \n",
       "L 151.389579 216.524791 \n",
       "L 151.934057 216.144919 \n",
       "L 152.478536 216.278827 \n",
       "L 153.023015 217.2117 \n",
       "L 153.567494 217.747731 \n",
       "L 154.111972 216.860914 \n",
       "L 154.656451 216.980306 \n",
       "L 155.20093 217.802422 \n",
       "L 155.745409 217.187024 \n",
       "L 156.289888 217.685142 \n",
       "L 156.834366 217.833808 \n",
       "L 157.378845 218.169725 \n",
       "L 157.923324 216.970266 \n",
       "L 158.467803 216.829777 \n",
       "L 159.012281 218.540357 \n",
       "L 159.55676 219.284773 \n",
       "L 160.101239 219.364493 \n",
       "L 160.645718 217.09946 \n",
       "L 161.190197 219.498069 \n",
       "L 161.734675 219.037786 \n",
       "L 162.279154 219.623841 \n",
       "L 162.823633 219.23908 \n",
       "L 163.368112 219.812484 \n",
       "L 163.91259 219.935041 \n",
       "L 164.457069 220.260864 \n",
       "L 165.001548 219.362164 \n",
       "L 165.546027 220.142992 \n",
       "L 166.090506 219.940848 \n",
       "L 166.634984 220.304314 \n",
       "L 167.179463 220.066632 \n",
       "L 167.723942 220.279411 \n",
       "L 168.268421 220.162453 \n",
       "L 168.812899 220.573906 \n",
       "L 169.357378 220.465222 \n",
       "L 169.901857 221.042374 \n",
       "L 170.990815 220.404004 \n",
       "L 171.535293 221.017108 \n",
       "L 172.624251 220.91323 \n",
       "L 173.16873 221.299606 \n",
       "L 174.257687 220.982802 \n",
       "L 174.802166 221.573696 \n",
       "L 175.346645 221.863015 \n",
       "L 175.891124 221.148565 \n",
       "L 176.435602 221.284738 \n",
       "L 178.069039 222.167226 \n",
       "L 178.613517 221.999245 \n",
       "L 179.157996 222.205262 \n",
       "L 179.702475 221.809762 \n",
       "L 180.791433 222.399276 \n",
       "L 183.513826 222.988256 \n",
       "L 184.058305 222.710921 \n",
       "L 184.602784 222.812358 \n",
       "L 185.147263 223.144636 \n",
       "L 185.691742 223.012407 \n",
       "L 186.23622 223.333274 \n",
       "L 186.780699 222.977168 \n",
       "L 187.325178 223.311067 \n",
       "L 187.869657 222.949867 \n",
       "L 188.414135 223.09748 \n",
       "L 188.958614 223.539676 \n",
       "L 189.503093 223.484425 \n",
       "L 190.592051 223.754329 \n",
       "L 191.136529 223.869555 \n",
       "L 192.225487 223.396904 \n",
       "L 192.769966 223.949636 \n",
       "L 193.314444 224.015244 \n",
       "L 193.858923 223.875323 \n",
       "L 194.403402 223.976191 \n",
       "L 194.947881 224.197103 \n",
       "L 195.49236 224.109353 \n",
       "L 196.581317 224.356856 \n",
       "L 197.125796 224.301805 \n",
       "L 198.214753 224.536371 \n",
       "L 198.759232 224.408803 \n",
       "L 199.303711 224.538084 \n",
       "L 199.84819 224.291294 \n",
       "L 200.392669 224.609904 \n",
       "L 202.026105 224.971712 \n",
       "L 203.115062 224.889232 \n",
       "L 204.20402 224.912061 \n",
       "L 204.748499 224.811929 \n",
       "L 205.292978 225.066665 \n",
       "L 205.837456 225.157787 \n",
       "L 206.381935 225.068391 \n",
       "L 206.926414 225.141887 \n",
       "L 207.470893 224.906145 \n",
       "L 208.015371 225.096201 \n",
       "L 208.55985 224.801366 \n",
       "L 209.104329 225.226589 \n",
       "L 210.737765 225.306495 \n",
       "L 211.282244 225.501115 \n",
       "L 212.371202 225.304993 \n",
       "L 212.91568 225.443071 \n",
       "L 213.460159 225.226862 \n",
       "L 214.004638 225.531388 \n",
       "L 215.093596 225.537874 \n",
       "L 215.638074 225.836411 \n",
       "L 216.727032 225.829389 \n",
       "L 217.271511 225.533504 \n",
       "L 217.815989 225.952801 \n",
       "L 218.360468 225.80682 \n",
       "L 218.904947 226.011415 \n",
       "L 219.449426 225.789475 \n",
       "L 221.082862 225.829268 \n",
       "L 221.627341 225.959767 \n",
       "L 222.17182 225.943809 \n",
       "L 222.716298 226.237007 \n",
       "L 223.260777 226.014405 \n",
       "L 223.805256 226.201411 \n",
       "L 225.438692 225.987279 \n",
       "L 228.705565 226.381905 \n",
       "L 229.794522 226.349749 \n",
       "L 230.339001 226.406613 \n",
       "L 230.88348 226.276409 \n",
       "L 231.427959 226.283811 \n",
       "L 231.972438 226.434112 \n",
       "L 232.516916 226.293569 \n",
       "L 233.061395 226.439447 \n",
       "L 234.150353 226.417649 \n",
       "L 235.23931 226.441964 \n",
       "L 235.783789 226.452347 \n",
       "L 236.328268 226.584725 \n",
       "L 236.872747 226.585492 \n",
       "L 237.417225 226.122021 \n",
       "L 238.506183 226.601353 \n",
       "L 240.139619 226.444326 \n",
       "L 241.228577 226.652529 \n",
       "L 241.773056 226.573636 \n",
       "L 242.317534 226.677691 \n",
       "L 242.862013 226.595576 \n",
       "L 243.406492 226.649873 \n",
       "L 243.950971 226.8417 \n",
       "L 245.039928 226.673262 \n",
       "L 245.584407 226.638299 \n",
       "L 246.128886 226.831808 \n",
       "L 246.673365 226.776405 \n",
       "L 247.217843 226.89706 \n",
       "L 249.395758 226.913857 \n",
       "L 249.940237 226.97933 \n",
       "L 251.029195 226.875656 \n",
       "L 251.573674 226.942927 \n",
       "L 252.118152 226.892665 \n",
       "L 252.662631 227.077681 \n",
       "L 253.20711 226.873785 \n",
       "L 253.751589 226.968541 \n",
       "L 254.296067 226.913161 \n",
       "L 255.385025 227.189179 \n",
       "L 255.929504 226.898404 \n",
       "L 257.018461 227.160212 \n",
       "L 257.56294 226.999522 \n",
       "L 258.107419 227.137694 \n",
       "L 258.651898 226.959155 \n",
       "L 259.196376 227.29369 \n",
       "L 259.740855 227.04065 \n",
       "L 262.463249 227.349119 \n",
       "L 263.552207 227.14201 \n",
       "L 264.096685 227.399792 \n",
       "L 265.185643 227.420446 \n",
       "L 266.274601 227.28576 \n",
       "L 266.819079 227.461624 \n",
       "L 269.541473 227.625975 \n",
       "L 270.085952 227.416179 \n",
       "L 270.630431 227.625749 \n",
       "L 271.719388 227.597857 \n",
       "L 272.263867 227.717456 \n",
       "L 272.808346 227.637518 \n",
       "L 273.897303 227.675539 \n",
       "L 276.619697 227.748543 \n",
       "L 278.253134 227.798685 \n",
       "L 278.797612 227.669657 \n",
       "L 279.88657 227.831723 \n",
       "L 283.153443 227.845872 \n",
       "L 284.2424 227.760994 \n",
       "L 284.786879 227.862955 \n",
       "L 286.964794 227.756465 \n",
       "L 287.509273 227.896735 \n",
       "L 288.59823 227.845544 \n",
       "L 291.320624 227.753614 \n",
       "L 291.865103 227.899116 \n",
       "L 294.587497 227.931227 \n",
       "L 297.85437 227.995625 \n",
       "L 298.398848 227.919222 \n",
       "L 299.487806 227.995548 \n",
       "L 307.110509 228.041025 \n",
       "L 307.654988 228.077463 \n",
       "L 308.743945 228.028836 \n",
       "L 333.789969 228.100932 \n",
       "L 334.334448 228.173319 \n",
       "L 335.423405 228.114523 \n",
       "L 343.046108 228.12419 \n",
       "L 343.590587 228.066685 \n",
       "L 344.679544 228.204377 \n",
       "L 347.946417 228.111738 \n",
       "L 349.579853 228.180974 \n",
       "L 351.21329 228.0558 \n",
       "L 352.302247 228.150434 \n",
       "L 352.846726 228.204074 \n",
       "L 353.391205 228.099443 \n",
       "L 353.935684 228.202254 \n",
       "L 355.56912 228.071896 \n",
       "L 356.113599 228.164089 \n",
       "L 357.747035 228.158327 \n",
       "L 358.835993 228.165087 \n",
       "L 364.825259 228.162061 \n",
       "L 365.369738 228.107942 \n",
       "L 365.914217 228.193072 \n",
       "L 366.458696 228.077418 \n",
       "L 368.636611 228.158433 \n",
       "L 369.181089 228.11389 \n",
       "L 369.725568 228.187124 \n",
       "L 369.725568 228.187124 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 50.14375 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 384.94375 239.758125 \n",
       "L 384.94375 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 384.94375 239.758125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 50.14375 22.318125 \n",
       "L 384.94375 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_17\">\n",
       "    <!-- autoencoder loss over time -->\n",
       "    <defs>\n",
       "     <path d=\"M 34.28125 27.484375 \n",
       "Q 23.390625 27.484375 19.1875 25 \n",
       "Q 14.984375 22.515625 14.984375 16.5 \n",
       "Q 14.984375 11.71875 18.140625 8.90625 \n",
       "Q 21.296875 6.109375 26.703125 6.109375 \n",
       "Q 34.1875 6.109375 38.703125 11.40625 \n",
       "Q 43.21875 16.703125 43.21875 25.484375 \n",
       "L 43.21875 27.484375 \n",
       "z\n",
       "M 52.203125 31.203125 \n",
       "L 52.203125 0 \n",
       "L 43.21875 0 \n",
       "L 43.21875 8.296875 \n",
       "Q 40.140625 3.328125 35.546875 0.953125 \n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \n",
       "Q 6 8.015625 6 15.921875 \n",
       "Q 6 25.140625 12.171875 29.828125 \n",
       "Q 18.359375 34.515625 30.609375 34.515625 \n",
       "L 43.21875 34.515625 \n",
       "L 43.21875 35.40625 \n",
       "Q 43.21875 41.609375 39.140625 45 \n",
       "Q 35.0625 48.390625 27.6875 48.390625 \n",
       "Q 23 48.390625 18.546875 47.265625 \n",
       "Q 14.109375 46.140625 10.015625 43.890625 \n",
       "L 10.015625 52.203125 \n",
       "Q 14.9375 54.109375 19.578125 55.046875 \n",
       "Q 24.21875 56 28.609375 56 \n",
       "Q 40.484375 56 46.34375 49.84375 \n",
       "Q 52.203125 43.703125 52.203125 31.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-97\"/>\n",
       "     <path d=\"M 8.5 21.578125 \n",
       "L 8.5 54.6875 \n",
       "L 17.484375 54.6875 \n",
       "L 17.484375 21.921875 \n",
       "Q 17.484375 14.15625 20.5 10.265625 \n",
       "Q 23.53125 6.390625 29.59375 6.390625 \n",
       "Q 36.859375 6.390625 41.078125 11.03125 \n",
       "Q 45.3125 15.671875 45.3125 23.6875 \n",
       "L 45.3125 54.6875 \n",
       "L 54.296875 54.6875 \n",
       "L 54.296875 0 \n",
       "L 45.3125 0 \n",
       "L 45.3125 8.40625 \n",
       "Q 42.046875 3.421875 37.71875 1 \n",
       "Q 33.40625 -1.421875 27.6875 -1.421875 \n",
       "Q 18.265625 -1.421875 13.375 4.4375 \n",
       "Q 8.5 10.296875 8.5 21.578125 \n",
       "z\n",
       "M 31.109375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-117\"/>\n",
       "     <path d=\"M 18.3125 70.21875 \n",
       "L 18.3125 54.6875 \n",
       "L 36.8125 54.6875 \n",
       "L 36.8125 47.703125 \n",
       "L 18.3125 47.703125 \n",
       "L 18.3125 18.015625 \n",
       "Q 18.3125 11.328125 20.140625 9.421875 \n",
       "Q 21.96875 7.515625 27.59375 7.515625 \n",
       "L 36.8125 7.515625 \n",
       "L 36.8125 0 \n",
       "L 27.59375 0 \n",
       "Q 17.1875 0 13.234375 3.875 \n",
       "Q 9.28125 7.765625 9.28125 18.015625 \n",
       "L 9.28125 47.703125 \n",
       "L 2.6875 47.703125 \n",
       "L 2.6875 54.6875 \n",
       "L 9.28125 54.6875 \n",
       "L 9.28125 70.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-116\"/>\n",
       "     <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-110\"/>\n",
       "     <path d=\"M 45.40625 46.390625 \n",
       "L 45.40625 75.984375 \n",
       "L 54.390625 75.984375 \n",
       "L 54.390625 0 \n",
       "L 45.40625 0 \n",
       "L 45.40625 8.203125 \n",
       "Q 42.578125 3.328125 38.25 0.953125 \n",
       "Q 33.9375 -1.421875 27.875 -1.421875 \n",
       "Q 17.96875 -1.421875 11.734375 6.484375 \n",
       "Q 5.515625 14.40625 5.515625 27.296875 \n",
       "Q 5.515625 40.1875 11.734375 48.09375 \n",
       "Q 17.96875 56 27.875 56 \n",
       "Q 33.9375 56 38.25 53.625 \n",
       "Q 42.578125 51.265625 45.40625 46.390625 \n",
       "z\n",
       "M 14.796875 27.296875 \n",
       "Q 14.796875 17.390625 18.875 11.75 \n",
       "Q 22.953125 6.109375 30.078125 6.109375 \n",
       "Q 37.203125 6.109375 41.296875 11.75 \n",
       "Q 45.40625 17.390625 45.40625 27.296875 \n",
       "Q 45.40625 37.203125 41.296875 42.84375 \n",
       "Q 37.203125 48.484375 30.078125 48.484375 \n",
       "Q 22.953125 48.484375 18.875 42.84375 \n",
       "Q 14.796875 37.203125 14.796875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-100\"/>\n",
       "     <path d=\"M 41.109375 46.296875 \n",
       "Q 39.59375 47.171875 37.8125 47.578125 \n",
       "Q 36.03125 48 33.890625 48 \n",
       "Q 26.265625 48 22.1875 43.046875 \n",
       "Q 18.109375 38.09375 18.109375 28.8125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 20.953125 51.171875 25.484375 53.578125 \n",
       "Q 30.03125 56 36.53125 56 \n",
       "Q 37.453125 56 38.578125 55.875 \n",
       "Q 39.703125 55.765625 41.0625 55.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-114\"/>\n",
       "     <path d=\"M 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 8.796875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "L 35.6875 0 \n",
       "L 23.484375 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-118\"/>\n",
       "     <path d=\"M 9.421875 54.6875 \n",
       "L 18.40625 54.6875 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 64.59375 \n",
       "L 9.421875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-105\"/>\n",
       "     <path d=\"M 52 44.1875 \n",
       "Q 55.375 50.25 60.0625 53.125 \n",
       "Q 64.75 56 71.09375 56 \n",
       "Q 79.640625 56 84.28125 50.015625 \n",
       "Q 88.921875 44.046875 88.921875 33.015625 \n",
       "L 88.921875 0 \n",
       "L 79.890625 0 \n",
       "L 79.890625 32.71875 \n",
       "Q 79.890625 40.578125 77.09375 44.375 \n",
       "Q 74.3125 48.1875 68.609375 48.1875 \n",
       "Q 61.625 48.1875 57.5625 43.546875 \n",
       "Q 53.515625 38.921875 53.515625 30.90625 \n",
       "L 53.515625 0 \n",
       "L 44.484375 0 \n",
       "L 44.484375 32.71875 \n",
       "Q 44.484375 40.625 41.703125 44.40625 \n",
       "Q 38.921875 48.1875 33.109375 48.1875 \n",
       "Q 26.21875 48.1875 22.15625 43.53125 \n",
       "Q 18.109375 38.875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.1875 51.21875 25.484375 53.609375 \n",
       "Q 29.78125 56 35.6875 56 \n",
       "Q 41.65625 56 45.828125 52.96875 \n",
       "Q 50 49.953125 52 44.1875 \n",
       "z\n",
       "\" id=\"DejaVuSans-109\"/>\n",
       "    </defs>\n",
       "    <g transform=\"translate(135.3625 16.318125)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-97\"/>\n",
       "     <use x=\"61.279297\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "     <use x=\"124.658203\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "     <use x=\"163.867188\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"225.048828\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"286.572266\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "     <use x=\"349.951172\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "     <use x=\"404.931641\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"466.113281\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "     <use x=\"529.589844\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"591.113281\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "     <use x=\"632.226562\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"664.013672\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "     <use x=\"691.796875\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"752.978516\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "     <use x=\"805.078125\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "     <use x=\"857.177734\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"888.964844\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"950.146484\" xlink:href=\"#DejaVuSans-118\"/>\n",
       "     <use x=\"1009.326172\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"1070.849609\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "     <use x=\"1111.962891\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"1143.75\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "     <use x=\"1182.958984\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "     <use x=\"1210.742188\" xlink:href=\"#DejaVuSans-109\"/>\n",
       "     <use x=\"1308.154297\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p5169031828\">\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"50.14375\" y=\"22.318125\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(losses3['epoch'], losses3['train_loss'])\n",
    "ax.plot(losses3['epoch'], losses3['validation_loss'])\n",
    "ax.set_ylabel('MSE loss')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_title('autoencoder loss over time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'autoencoder loss over time')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"277.314375pt\" version=\"1.1\" viewBox=\"0 0 392.14375 277.314375\" width=\"392.14375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 277.314375 \n",
       "L 392.14375 277.314375 \n",
       "L 392.14375 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 384.94375 239.758125 \n",
       "L 384.94375 22.318125 \n",
       "L 50.14375 22.318125 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"maf81c3fec6\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"64.637256\" xlink:href=\"#maf81c3fec6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(61.456006 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.117776\" xlink:href=\"#maf81c3fec6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 20 -->\n",
       "      <defs>\n",
       "       <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(101.755276 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"151.598295\" xlink:href=\"#maf81c3fec6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 40 -->\n",
       "      <defs>\n",
       "       <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(145.235795 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"195.078815\" xlink:href=\"#maf81c3fec6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 60 -->\n",
       "      <defs>\n",
       "       <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(188.716315 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"238.559334\" xlink:href=\"#maf81c3fec6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 80 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 34.625 \n",
       "Q 24.75 34.625 20.71875 30.859375 \n",
       "Q 16.703125 27.09375 16.703125 20.515625 \n",
       "Q 16.703125 13.921875 20.71875 10.15625 \n",
       "Q 24.75 6.390625 31.78125 6.390625 \n",
       "Q 38.8125 6.390625 42.859375 10.171875 \n",
       "Q 46.921875 13.96875 46.921875 20.515625 \n",
       "Q 46.921875 27.09375 42.890625 30.859375 \n",
       "Q 38.875 34.625 31.78125 34.625 \n",
       "z\n",
       "M 21.921875 38.8125 \n",
       "Q 15.578125 40.375 12.03125 44.71875 \n",
       "Q 8.5 49.078125 8.5 55.328125 \n",
       "Q 8.5 64.0625 14.71875 69.140625 \n",
       "Q 20.953125 74.21875 31.78125 74.21875 \n",
       "Q 42.671875 74.21875 48.875 69.140625 \n",
       "Q 55.078125 64.0625 55.078125 55.328125 \n",
       "Q 55.078125 49.078125 51.53125 44.71875 \n",
       "Q 48 40.375 41.703125 38.8125 \n",
       "Q 48.828125 37.15625 52.796875 32.3125 \n",
       "Q 56.78125 27.484375 56.78125 20.515625 \n",
       "Q 56.78125 9.90625 50.3125 4.234375 \n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \n",
       "Q 19.734375 -1.421875 13.25 4.234375 \n",
       "Q 6.78125 9.90625 6.78125 20.515625 \n",
       "Q 6.78125 27.484375 10.78125 32.3125 \n",
       "Q 14.796875 37.15625 21.921875 38.8125 \n",
       "z\n",
       "M 18.3125 54.390625 \n",
       "Q 18.3125 48.734375 21.84375 45.5625 \n",
       "Q 25.390625 42.390625 31.78125 42.390625 \n",
       "Q 38.140625 42.390625 41.71875 45.5625 \n",
       "Q 45.3125 48.734375 45.3125 54.390625 \n",
       "Q 45.3125 60.0625 41.71875 63.234375 \n",
       "Q 38.140625 66.40625 31.78125 66.40625 \n",
       "Q 25.390625 66.40625 21.84375 63.234375 \n",
       "Q 18.3125 60.0625 18.3125 54.390625 \n",
       "z\n",
       "\" id=\"DejaVuSans-56\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(232.196834 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"282.039854\" xlink:href=\"#maf81c3fec6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 100 -->\n",
       "      <defs>\n",
       "       <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(272.496104 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"325.520373\" xlink:href=\"#maf81c3fec6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 120 -->\n",
       "      <g transform=\"translate(315.976623 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"369.000893\" xlink:href=\"#maf81c3fec6\" y=\"239.758125\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 140 -->\n",
       "      <g transform=\"translate(359.457143 254.356562)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_9\">\n",
       "     <!-- epoch -->\n",
       "     <defs>\n",
       "      <path d=\"M 56.203125 29.59375 \n",
       "L 56.203125 25.203125 \n",
       "L 14.890625 25.203125 \n",
       "Q 15.484375 15.921875 20.484375 11.0625 \n",
       "Q 25.484375 6.203125 34.421875 6.203125 \n",
       "Q 39.59375 6.203125 44.453125 7.46875 \n",
       "Q 49.3125 8.734375 54.109375 11.28125 \n",
       "L 54.109375 2.78125 \n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \n",
       "Q 5.515625 13.8125 5.515625 26.8125 \n",
       "Q 5.515625 40.234375 12.765625 48.109375 \n",
       "Q 20.015625 56 32.328125 56 \n",
       "Q 43.359375 56 49.78125 48.890625 \n",
       "Q 56.203125 41.796875 56.203125 29.59375 \n",
       "z\n",
       "M 47.21875 32.234375 \n",
       "Q 47.125 39.59375 43.09375 43.984375 \n",
       "Q 39.0625 48.390625 32.421875 48.390625 \n",
       "Q 24.90625 48.390625 20.390625 44.140625 \n",
       "Q 15.875 39.890625 15.1875 32.171875 \n",
       "z\n",
       "\" id=\"DejaVuSans-101\"/>\n",
       "      <path d=\"M 18.109375 8.203125 \n",
       "L 18.109375 -20.796875 \n",
       "L 9.078125 -20.796875 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.390625 \n",
       "Q 20.953125 51.265625 25.265625 53.625 \n",
       "Q 29.59375 56 35.59375 56 \n",
       "Q 45.5625 56 51.78125 48.09375 \n",
       "Q 58.015625 40.1875 58.015625 27.296875 \n",
       "Q 58.015625 14.40625 51.78125 6.484375 \n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \n",
       "Q 20.953125 3.328125 18.109375 8.203125 \n",
       "z\n",
       "M 48.6875 27.296875 \n",
       "Q 48.6875 37.203125 44.609375 42.84375 \n",
       "Q 40.53125 48.484375 33.40625 48.484375 \n",
       "Q 26.265625 48.484375 22.1875 42.84375 \n",
       "Q 18.109375 37.203125 18.109375 27.296875 \n",
       "Q 18.109375 17.390625 22.1875 11.75 \n",
       "Q 26.265625 6.109375 33.40625 6.109375 \n",
       "Q 40.53125 6.109375 44.609375 11.75 \n",
       "Q 48.6875 17.390625 48.6875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-112\"/>\n",
       "      <path d=\"M 30.609375 48.390625 \n",
       "Q 23.390625 48.390625 19.1875 42.75 \n",
       "Q 14.984375 37.109375 14.984375 27.296875 \n",
       "Q 14.984375 17.484375 19.15625 11.84375 \n",
       "Q 23.34375 6.203125 30.609375 6.203125 \n",
       "Q 37.796875 6.203125 41.984375 11.859375 \n",
       "Q 46.1875 17.53125 46.1875 27.296875 \n",
       "Q 46.1875 37.015625 41.984375 42.703125 \n",
       "Q 37.796875 48.390625 30.609375 48.390625 \n",
       "z\n",
       "M 30.609375 56 \n",
       "Q 42.328125 56 49.015625 48.375 \n",
       "Q 55.71875 40.765625 55.71875 27.296875 \n",
       "Q 55.71875 13.875 49.015625 6.21875 \n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \n",
       "Q 5.515625 13.875 5.515625 27.296875 \n",
       "Q 5.515625 40.765625 12.171875 48.375 \n",
       "Q 18.84375 56 30.609375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-111\"/>\n",
       "      <path d=\"M 48.78125 52.59375 \n",
       "L 48.78125 44.1875 \n",
       "Q 44.96875 46.296875 41.140625 47.34375 \n",
       "Q 37.3125 48.390625 33.40625 48.390625 \n",
       "Q 24.65625 48.390625 19.8125 42.84375 \n",
       "Q 14.984375 37.3125 14.984375 27.296875 \n",
       "Q 14.984375 17.28125 19.8125 11.734375 \n",
       "Q 24.65625 6.203125 33.40625 6.203125 \n",
       "Q 37.3125 6.203125 41.140625 7.25 \n",
       "Q 44.96875 8.296875 48.78125 10.40625 \n",
       "L 48.78125 2.09375 \n",
       "Q 45.015625 0.34375 40.984375 -0.53125 \n",
       "Q 36.96875 -1.421875 32.421875 -1.421875 \n",
       "Q 20.0625 -1.421875 12.78125 6.34375 \n",
       "Q 5.515625 14.109375 5.515625 27.296875 \n",
       "Q 5.515625 40.671875 12.859375 48.328125 \n",
       "Q 20.21875 56 33.015625 56 \n",
       "Q 37.15625 56 41.109375 55.140625 \n",
       "Q 45.0625 54.296875 48.78125 52.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-99\"/>\n",
       "      <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 75.984375 \n",
       "L 18.109375 75.984375 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-104\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(202.315625 268.034687)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-101\"/>\n",
       "      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\n",
       "      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m844c708873\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m844c708873\" y=\"232.879267\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.00 -->\n",
       "      <defs>\n",
       "       <path d=\"M 10.6875 12.40625 \n",
       "L 21 12.40625 \n",
       "L 21 0 \n",
       "L 10.6875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-46\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(20.878125 236.678486)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m844c708873\" y=\"192.109373\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.05 -->\n",
       "      <defs>\n",
       "       <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(20.878125 195.908592)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m844c708873\" y=\"151.339479\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 0.10 -->\n",
       "      <g transform=\"translate(20.878125 155.138698)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m844c708873\" y=\"110.569585\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 0.15 -->\n",
       "      <g transform=\"translate(20.878125 114.368804)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m844c708873\" y=\"69.799691\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 0.20 -->\n",
       "      <g transform=\"translate(20.878125 73.598909)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m844c708873\" y=\"29.029797\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 0.25 -->\n",
       "      <g transform=\"translate(20.878125 32.829015)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- MSE loss -->\n",
       "     <defs>\n",
       "      <path d=\"M 9.8125 72.90625 \n",
       "L 24.515625 72.90625 \n",
       "L 43.109375 23.296875 \n",
       "L 61.8125 72.90625 \n",
       "L 76.515625 72.90625 \n",
       "L 76.515625 0 \n",
       "L 66.890625 0 \n",
       "L 66.890625 64.015625 \n",
       "L 48.09375 14.015625 \n",
       "L 38.1875 14.015625 \n",
       "L 19.390625 64.015625 \n",
       "L 19.390625 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-77\"/>\n",
       "      <path d=\"M 53.515625 70.515625 \n",
       "L 53.515625 60.890625 \n",
       "Q 47.90625 63.578125 42.921875 64.890625 \n",
       "Q 37.9375 66.21875 33.296875 66.21875 \n",
       "Q 25.25 66.21875 20.875 63.09375 \n",
       "Q 16.5 59.96875 16.5 54.203125 \n",
       "Q 16.5 49.359375 19.40625 46.890625 \n",
       "Q 22.3125 44.4375 30.421875 42.921875 \n",
       "L 36.375 41.703125 \n",
       "Q 47.40625 39.59375 52.65625 34.296875 \n",
       "Q 57.90625 29 57.90625 20.125 \n",
       "Q 57.90625 9.515625 50.796875 4.046875 \n",
       "Q 43.703125 -1.421875 29.984375 -1.421875 \n",
       "Q 24.8125 -1.421875 18.96875 -0.25 \n",
       "Q 13.140625 0.921875 6.890625 3.21875 \n",
       "L 6.890625 13.375 \n",
       "Q 12.890625 10.015625 18.65625 8.296875 \n",
       "Q 24.421875 6.59375 29.984375 6.59375 \n",
       "Q 38.421875 6.59375 43.015625 9.90625 \n",
       "Q 47.609375 13.234375 47.609375 19.390625 \n",
       "Q 47.609375 24.75 44.3125 27.78125 \n",
       "Q 41.015625 30.8125 33.5 32.328125 \n",
       "L 27.484375 33.5 \n",
       "Q 16.453125 35.6875 11.515625 40.375 \n",
       "Q 6.59375 45.0625 6.59375 53.421875 \n",
       "Q 6.59375 63.09375 13.40625 68.65625 \n",
       "Q 20.21875 74.21875 32.171875 74.21875 \n",
       "Q 37.3125 74.21875 42.625 73.28125 \n",
       "Q 47.953125 72.359375 53.515625 70.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-83\"/>\n",
       "      <path d=\"M 9.8125 72.90625 \n",
       "L 55.90625 72.90625 \n",
       "L 55.90625 64.59375 \n",
       "L 19.671875 64.59375 \n",
       "L 19.671875 43.015625 \n",
       "L 54.390625 43.015625 \n",
       "L 54.390625 34.71875 \n",
       "L 19.671875 34.71875 \n",
       "L 19.671875 8.296875 \n",
       "L 56.78125 8.296875 \n",
       "L 56.78125 0 \n",
       "L 9.8125 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-69\"/>\n",
       "      <path id=\"DejaVuSans-32\"/>\n",
       "      <path d=\"M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-108\"/>\n",
       "      <path d=\"M 44.28125 53.078125 \n",
       "L 44.28125 44.578125 \n",
       "Q 40.484375 46.53125 36.375 47.5 \n",
       "Q 32.28125 48.484375 27.875 48.484375 \n",
       "Q 21.1875 48.484375 17.84375 46.4375 \n",
       "Q 14.5 44.390625 14.5 40.28125 \n",
       "Q 14.5 37.15625 16.890625 35.375 \n",
       "Q 19.28125 33.59375 26.515625 31.984375 \n",
       "L 29.59375 31.296875 \n",
       "Q 39.15625 29.25 43.1875 25.515625 \n",
       "Q 47.21875 21.78125 47.21875 15.09375 \n",
       "Q 47.21875 7.46875 41.1875 3.015625 \n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \n",
       "Q 10.6875 0.296875 5.421875 2 \n",
       "L 5.421875 11.28125 \n",
       "Q 10.40625 8.6875 15.234375 7.390625 \n",
       "Q 20.0625 6.109375 24.8125 6.109375 \n",
       "Q 31.15625 6.109375 34.5625 8.28125 \n",
       "Q 37.984375 10.453125 37.984375 14.40625 \n",
       "Q 37.984375 18.0625 35.515625 20.015625 \n",
       "Q 33.0625 21.96875 24.703125 23.78125 \n",
       "L 21.578125 24.515625 \n",
       "Q 13.234375 26.265625 9.515625 29.90625 \n",
       "Q 5.8125 33.546875 5.8125 39.890625 \n",
       "Q 5.8125 47.609375 11.28125 51.796875 \n",
       "Q 16.75 56 26.8125 56 \n",
       "Q 31.78125 56 36.171875 55.265625 \n",
       "Q 40.578125 54.546875 44.28125 53.078125 \n",
       "z\n",
       "\" id=\"DejaVuSans-115\"/>\n",
       "     </defs>\n",
       "     <g transform=\"translate(14.798438 152.932656)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-77\"/>\n",
       "      <use x=\"86.279297\" xlink:href=\"#DejaVuSans-83\"/>\n",
       "      <use x=\"149.755859\" xlink:href=\"#DejaVuSans-69\"/>\n",
       "      <use x=\"212.939453\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "      <use x=\"244.726562\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "      <use x=\"272.509766\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "      <use x=\"333.691406\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "      <use x=\"385.791016\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path clip-path=\"url(#p686c8bb920)\" d=\"M 65.361932 49.654293 \n",
       "L 66.086607 58.808945 \n",
       "L 66.811282 54.554236 \n",
       "L 68.260633 65.142948 \n",
       "L 68.985308 77.474716 \n",
       "L 70.434659 73.087349 \n",
       "L 71.159334 81.788694 \n",
       "L 71.88401 83.958824 \n",
       "L 72.608685 89.347722 \n",
       "L 73.33336 92.355851 \n",
       "L 74.058036 99.257738 \n",
       "L 74.782711 99.027027 \n",
       "L 75.507386 100.294323 \n",
       "L 76.232062 104.606966 \n",
       "L 76.956737 109.703635 \n",
       "L 77.681412 113.626469 \n",
       "L 78.406088 112.04822 \n",
       "L 79.130763 114.553445 \n",
       "L 80.580114 120.607284 \n",
       "L 81.304789 117.872053 \n",
       "L 82.029464 129.490728 \n",
       "L 82.75414 130.659764 \n",
       "L 83.478815 132.28303 \n",
       "L 84.20349 129.280028 \n",
       "L 85.652841 137.398538 \n",
       "L 86.377516 137.643131 \n",
       "L 87.102192 144.989989 \n",
       "L 87.826867 139.601261 \n",
       "L 88.551542 147.744905 \n",
       "L 89.276218 148.47205 \n",
       "L 90.000893 143.564866 \n",
       "L 90.725568 151.212008 \n",
       "L 91.450244 143.800601 \n",
       "L 92.174919 155.821326 \n",
       "L 92.899594 152.881767 \n",
       "L 93.624269 156.073513 \n",
       "L 94.348945 158.125991 \n",
       "L 95.07362 159.691658 \n",
       "L 95.798295 150.936954 \n",
       "L 96.522971 158.575142 \n",
       "L 97.247646 154.071951 \n",
       "L 97.972321 164.937467 \n",
       "L 98.696997 159.711536 \n",
       "L 99.421672 166.15977 \n",
       "L 100.146347 157.281813 \n",
       "L 100.871023 164.107584 \n",
       "L 101.595698 163.910007 \n",
       "L 102.320373 171.170719 \n",
       "L 103.045049 164.615974 \n",
       "L 103.769724 175.517443 \n",
       "L 104.494399 175.647354 \n",
       "L 105.219075 178.204346 \n",
       "L 105.94375 179.606864 \n",
       "L 106.668425 173.302235 \n",
       "L 107.393101 178.313359 \n",
       "L 108.117776 180.276945 \n",
       "L 108.842451 179.81308 \n",
       "L 109.567127 180.51926 \n",
       "L 110.291802 181.519291 \n",
       "L 111.016477 183.541751 \n",
       "L 111.741153 175.492571 \n",
       "L 112.465828 182.142098 \n",
       "L 113.190503 186.357409 \n",
       "L 113.915179 176.553845 \n",
       "L 114.639854 184.501391 \n",
       "L 115.364529 187.155971 \n",
       "L 116.089205 182.563172 \n",
       "L 117.538555 192.139864 \n",
       "L 118.263231 182.489155 \n",
       "L 118.987906 190.885817 \n",
       "L 119.712581 191.511301 \n",
       "L 120.437256 190.145073 \n",
       "L 121.161932 192.890137 \n",
       "L 121.886607 186.348554 \n",
       "L 122.611282 193.634336 \n",
       "L 123.335958 192.132473 \n",
       "L 124.060633 192.89055 \n",
       "L 124.785308 187.877412 \n",
       "L 125.509984 195.010694 \n",
       "L 126.234659 197.976801 \n",
       "L 126.959334 193.511653 \n",
       "L 127.68401 198.89937 \n",
       "L 128.408685 192.985685 \n",
       "L 129.13336 191.864293 \n",
       "L 129.858036 188.148265 \n",
       "L 130.582711 195.033369 \n",
       "L 131.307386 188.761251 \n",
       "L 132.032062 192.054438 \n",
       "L 132.756737 198.731044 \n",
       "L 133.481412 197.975607 \n",
       "L 134.206088 198.179062 \n",
       "L 134.930763 199.613614 \n",
       "L 135.655438 192.968495 \n",
       "L 136.380114 192.951363 \n",
       "L 137.104789 200.07103 \n",
       "L 137.829464 203.873004 \n",
       "L 138.55414 200.610814 \n",
       "L 139.278815 200.512833 \n",
       "L 140.00349 199.513058 \n",
       "L 140.728166 202.669446 \n",
       "L 141.452841 203.672274 \n",
       "L 142.177516 203.684142 \n",
       "L 142.902192 192.426479 \n",
       "L 143.626867 196.567269 \n",
       "L 144.351542 198.783227 \n",
       "L 145.076218 204.211268 \n",
       "L 145.800893 200.243499 \n",
       "L 146.525568 205.711797 \n",
       "L 147.250244 205.792876 \n",
       "L 147.974919 204.076244 \n",
       "L 148.699594 204.573537 \n",
       "L 149.424269 207.952429 \n",
       "L 150.148945 203.827489 \n",
       "L 150.87362 200.406296 \n",
       "L 151.598295 205.879074 \n",
       "L 152.322971 204.29851 \n",
       "L 153.047646 210.873867 \n",
       "L 153.772321 206.508718 \n",
       "L 154.496997 195.825741 \n",
       "L 155.221672 203.882822 \n",
       "L 155.946347 206.643591 \n",
       "L 156.671023 208.183215 \n",
       "L 157.395698 196.280791 \n",
       "L 158.120373 207.156792 \n",
       "L 158.845049 207.282005 \n",
       "L 159.569724 207.239427 \n",
       "L 160.294399 207.702484 \n",
       "L 161.019075 207.886364 \n",
       "L 161.74375 196.605537 \n",
       "L 162.468425 205.390073 \n",
       "L 163.193101 203.695937 \n",
       "L 164.642451 211.520523 \n",
       "L 165.367127 211.389993 \n",
       "L 166.091802 199.868222 \n",
       "L 166.816477 207.724026 \n",
       "L 167.541153 191.407992 \n",
       "L 168.265828 199.747612 \n",
       "L 168.990503 198.789269 \n",
       "L 169.715179 206.195579 \n",
       "L 170.439854 212.059517 \n",
       "L 171.164529 198.287665 \n",
       "L 171.889205 201.808874 \n",
       "L 172.61388 209.675606 \n",
       "L 173.338555 194.255226 \n",
       "L 174.063231 210.310755 \n",
       "L 174.787906 209.00513 \n",
       "L 175.512581 211.013459 \n",
       "L 176.237256 202.491953 \n",
       "L 176.961932 210.326778 \n",
       "L 177.686607 212.549329 \n",
       "L 178.411282 210.895634 \n",
       "L 179.135958 212.353552 \n",
       "L 179.860633 211.708677 \n",
       "L 180.585308 208.467368 \n",
       "L 181.309984 210.212352 \n",
       "L 182.034659 213.20154 \n",
       "L 182.759334 211.102169 \n",
       "L 183.48401 206.421779 \n",
       "L 184.208685 213.573217 \n",
       "L 184.93336 210.247735 \n",
       "L 185.658036 212.789413 \n",
       "L 186.382711 212.230682 \n",
       "L 187.107386 213.851819 \n",
       "L 187.832062 211.395926 \n",
       "L 188.556737 214.851796 \n",
       "L 189.281412 210.435568 \n",
       "L 190.006088 214.12016 \n",
       "L 190.730763 213.396084 \n",
       "L 191.455438 211.492072 \n",
       "L 192.180114 198.247374 \n",
       "L 192.904789 212.470756 \n",
       "L 193.629464 209.908375 \n",
       "L 194.35414 212.350134 \n",
       "L 195.078815 213.82204 \n",
       "L 195.80349 213.40671 \n",
       "L 196.528166 214.590709 \n",
       "L 197.252841 211.995052 \n",
       "L 197.977516 214.235784 \n",
       "L 198.702192 215.491795 \n",
       "L 199.426867 209.644683 \n",
       "L 200.151542 214.470123 \n",
       "L 200.876218 214.432409 \n",
       "L 201.600893 211.001862 \n",
       "L 202.325568 214.728643 \n",
       "L 203.050244 214.931495 \n",
       "L 203.774919 213.320226 \n",
       "L 204.499594 218.295609 \n",
       "L 205.224269 217.797072 \n",
       "L 205.948945 216.966621 \n",
       "L 206.67362 217.840249 \n",
       "L 207.398295 216.940447 \n",
       "L 208.122971 213.175048 \n",
       "L 208.847646 218.042685 \n",
       "L 209.572321 218.107824 \n",
       "L 210.296997 217.864029 \n",
       "L 211.021672 217.870141 \n",
       "L 211.746347 216.126678 \n",
       "L 212.471023 217.252978 \n",
       "L 213.195698 217.798265 \n",
       "L 213.920373 219.722536 \n",
       "L 214.645049 219.457653 \n",
       "L 215.369724 218.929827 \n",
       "L 216.094399 217.085486 \n",
       "L 216.819075 218.036285 \n",
       "L 217.54375 220.994089 \n",
       "L 218.268425 218.995694 \n",
       "L 218.993101 218.837552 \n",
       "L 219.717776 220.472883 \n",
       "L 220.442451 219.414145 \n",
       "L 221.167127 221.324105 \n",
       "L 221.891802 220.206314 \n",
       "L 222.616477 219.737845 \n",
       "L 223.341153 219.472909 \n",
       "L 224.065828 221.494367 \n",
       "L 224.790503 220.709171 \n",
       "L 225.515179 220.773958 \n",
       "L 226.239854 218.931434 \n",
       "L 226.964529 222.884105 \n",
       "L 227.689205 221.960462 \n",
       "L 228.41388 220.061865 \n",
       "L 229.138555 222.561752 \n",
       "L 229.863231 219.629808 \n",
       "L 230.587906 223.512768 \n",
       "L 231.312581 221.620012 \n",
       "L 232.037256 222.61865 \n",
       "L 232.761932 221.533064 \n",
       "L 233.486607 223.156911 \n",
       "L 234.211282 222.397214 \n",
       "L 234.935958 224.312841 \n",
       "L 235.660633 222.242734 \n",
       "L 236.385308 223.927971 \n",
       "L 237.109984 224.239236 \n",
       "L 237.834659 222.528461 \n",
       "L 238.559334 223.496046 \n",
       "L 239.28401 223.304381 \n",
       "L 240.008685 222.424026 \n",
       "L 240.73336 222.917937 \n",
       "L 241.458036 220.280397 \n",
       "L 242.182711 224.057653 \n",
       "L 242.907386 221.391611 \n",
       "L 243.632062 220.54006 \n",
       "L 244.356737 221.295033 \n",
       "L 245.081412 223.523652 \n",
       "L 245.806088 224.025309 \n",
       "L 246.530763 223.622 \n",
       "L 247.255438 224.280409 \n",
       "L 247.980114 221.671162 \n",
       "L 248.704789 221.633862 \n",
       "L 249.429464 223.362831 \n",
       "L 250.15414 223.343389 \n",
       "L 250.878815 224.092691 \n",
       "L 251.60349 222.182191 \n",
       "L 252.328166 223.667292 \n",
       "L 253.052841 224.589545 \n",
       "L 253.777516 222.87964 \n",
       "L 254.502192 225.407709 \n",
       "L 255.226867 224.163418 \n",
       "L 255.951542 226.30395 \n",
       "L 257.400893 223.4555 \n",
       "L 258.125568 226.029929 \n",
       "L 260.299594 224.063405 \n",
       "L 261.024269 225.124343 \n",
       "L 261.748945 223.941576 \n",
       "L 262.47362 227.004318 \n",
       "L 263.198295 226.10069 \n",
       "L 263.922971 224.894092 \n",
       "L 264.647646 222.651353 \n",
       "L 265.372321 223.931101 \n",
       "L 266.096997 223.806756 \n",
       "L 266.821672 225.117392 \n",
       "L 267.546347 224.190716 \n",
       "L 268.271023 224.434934 \n",
       "L 268.995698 221.739862 \n",
       "L 269.720373 225.617 \n",
       "L 270.445049 224.943741 \n",
       "L 271.169724 224.804142 \n",
       "L 271.894399 226.274518 \n",
       "L 272.619075 226.922758 \n",
       "L 273.34375 224.27599 \n",
       "L 274.068425 225.710357 \n",
       "L 274.793101 226.292527 \n",
       "L 275.517776 223.895583 \n",
       "L 276.242451 226.105879 \n",
       "L 276.967127 223.101377 \n",
       "L 277.691802 225.771268 \n",
       "L 278.416477 227.654925 \n",
       "L 279.141153 224.941139 \n",
       "L 279.865828 227.451605 \n",
       "L 280.590503 227.209441 \n",
       "L 281.315179 227.505253 \n",
       "L 282.039854 223.889845 \n",
       "L 282.764529 225.039031 \n",
       "L 283.489205 225.616237 \n",
       "L 284.21388 225.596999 \n",
       "L 284.938555 227.339583 \n",
       "L 285.663231 225.705366 \n",
       "L 286.387906 226.264533 \n",
       "L 287.112581 227.020023 \n",
       "L 287.837256 226.681592 \n",
       "L 288.561932 223.169636 \n",
       "L 290.011282 227.485521 \n",
       "L 290.735958 222.77503 \n",
       "L 291.460633 223.501924 \n",
       "L 292.185308 225.097922 \n",
       "L 292.909984 225.902499 \n",
       "L 293.634659 227.510897 \n",
       "L 294.359334 227.112786 \n",
       "L 295.08401 224.787268 \n",
       "L 295.808685 225.22291 \n",
       "L 296.53336 223.193804 \n",
       "L 297.258036 226.240859 \n",
       "L 297.982711 227.91531 \n",
       "L 298.707386 222.94686 \n",
       "L 299.432062 226.943461 \n",
       "L 300.156737 226.620752 \n",
       "L 300.881412 227.292883 \n",
       "L 301.606088 224.483766 \n",
       "L 302.330763 226.881948 \n",
       "L 303.055438 227.538422 \n",
       "L 303.780114 225.130077 \n",
       "L 304.504789 228.25046 \n",
       "L 305.229464 226.685952 \n",
       "L 305.95414 228.087792 \n",
       "L 306.678815 228.442354 \n",
       "L 308.128166 226.70349 \n",
       "L 308.852841 220.245225 \n",
       "L 309.577516 226.468292 \n",
       "L 310.302192 227.491155 \n",
       "L 311.026867 227.055778 \n",
       "L 311.751542 223.231892 \n",
       "L 312.476218 229.068869 \n",
       "L 313.200893 225.718442 \n",
       "L 313.925568 225.7972 \n",
       "L 314.650244 227.849086 \n",
       "L 315.374919 224.577488 \n",
       "L 316.099594 226.32617 \n",
       "L 316.824269 226.200582 \n",
       "L 317.548945 228.63475 \n",
       "L 318.27362 223.113045 \n",
       "L 318.998295 227.410575 \n",
       "L 319.722971 228.901533 \n",
       "L 320.447646 224.798905 \n",
       "L 321.172321 223.768614 \n",
       "L 321.896997 228.543337 \n",
       "L 322.621672 228.495019 \n",
       "L 323.346347 225.292818 \n",
       "L 324.071023 228.384614 \n",
       "L 324.795698 226.164109 \n",
       "L 325.520373 226.096722 \n",
       "L 326.245049 227.81041 \n",
       "L 326.969724 227.743609 \n",
       "L 327.694399 226.778118 \n",
       "L 328.419075 227.076517 \n",
       "L 329.14375 227.967941 \n",
       "L 329.868425 226.966694 \n",
       "L 330.593101 226.911671 \n",
       "L 331.317776 227.969505 \n",
       "L 332.042451 228.280467 \n",
       "L 332.767127 228.442795 \n",
       "L 333.491802 229.24473 \n",
       "L 334.216477 225.691254 \n",
       "L 334.941153 229.432524 \n",
       "L 335.665828 220.811293 \n",
       "L 336.390503 228.149512 \n",
       "L 337.115179 226.922841 \n",
       "L 337.839854 229.170469 \n",
       "L 338.564529 227.968173 \n",
       "L 339.289205 227.185847 \n",
       "L 340.01388 226.700274 \n",
       "L 340.738555 227.90955 \n",
       "L 341.463231 223.961723 \n",
       "L 342.187906 227.435829 \n",
       "L 342.912581 228.518259 \n",
       "L 343.637256 226.606913 \n",
       "L 344.361932 226.136312 \n",
       "L 345.086607 226.806871 \n",
       "L 345.811282 225.054703 \n",
       "L 346.535958 228.457401 \n",
       "L 347.260633 225.232378 \n",
       "L 347.985308 228.325029 \n",
       "L 348.709984 229.063638 \n",
       "L 349.434659 227.811802 \n",
       "L 350.159334 228.30794 \n",
       "L 350.88401 228.024353 \n",
       "L 351.608685 227.954223 \n",
       "L 352.33336 228.610494 \n",
       "L 353.058036 229.60327 \n",
       "L 353.782711 227.701358 \n",
       "L 354.507386 229.320252 \n",
       "L 355.956737 227.838092 \n",
       "L 356.681412 229.196369 \n",
       "L 357.406088 229.874489 \n",
       "L 358.130763 227.691687 \n",
       "L 358.855438 228.201371 \n",
       "L 359.580114 228.422362 \n",
       "L 360.304789 226.291454 \n",
       "L 361.029464 227.973591 \n",
       "L 361.75414 226.984799 \n",
       "L 362.478815 228.459303 \n",
       "L 363.20349 224.677278 \n",
       "L 364.652841 228.699108 \n",
       "L 365.377516 229.139073 \n",
       "L 366.102192 227.58889 \n",
       "L 366.826867 228.352181 \n",
       "L 367.551542 225.490681 \n",
       "L 368.276218 227.364764 \n",
       "L 369.000893 226.207094 \n",
       "L 369.725568 229.349623 \n",
       "L 369.725568 229.349623 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path clip-path=\"url(#p686c8bb920)\" d=\"M 65.361932 32.201761 \n",
       "L 66.086607 64.317123 \n",
       "L 66.811282 67.614978 \n",
       "L 67.535958 65.237453 \n",
       "L 68.260633 73.35117 \n",
       "L 68.985308 80.185367 \n",
       "L 69.709984 82.358668 \n",
       "L 70.434659 73.315667 \n",
       "L 71.88401 91.461438 \n",
       "L 72.608685 94.075676 \n",
       "L 73.33336 101.078351 \n",
       "L 74.058036 109.772333 \n",
       "L 74.782711 107.064464 \n",
       "L 75.507386 107.729612 \n",
       "L 76.232062 108.835515 \n",
       "L 76.956737 112.266914 \n",
       "L 77.681412 115.12529 \n",
       "L 78.406088 119.082461 \n",
       "L 79.130763 122.170625 \n",
       "L 79.855438 122.819625 \n",
       "L 80.580114 128.164891 \n",
       "L 81.304789 129.939696 \n",
       "L 82.75414 136.460547 \n",
       "L 83.478815 138.989368 \n",
       "L 84.20349 137.574044 \n",
       "L 84.928166 140.588692 \n",
       "L 85.652841 139.542903 \n",
       "L 86.377516 151.987755 \n",
       "L 87.102192 147.219158 \n",
       "L 89.276218 154.151038 \n",
       "L 90.725568 156.79301 \n",
       "L 91.450244 159.511674 \n",
       "L 92.174919 157.763083 \n",
       "L 92.899594 160.639958 \n",
       "L 93.624269 159.520471 \n",
       "L 94.348945 164.172188 \n",
       "L 95.07362 164.866083 \n",
       "L 95.798295 166.687814 \n",
       "L 96.522971 167.722801 \n",
       "L 97.247646 169.13917 \n",
       "L 97.972321 165.083909 \n",
       "L 98.696997 164.476798 \n",
       "L 99.421672 173.114864 \n",
       "L 100.146347 171.87699 \n",
       "L 100.871023 179.362374 \n",
       "L 101.595698 169.557082 \n",
       "L 102.320373 176.611578 \n",
       "L 103.045049 176.636444 \n",
       "L 103.769724 180.273257 \n",
       "L 104.494399 175.739551 \n",
       "L 105.219075 179.672762 \n",
       "L 105.94375 182.943913 \n",
       "L 106.668425 181.679748 \n",
       "L 107.393101 182.15138 \n",
       "L 108.117776 183.174731 \n",
       "L 108.842451 185.372099 \n",
       "L 109.567127 186.1553 \n",
       "L 110.291802 188.285573 \n",
       "L 111.016477 188.944573 \n",
       "L 111.741153 188.483536 \n",
       "L 112.465828 192.475943 \n",
       "L 113.190503 192.952994 \n",
       "L 113.915179 191.377498 \n",
       "L 114.639854 192.43113 \n",
       "L 115.364529 193.011447 \n",
       "L 116.089205 188.204172 \n",
       "L 116.81388 195.09455 \n",
       "L 117.538555 195.553329 \n",
       "L 118.263231 194.502604 \n",
       "L 118.987906 196.799858 \n",
       "L 119.712581 195.80521 \n",
       "L 120.437256 198.888884 \n",
       "L 121.886607 196.972512 \n",
       "L 122.611282 198.100883 \n",
       "L 123.335958 200.261721 \n",
       "L 124.060633 199.589131 \n",
       "L 124.785308 199.362278 \n",
       "L 125.509984 197.281632 \n",
       "L 126.234659 202.849053 \n",
       "L 126.959334 201.100696 \n",
       "L 127.68401 200.463925 \n",
       "L 128.408685 197.889263 \n",
       "L 129.13336 199.246105 \n",
       "L 129.858036 203.702705 \n",
       "L 130.582711 204.279264 \n",
       "L 131.307386 200.068357 \n",
       "L 132.032062 202.133605 \n",
       "L 132.756737 202.831611 \n",
       "L 133.481412 200.52142 \n",
       "L 134.206088 203.193479 \n",
       "L 134.930763 201.705863 \n",
       "L 135.655438 202.298969 \n",
       "L 136.380114 206.046372 \n",
       "L 137.104789 201.552981 \n",
       "L 137.829464 203.68656 \n",
       "L 138.55414 204.423055 \n",
       "L 139.278815 203.06426 \n",
       "L 140.00349 204.001191 \n",
       "L 140.728166 207.274781 \n",
       "L 141.452841 205.72214 \n",
       "L 142.177516 206.892603 \n",
       "L 142.902192 205.510796 \n",
       "L 143.626867 205.33508 \n",
       "L 144.351542 207.305096 \n",
       "L 145.076218 206.670953 \n",
       "L 145.800893 204.299297 \n",
       "L 147.250244 208.009152 \n",
       "L 147.974919 207.33132 \n",
       "L 148.699594 205.532761 \n",
       "L 149.424269 208.298576 \n",
       "L 150.148945 208.024634 \n",
       "L 150.87362 208.524982 \n",
       "L 151.598295 207.356204 \n",
       "L 152.322971 208.622079 \n",
       "L 153.047646 211.467543 \n",
       "L 153.772321 207.800036 \n",
       "L 154.496997 208.765271 \n",
       "L 155.221672 211.979911 \n",
       "L 155.946347 211.123016 \n",
       "L 156.671023 208.434503 \n",
       "L 157.395698 209.291306 \n",
       "L 158.120373 209.937118 \n",
       "L 158.845049 214.318758 \n",
       "L 159.569724 206.522105 \n",
       "L 160.294399 211.627757 \n",
       "L 161.74375 212.364132 \n",
       "L 162.468425 213.367953 \n",
       "L 163.193101 212.891699 \n",
       "L 163.917776 208.339775 \n",
       "L 164.642451 215.165135 \n",
       "L 166.091802 212.111205 \n",
       "L 168.265828 214.548423 \n",
       "L 168.990503 211.701297 \n",
       "L 169.715179 213.051674 \n",
       "L 170.439854 215.629919 \n",
       "L 171.164529 214.391539 \n",
       "L 171.889205 209.914945 \n",
       "L 172.61388 215.341838 \n",
       "L 173.338555 213.519394 \n",
       "L 174.063231 215.570746 \n",
       "L 174.787906 214.100601 \n",
       "L 175.512581 208.579527 \n",
       "L 176.237256 214.176082 \n",
       "L 176.961932 209.776243 \n",
       "L 177.686607 213.783469 \n",
       "L 178.411282 214.418523 \n",
       "L 179.135958 213.805345 \n",
       "L 179.860633 214.716558 \n",
       "L 180.585308 213.53354 \n",
       "L 181.309984 215.225171 \n",
       "L 182.034659 214.625979 \n",
       "L 182.759334 214.953486 \n",
       "L 183.48401 214.941987 \n",
       "L 184.208685 217.390245 \n",
       "L 184.93336 215.306363 \n",
       "L 185.658036 215.362512 \n",
       "L 186.382711 216.955505 \n",
       "L 187.107386 212.928235 \n",
       "L 187.832062 215.291843 \n",
       "L 188.556737 216.230147 \n",
       "L 189.281412 216.108092 \n",
       "L 191.455438 216.45131 \n",
       "L 192.180114 212.833461 \n",
       "L 193.629464 218.208901 \n",
       "L 194.35414 216.570976 \n",
       "L 195.078815 216.401958 \n",
       "L 195.80349 215.978498 \n",
       "L 196.528166 216.977628 \n",
       "L 197.252841 218.258438 \n",
       "L 197.977516 217.99633 \n",
       "L 198.702192 214.947394 \n",
       "L 199.426867 216.481531 \n",
       "L 200.151542 216.097492 \n",
       "L 200.876218 216.021042 \n",
       "L 201.600893 217.756731 \n",
       "L 202.325568 216.870593 \n",
       "L 203.050244 214.261407 \n",
       "L 203.774919 218.079325 \n",
       "L 204.499594 217.760531 \n",
       "L 205.224269 217.787251 \n",
       "L 205.948945 218.841055 \n",
       "L 206.67362 217.282025 \n",
       "L 207.398295 218.484481 \n",
       "L 208.122971 218.13244 \n",
       "L 208.847646 218.293284 \n",
       "L 209.572321 218.650461 \n",
       "L 210.296997 218.819378 \n",
       "L 211.021672 218.557252 \n",
       "L 211.746347 218.67884 \n",
       "L 212.471023 218.212163 \n",
       "L 213.195698 217.882338 \n",
       "L 213.920373 219.328833 \n",
       "L 214.645049 218.819383 \n",
       "L 215.369724 220.098574 \n",
       "L 216.094399 219.598451 \n",
       "L 216.819075 220.305703 \n",
       "L 217.54375 220.271162 \n",
       "L 218.268425 219.597124 \n",
       "L 218.993101 219.688106 \n",
       "L 219.717776 220.621665 \n",
       "L 220.442451 220.71739 \n",
       "L 221.167127 221.150666 \n",
       "L 222.616477 220.608532 \n",
       "L 223.341153 221.320043 \n",
       "L 224.065828 221.431428 \n",
       "L 224.790503 221.691945 \n",
       "L 226.239854 221.665682 \n",
       "L 226.964529 221.423826 \n",
       "L 228.41388 222.341266 \n",
       "L 229.138555 222.347247 \n",
       "L 229.863231 222.152203 \n",
       "L 230.587906 222.225458 \n",
       "L 232.037256 222.098848 \n",
       "L 232.761932 222.648992 \n",
       "L 233.486607 222.762612 \n",
       "L 234.211282 223.00049 \n",
       "L 234.935958 222.392404 \n",
       "L 236.385308 223.147119 \n",
       "L 237.834659 223.330637 \n",
       "L 238.559334 223.157849 \n",
       "L 240.008685 223.61652 \n",
       "L 240.73336 223.229867 \n",
       "L 242.182711 223.748744 \n",
       "L 242.907386 223.763769 \n",
       "L 243.632062 224.030359 \n",
       "L 244.356737 223.93018 \n",
       "L 245.081412 223.982068 \n",
       "L 245.806088 223.671503 \n",
       "L 248.704789 224.347389 \n",
       "L 250.15414 224.095242 \n",
       "L 250.878815 224.469272 \n",
       "L 251.60349 224.557988 \n",
       "L 252.328166 224.344692 \n",
       "L 253.777516 224.710005 \n",
       "L 256.676218 224.714901 \n",
       "L 261.024269 225.06169 \n",
       "L 261.748945 224.921282 \n",
       "L 262.47362 225.135368 \n",
       "L 263.922971 225.231594 \n",
       "L 266.096997 225.290766 \n",
       "L 267.546347 225.236988 \n",
       "L 268.271023 225.455726 \n",
       "L 268.995698 225.521648 \n",
       "L 269.720373 225.24405 \n",
       "L 270.445049 225.461284 \n",
       "L 273.34375 225.386059 \n",
       "L 274.068425 225.578787 \n",
       "L 275.517776 225.700153 \n",
       "L 276.242451 225.672456 \n",
       "L 276.967127 225.478818 \n",
       "L 278.416477 225.656562 \n",
       "L 279.141153 225.824347 \n",
       "L 280.590503 225.84471 \n",
       "L 281.315179 225.691186 \n",
       "L 282.764529 225.971502 \n",
       "L 284.938555 225.968226 \n",
       "L 286.387906 226.058242 \n",
       "L 287.112581 225.832376 \n",
       "L 287.837256 225.781848 \n",
       "L 288.561932 226.100042 \n",
       "L 289.286607 226.122666 \n",
       "L 290.011282 225.921157 \n",
       "L 291.460633 226.164516 \n",
       "L 292.909984 226.232233 \n",
       "L 293.634659 226.091675 \n",
       "L 294.359334 226.225163 \n",
       "L 295.08401 226.075617 \n",
       "L 295.808685 226.286865 \n",
       "L 296.53336 226.364678 \n",
       "L 297.982711 226.295876 \n",
       "L 298.707386 226.345477 \n",
       "L 299.432062 225.995373 \n",
       "L 300.156737 226.3362 \n",
       "L 303.055438 226.487347 \n",
       "L 304.504789 226.378882 \n",
       "L 305.229464 226.483748 \n",
       "L 305.95414 226.395176 \n",
       "L 307.40349 226.539283 \n",
       "L 308.128166 226.467401 \n",
       "L 309.577516 226.547517 \n",
       "L 310.302192 226.42354 \n",
       "L 311.026867 226.574074 \n",
       "L 311.751542 226.606225 \n",
       "L 312.476218 226.517028 \n",
       "L 313.200893 226.650257 \n",
       "L 314.650244 226.703866 \n",
       "L 315.374919 226.487492 \n",
       "L 316.099594 226.675544 \n",
       "L 317.548945 226.677066 \n",
       "L 318.27362 226.593376 \n",
       "L 318.998295 226.685722 \n",
       "L 319.722971 226.612846 \n",
       "L 321.172321 226.773768 \n",
       "L 327.694399 226.883026 \n",
       "L 328.419075 226.761464 \n",
       "L 329.868425 226.889471 \n",
       "L 336.390503 227.005761 \n",
       "L 337.115179 226.811244 \n",
       "L 337.839854 227.017348 \n",
       "L 339.289205 227.036238 \n",
       "L 341.463231 227.166135 \n",
       "L 342.912581 227.025327 \n",
       "L 344.361932 227.053517 \n",
       "L 345.086607 227.217259 \n",
       "L 346.535958 227.055885 \n",
       "L 347.260633 227.246192 \n",
       "L 347.985308 227.27457 \n",
       "L 348.709984 227.47001 \n",
       "L 349.434659 227.408456 \n",
       "L 350.159334 227.560817 \n",
       "L 350.88401 227.49196 \n",
       "L 352.33336 227.569876 \n",
       "L 355.956737 227.524237 \n",
       "L 356.681412 227.481243 \n",
       "L 358.130763 227.714871 \n",
       "L 359.580114 227.476222 \n",
       "L 360.304789 227.636629 \n",
       "L 369.725568 227.681321 \n",
       "L 369.725568 227.681321 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 50.14375 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 384.94375 239.758125 \n",
       "L 384.94375 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 50.14375 239.758125 \n",
       "L 384.94375 239.758125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 50.14375 22.318125 \n",
       "L 384.94375 22.318125 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_17\">\n",
       "    <!-- autoencoder loss over time -->\n",
       "    <defs>\n",
       "     <path d=\"M 34.28125 27.484375 \n",
       "Q 23.390625 27.484375 19.1875 25 \n",
       "Q 14.984375 22.515625 14.984375 16.5 \n",
       "Q 14.984375 11.71875 18.140625 8.90625 \n",
       "Q 21.296875 6.109375 26.703125 6.109375 \n",
       "Q 34.1875 6.109375 38.703125 11.40625 \n",
       "Q 43.21875 16.703125 43.21875 25.484375 \n",
       "L 43.21875 27.484375 \n",
       "z\n",
       "M 52.203125 31.203125 \n",
       "L 52.203125 0 \n",
       "L 43.21875 0 \n",
       "L 43.21875 8.296875 \n",
       "Q 40.140625 3.328125 35.546875 0.953125 \n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \n",
       "Q 6 8.015625 6 15.921875 \n",
       "Q 6 25.140625 12.171875 29.828125 \n",
       "Q 18.359375 34.515625 30.609375 34.515625 \n",
       "L 43.21875 34.515625 \n",
       "L 43.21875 35.40625 \n",
       "Q 43.21875 41.609375 39.140625 45 \n",
       "Q 35.0625 48.390625 27.6875 48.390625 \n",
       "Q 23 48.390625 18.546875 47.265625 \n",
       "Q 14.109375 46.140625 10.015625 43.890625 \n",
       "L 10.015625 52.203125 \n",
       "Q 14.9375 54.109375 19.578125 55.046875 \n",
       "Q 24.21875 56 28.609375 56 \n",
       "Q 40.484375 56 46.34375 49.84375 \n",
       "Q 52.203125 43.703125 52.203125 31.203125 \n",
       "z\n",
       "\" id=\"DejaVuSans-97\"/>\n",
       "     <path d=\"M 8.5 21.578125 \n",
       "L 8.5 54.6875 \n",
       "L 17.484375 54.6875 \n",
       "L 17.484375 21.921875 \n",
       "Q 17.484375 14.15625 20.5 10.265625 \n",
       "Q 23.53125 6.390625 29.59375 6.390625 \n",
       "Q 36.859375 6.390625 41.078125 11.03125 \n",
       "Q 45.3125 15.671875 45.3125 23.6875 \n",
       "L 45.3125 54.6875 \n",
       "L 54.296875 54.6875 \n",
       "L 54.296875 0 \n",
       "L 45.3125 0 \n",
       "L 45.3125 8.40625 \n",
       "Q 42.046875 3.421875 37.71875 1 \n",
       "Q 33.40625 -1.421875 27.6875 -1.421875 \n",
       "Q 18.265625 -1.421875 13.375 4.4375 \n",
       "Q 8.5 10.296875 8.5 21.578125 \n",
       "z\n",
       "M 31.109375 56 \n",
       "z\n",
       "\" id=\"DejaVuSans-117\"/>\n",
       "     <path d=\"M 18.3125 70.21875 \n",
       "L 18.3125 54.6875 \n",
       "L 36.8125 54.6875 \n",
       "L 36.8125 47.703125 \n",
       "L 18.3125 47.703125 \n",
       "L 18.3125 18.015625 \n",
       "Q 18.3125 11.328125 20.140625 9.421875 \n",
       "Q 21.96875 7.515625 27.59375 7.515625 \n",
       "L 36.8125 7.515625 \n",
       "L 36.8125 0 \n",
       "L 27.59375 0 \n",
       "Q 17.1875 0 13.234375 3.875 \n",
       "Q 9.28125 7.765625 9.28125 18.015625 \n",
       "L 9.28125 47.703125 \n",
       "L 2.6875 47.703125 \n",
       "L 2.6875 54.6875 \n",
       "L 9.28125 54.6875 \n",
       "L 9.28125 70.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-116\"/>\n",
       "     <path d=\"M 54.890625 33.015625 \n",
       "L 54.890625 0 \n",
       "L 45.90625 0 \n",
       "L 45.90625 32.71875 \n",
       "Q 45.90625 40.484375 42.875 44.328125 \n",
       "Q 39.84375 48.1875 33.796875 48.1875 \n",
       "Q 26.515625 48.1875 22.3125 43.546875 \n",
       "Q 18.109375 38.921875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.34375 51.125 25.703125 53.5625 \n",
       "Q 30.078125 56 35.796875 56 \n",
       "Q 45.21875 56 50.046875 50.171875 \n",
       "Q 54.890625 44.34375 54.890625 33.015625 \n",
       "z\n",
       "\" id=\"DejaVuSans-110\"/>\n",
       "     <path d=\"M 45.40625 46.390625 \n",
       "L 45.40625 75.984375 \n",
       "L 54.390625 75.984375 \n",
       "L 54.390625 0 \n",
       "L 45.40625 0 \n",
       "L 45.40625 8.203125 \n",
       "Q 42.578125 3.328125 38.25 0.953125 \n",
       "Q 33.9375 -1.421875 27.875 -1.421875 \n",
       "Q 17.96875 -1.421875 11.734375 6.484375 \n",
       "Q 5.515625 14.40625 5.515625 27.296875 \n",
       "Q 5.515625 40.1875 11.734375 48.09375 \n",
       "Q 17.96875 56 27.875 56 \n",
       "Q 33.9375 56 38.25 53.625 \n",
       "Q 42.578125 51.265625 45.40625 46.390625 \n",
       "z\n",
       "M 14.796875 27.296875 \n",
       "Q 14.796875 17.390625 18.875 11.75 \n",
       "Q 22.953125 6.109375 30.078125 6.109375 \n",
       "Q 37.203125 6.109375 41.296875 11.75 \n",
       "Q 45.40625 17.390625 45.40625 27.296875 \n",
       "Q 45.40625 37.203125 41.296875 42.84375 \n",
       "Q 37.203125 48.484375 30.078125 48.484375 \n",
       "Q 22.953125 48.484375 18.875 42.84375 \n",
       "Q 14.796875 37.203125 14.796875 27.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-100\"/>\n",
       "     <path d=\"M 41.109375 46.296875 \n",
       "Q 39.59375 47.171875 37.8125 47.578125 \n",
       "Q 36.03125 48 33.890625 48 \n",
       "Q 26.265625 48 22.1875 43.046875 \n",
       "Q 18.109375 38.09375 18.109375 28.8125 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 20.953125 51.171875 25.484375 53.578125 \n",
       "Q 30.03125 56 36.53125 56 \n",
       "Q 37.453125 56 38.578125 55.875 \n",
       "Q 39.703125 55.765625 41.0625 55.515625 \n",
       "z\n",
       "\" id=\"DejaVuSans-114\"/>\n",
       "     <path d=\"M 2.984375 54.6875 \n",
       "L 12.5 54.6875 \n",
       "L 29.59375 8.796875 \n",
       "L 46.6875 54.6875 \n",
       "L 56.203125 54.6875 \n",
       "L 35.6875 0 \n",
       "L 23.484375 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-118\"/>\n",
       "     <path d=\"M 9.421875 54.6875 \n",
       "L 18.40625 54.6875 \n",
       "L 18.40625 0 \n",
       "L 9.421875 0 \n",
       "z\n",
       "M 9.421875 75.984375 \n",
       "L 18.40625 75.984375 \n",
       "L 18.40625 64.59375 \n",
       "L 9.421875 64.59375 \n",
       "z\n",
       "\" id=\"DejaVuSans-105\"/>\n",
       "     <path d=\"M 52 44.1875 \n",
       "Q 55.375 50.25 60.0625 53.125 \n",
       "Q 64.75 56 71.09375 56 \n",
       "Q 79.640625 56 84.28125 50.015625 \n",
       "Q 88.921875 44.046875 88.921875 33.015625 \n",
       "L 88.921875 0 \n",
       "L 79.890625 0 \n",
       "L 79.890625 32.71875 \n",
       "Q 79.890625 40.578125 77.09375 44.375 \n",
       "Q 74.3125 48.1875 68.609375 48.1875 \n",
       "Q 61.625 48.1875 57.5625 43.546875 \n",
       "Q 53.515625 38.921875 53.515625 30.90625 \n",
       "L 53.515625 0 \n",
       "L 44.484375 0 \n",
       "L 44.484375 32.71875 \n",
       "Q 44.484375 40.625 41.703125 44.40625 \n",
       "Q 38.921875 48.1875 33.109375 48.1875 \n",
       "Q 26.21875 48.1875 22.15625 43.53125 \n",
       "Q 18.109375 38.875 18.109375 30.90625 \n",
       "L 18.109375 0 \n",
       "L 9.078125 0 \n",
       "L 9.078125 54.6875 \n",
       "L 18.109375 54.6875 \n",
       "L 18.109375 46.1875 \n",
       "Q 21.1875 51.21875 25.484375 53.609375 \n",
       "Q 29.78125 56 35.6875 56 \n",
       "Q 41.65625 56 45.828125 52.96875 \n",
       "Q 50 49.953125 52 44.1875 \n",
       "z\n",
       "\" id=\"DejaVuSans-109\"/>\n",
       "    </defs>\n",
       "    <g transform=\"translate(135.3625 16.318125)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#DejaVuSans-97\"/>\n",
       "     <use x=\"61.279297\" xlink:href=\"#DejaVuSans-117\"/>\n",
       "     <use x=\"124.658203\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "     <use x=\"163.867188\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"225.048828\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"286.572266\" xlink:href=\"#DejaVuSans-110\"/>\n",
       "     <use x=\"349.951172\" xlink:href=\"#DejaVuSans-99\"/>\n",
       "     <use x=\"404.931641\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"466.113281\" xlink:href=\"#DejaVuSans-100\"/>\n",
       "     <use x=\"529.589844\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"591.113281\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "     <use x=\"632.226562\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"664.013672\" xlink:href=\"#DejaVuSans-108\"/>\n",
       "     <use x=\"691.796875\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"752.978516\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "     <use x=\"805.078125\" xlink:href=\"#DejaVuSans-115\"/>\n",
       "     <use x=\"857.177734\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"888.964844\" xlink:href=\"#DejaVuSans-111\"/>\n",
       "     <use x=\"950.146484\" xlink:href=\"#DejaVuSans-118\"/>\n",
       "     <use x=\"1009.326172\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "     <use x=\"1070.849609\" xlink:href=\"#DejaVuSans-114\"/>\n",
       "     <use x=\"1111.962891\" xlink:href=\"#DejaVuSans-32\"/>\n",
       "     <use x=\"1143.75\" xlink:href=\"#DejaVuSans-116\"/>\n",
       "     <use x=\"1182.958984\" xlink:href=\"#DejaVuSans-105\"/>\n",
       "     <use x=\"1210.742188\" xlink:href=\"#DejaVuSans-109\"/>\n",
       "     <use x=\"1308.154297\" xlink:href=\"#DejaVuSans-101\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p686c8bb920\">\n",
       "   <rect height=\"217.44\" width=\"334.8\" x=\"50.14375\" y=\"22.318125\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(losses3['epoch'], losses3['train_loss'])\n",
    "ax.plot(losses3['epoch'], losses3['validation_loss'])\n",
    "ax.set_ylabel('MSE loss')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_title('autoencoder loss over time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded4 = ae_4.get_encoded_representations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('autoencodercoll42_embeddings.pkl', 'wb') as fh:\n",
    "    pickle.dump(encoded4, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
